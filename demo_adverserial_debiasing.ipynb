{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from tabulate import tabulate\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from adversarial_debiasing import AdversarialDebiasing\n",
    "from load_data import load_data, transform_data, Datapoint\n",
    "\n",
    "from load_vectors import load_pretrained_vectors, load_vectors\n",
    "import config\n",
    "import utility_functions\n",
    "import qualitative_evaluation\n",
    "\n",
    "import gensim\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autoreloading changes made in other python scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the desired word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Wikipedia2Vec - pass \"Wikipedia2Vec\"\n",
    "# For Glove - pass \"Glove\"\n",
    "# For GoogleNews (Word2Vec) - pass \"GoogleNews\"\n",
    "\n",
    "word_vectors = load_pretrained_vectors(\"GoogleNews\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Google Analogies Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Raw_Datapoint(x1='Athens', x2='Greece', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Cairo', y='Egypt', task='capital-common-countries')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_dataset = load_data()\n",
    "analogy_dataset[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming the above dataset to include the respective word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datapoint(analogy_embeddings=array([-6.68945312e-02, -3.49121094e-02,  6.05468750e-02,  1.48437500e-01,\n",
       "        1.80664062e-02,  1.34887695e-02, -2.09960938e-01, -2.50000000e-01,\n",
       "       -1.62109375e-01,  1.82617188e-01, -1.88476562e-01, -1.99218750e-01,\n",
       "       -1.69921875e-01, -7.86132812e-02, -1.85394287e-03,  2.64892578e-02,\n",
       "       -1.18652344e-01,  6.93359375e-02,  5.44433594e-02, -1.07421875e-01,\n",
       "       -2.80761719e-02,  3.11279297e-02,  2.21679688e-01, -2.41210938e-01,\n",
       "       -1.60156250e-01, -5.15747070e-03, -9.61914062e-02,  1.77734375e-01,\n",
       "       -3.85742188e-02,  1.15722656e-01,  1.61132812e-01, -1.25976562e-01,\n",
       "       -4.90722656e-02, -2.38281250e-01, -1.10351562e-01, -1.59912109e-02,\n",
       "       -1.00097656e-01,  1.10473633e-02,  7.17773438e-02,  1.21093750e-01,\n",
       "       -7.42187500e-02,  3.23486328e-03,  1.25000000e-01,  4.17480469e-02,\n",
       "        1.10839844e-01,  4.32128906e-02, -1.08032227e-02, -1.89453125e-01,\n",
       "       -9.71679688e-02,  1.46484375e-01, -1.13769531e-01,  3.04687500e-01,\n",
       "        1.98242188e-01,  1.35498047e-02,  1.45507812e-01, -2.19726562e-01,\n",
       "       -1.51367188e-01, -5.64575195e-03, -1.27929688e-01, -9.86328125e-02,\n",
       "       -3.66210938e-02, -1.48437500e-01,  1.11083984e-02,  3.93066406e-02,\n",
       "        3.29589844e-02, -3.10546875e-01,  1.77001953e-02, -1.02050781e-01,\n",
       "       -5.20019531e-02, -3.56445312e-02, -1.14135742e-02,  1.44531250e-01,\n",
       "        4.44335938e-02, -1.91406250e-01, -1.47460938e-01, -3.93066406e-02,\n",
       "        9.91210938e-02, -4.98046875e-02, -1.55029297e-02, -1.24023438e-01,\n",
       "       -1.40625000e-01,  8.49609375e-02,  1.58203125e-01, -6.64062500e-02,\n",
       "        1.63574219e-02, -4.33349609e-03, -1.47705078e-02, -2.41699219e-02,\n",
       "        6.15234375e-02,  1.31835938e-01, -1.20605469e-01, -1.04003906e-01,\n",
       "       -8.05664062e-02, -1.70898438e-02, -1.18652344e-01,  1.46484375e-01,\n",
       "       -5.41992188e-02,  7.81250000e-02,  1.49414062e-01,  8.93554688e-02,\n",
       "       -1.86523438e-01,  2.91748047e-02,  1.09375000e-01, -9.03320312e-02,\n",
       "       -2.06298828e-02,  1.33789062e-01, -2.94189453e-02, -9.82666016e-03,\n",
       "        1.14746094e-01, -1.03027344e-01, -1.24511719e-01, -8.36181641e-03,\n",
       "        9.61914062e-02, -1.10839844e-01,  7.47070312e-02,  5.07812500e-02,\n",
       "       -8.44726562e-02, -1.32812500e-01,  4.12597656e-02, -9.61914062e-02,\n",
       "       -8.25195312e-02, -7.32421875e-02, -3.73535156e-02,  1.08032227e-02,\n",
       "        1.54296875e-01,  1.43554688e-01, -1.12792969e-01,  1.87500000e-01,\n",
       "        2.86865234e-02,  1.84570312e-01, -1.92382812e-01, -6.73828125e-02,\n",
       "       -2.61230469e-02,  7.27539062e-02, -4.54101562e-02, -6.17675781e-02,\n",
       "       -2.53906250e-01, -1.41601562e-02,  1.44531250e-01, -2.85644531e-02,\n",
       "        1.30859375e-01, -1.60156250e-01,  3.71093750e-02, -1.00585938e-01,\n",
       "       -1.00585938e-01, -2.40478516e-02,  8.05664062e-02, -5.00488281e-02,\n",
       "        8.62121582e-04, -1.42578125e-01,  1.11816406e-01, -1.49414062e-01,\n",
       "        3.54003906e-02, -2.16796875e-01, -1.19628906e-01, -1.78710938e-01,\n",
       "       -4.29687500e-02,  1.49414062e-01,  2.39257812e-02, -1.38671875e-01,\n",
       "       -1.18164062e-01,  1.06445312e-01, -2.80761719e-02, -1.58203125e-01,\n",
       "        1.78710938e-01, -1.00097656e-01,  2.06054688e-01, -1.68457031e-02,\n",
       "       -2.85156250e-01,  1.25976562e-01, -2.10937500e-01, -1.50756836e-02,\n",
       "        5.22460938e-02,  1.40380859e-02, -1.30859375e-01,  2.24609375e-02,\n",
       "        2.11914062e-01, -2.46093750e-01,  1.56250000e-01, -2.28515625e-01,\n",
       "        6.68945312e-02, -3.97949219e-02,  1.38549805e-02,  6.34765625e-02,\n",
       "       -3.08837891e-02,  6.12792969e-02, -7.71484375e-02, -1.01074219e-01,\n",
       "        1.48437500e-01,  6.73828125e-02,  1.56250000e-01,  1.53320312e-01,\n",
       "       -2.69531250e-01,  8.05664062e-02,  1.54296875e-01,  1.36718750e-01,\n",
       "       -2.50244141e-02,  1.52587891e-02,  7.95898438e-02, -6.39648438e-02,\n",
       "       -2.49023438e-01,  5.12695312e-02, -3.14453125e-01, -2.75390625e-01,\n",
       "       -1.59179688e-01, -2.75390625e-01, -6.15234375e-02, -1.50756836e-02,\n",
       "       -5.46875000e-02,  9.27734375e-02, -2.24304199e-03, -5.88378906e-02,\n",
       "       -3.04687500e-01,  5.27343750e-02, -1.90429688e-01, -4.05883789e-03,\n",
       "        1.83593750e-01, -2.36328125e-01, -1.66015625e-02, -6.59179688e-02,\n",
       "       -9.27734375e-03, -1.49414062e-01, -7.03125000e-02, -3.05175781e-02,\n",
       "       -1.14746094e-01,  2.86865234e-03,  1.16699219e-01,  1.53320312e-01,\n",
       "       -1.86523438e-01,  8.72802734e-03,  1.07910156e-01, -8.30078125e-02,\n",
       "       -8.49609375e-02,  1.44042969e-02, -7.99560547e-03, -8.64257812e-02,\n",
       "        2.21679688e-01,  4.46777344e-02, -1.34887695e-02,  4.85839844e-02,\n",
       "        3.26171875e-01,  1.96289062e-01, -4.24804688e-02,  2.27050781e-02,\n",
       "       -1.55273438e-01,  1.65039062e-01, -5.83496094e-02,  4.58984375e-02,\n",
       "       -1.25000000e-01, -1.42578125e-01,  2.73437500e-01,  1.38671875e-01,\n",
       "        2.01171875e-01,  2.34375000e-01,  1.03515625e-01, -2.44140625e-02,\n",
       "       -4.44335938e-02,  1.51977539e-02,  1.74804688e-01, -9.27734375e-02,\n",
       "       -2.25830078e-02,  4.94384766e-03,  1.60156250e-01, -1.23046875e-01,\n",
       "        3.73535156e-02,  1.14257812e-01, -9.76562500e-02, -9.47265625e-02,\n",
       "       -9.76562500e-03,  3.80859375e-02,  5.67626953e-03,  1.15966797e-02,\n",
       "        1.30859375e-01,  2.36816406e-02,  7.51953125e-02, -1.02050781e-01,\n",
       "        8.98437500e-02, -2.85156250e-01, -1.62109375e-01,  1.84570312e-01,\n",
       "       -6.83593750e-02,  1.37695312e-01, -2.92968750e-02,  6.83593750e-03,\n",
       "       -1.12304688e-01,  9.22851562e-02, -5.92041016e-03, -7.91015625e-02,\n",
       "       -1.08398438e-01,  1.12792969e-01,  2.05078125e-01,  1.50390625e-01,\n",
       "       -7.37304688e-02, -2.62451172e-02, -1.53198242e-02,  3.90625000e-02,\n",
       "       -1.18164062e-01, -4.80957031e-02, -1.66992188e-01,  1.77734375e-01,\n",
       "        2.43164062e-01,  1.40625000e-01,  5.05371094e-02,  4.10156250e-01,\n",
       "       -1.29882812e-01,  8.05664062e-02, -1.16210938e-01, -2.61718750e-01,\n",
       "        3.44238281e-02,  5.63964844e-02, -3.06640625e-01, -4.92187500e-01,\n",
       "       -2.51953125e-01,  3.88183594e-02, -8.05664062e-02, -1.18652344e-01,\n",
       "       -2.25830078e-02,  1.11816406e-01, -7.08007812e-02, -1.39648438e-01,\n",
       "        5.71289062e-02, -7.61718750e-02,  4.14062500e-01, -7.66601562e-02,\n",
       "        1.85546875e-01,  1.32812500e-01, -1.54296875e-01,  1.60156250e-01,\n",
       "        3.34472656e-02,  8.05664062e-02, -2.23388672e-02, -4.24194336e-03,\n",
       "        1.42578125e-01, -1.73828125e-01, -2.94921875e-01,  3.95507812e-02,\n",
       "       -2.18750000e-01,  2.19726562e-01,  1.45507812e-01,  2.32421875e-01,\n",
       "       -5.61523438e-03, -1.44653320e-02,  4.35546875e-01,  2.17773438e-01,\n",
       "        1.27929688e-01, -1.19140625e-01, -2.07031250e-01, -1.82617188e-01,\n",
       "       -2.42919922e-02,  1.99218750e-01, -2.65625000e-01,  1.07421875e-01,\n",
       "        2.61718750e-01,  2.38281250e-01, -2.27539062e-01, -1.91406250e-01,\n",
       "       -2.46093750e-01,  2.25830078e-02, -1.48437500e-01, -1.75781250e-01,\n",
       "       -3.00292969e-02, -1.00585938e-01, -1.23046875e-01, -2.35351562e-01,\n",
       "        7.27539062e-02, -5.03906250e-01,  1.52343750e-01, -6.93359375e-02,\n",
       "       -1.27929688e-01, -2.21679688e-01, -5.98907471e-04,  3.47656250e-01,\n",
       "        8.25195312e-02,  9.27734375e-02, -1.13769531e-01, -3.95507812e-02,\n",
       "        5.05371094e-02, -9.57031250e-02,  8.98437500e-02,  4.83398438e-02,\n",
       "       -2.26562500e-01, -5.63964844e-02, -1.24511719e-01, -1.26953125e-01,\n",
       "        1.55273438e-01,  1.87500000e-01, -5.17578125e-02,  1.66015625e-01,\n",
       "        1.32446289e-02,  1.67968750e-01,  2.31933594e-02,  1.31835938e-01,\n",
       "       -2.65625000e-01,  1.13769531e-01, -2.94921875e-01,  3.73535156e-02,\n",
       "       -1.39770508e-02, -1.43554688e-01,  4.19921875e-01,  3.97949219e-02,\n",
       "       -1.00097656e-01,  2.05078125e-01,  1.37695312e-01, -3.78417969e-02,\n",
       "        9.66796875e-02,  5.90820312e-02, -2.57812500e-01,  4.12597656e-02,\n",
       "        1.50390625e-01, -2.51953125e-01,  5.02929688e-02, -6.59179688e-02,\n",
       "        1.90429688e-01,  1.14257812e-01,  5.15136719e-02, -6.34765625e-02,\n",
       "       -1.76757812e-01, -2.65625000e-01,  1.04492188e-01, -1.11816406e-01,\n",
       "        2.18750000e-01, -3.33984375e-01, -5.93261719e-02,  1.04492188e-01,\n",
       "        2.09960938e-01,  3.14941406e-02, -1.73828125e-01,  1.66992188e-01,\n",
       "       -1.39648438e-01, -1.73339844e-02, -1.61132812e-01,  4.85839844e-02,\n",
       "        1.39648438e-01,  1.43432617e-03,  9.33837891e-03,  7.32421875e-02,\n",
       "       -2.22656250e-01, -7.66601562e-02,  9.57031250e-02,  1.79443359e-02,\n",
       "        3.45703125e-01, -3.10546875e-01,  8.54492188e-02,  2.58789062e-02,\n",
       "       -2.18750000e-01, -1.10351562e-01, -8.34960938e-02, -4.49218750e-02,\n",
       "        1.14257812e-01, -8.10546875e-02, -3.51562500e-02, -2.63671875e-01,\n",
       "       -2.02148438e-01, -1.52343750e-01, -1.73828125e-01, -1.93359375e-01,\n",
       "       -2.09960938e-01,  1.96289062e-01, -7.69042969e-03, -6.98242188e-02,\n",
       "        1.38671875e-01,  2.57812500e-01,  1.78222656e-02, -1.58203125e-01,\n",
       "        3.16406250e-01,  6.12792969e-02,  1.55273438e-01,  2.29492188e-01,\n",
       "       -3.75000000e-01,  1.09863281e-01, -4.10156250e-01, -4.85839844e-02,\n",
       "        7.20214844e-03, -6.98242188e-02,  9.91210938e-02, -1.83593750e-01,\n",
       "        3.12500000e-01, -2.59765625e-01,  4.10156250e-01, -1.46484375e-01,\n",
       "       -4.06265259e-04, -2.46093750e-01,  9.13085938e-02,  1.19628906e-01,\n",
       "        6.12792969e-02,  1.18164062e-01, -5.63964844e-02, -3.61328125e-02,\n",
       "       -1.24023438e-01, -1.11328125e-01,  1.77734375e-01,  8.00781250e-02,\n",
       "       -1.43432617e-02,  4.54101562e-02,  3.55468750e-01,  9.42382812e-02,\n",
       "       -1.53320312e-01,  2.71484375e-01, -9.52148438e-02, -2.24609375e-01,\n",
       "       -2.06054688e-01, -1.04003906e-01, -2.02148438e-01, -3.51562500e-01,\n",
       "        1.22680664e-02,  5.51757812e-02,  1.54296875e-01, -3.20312500e-01,\n",
       "       -8.83789062e-02, -1.39648438e-01,  1.09375000e-01,  7.66601562e-02,\n",
       "       -9.13085938e-02, -1.22558594e-01, -1.88476562e-01,  1.05468750e-01,\n",
       "        2.15820312e-01, -1.80664062e-01,  7.37304688e-02,  4.78515625e-02,\n",
       "       -1.08398438e-01, -2.77343750e-01, -6.98242188e-02, -1.04370117e-02,\n",
       "       -1.65039062e-01,  2.74658203e-02,  3.61328125e-02,  3.11279297e-03,\n",
       "        1.33789062e-01, -8.59375000e-02,  1.37695312e-01, -8.74023438e-02,\n",
       "        4.90722656e-02,  1.85546875e-01, -3.49121094e-02,  2.77343750e-01,\n",
       "        1.59179688e-01, -7.08007812e-02,  1.57226562e-01, -1.21093750e-01,\n",
       "        2.89062500e-01,  2.42187500e-01, -3.29589844e-02,  3.14453125e-01,\n",
       "       -3.44238281e-02,  7.91015625e-02, -1.91406250e-01, -6.37817383e-03,\n",
       "       -1.40625000e-01, -8.30078125e-02,  1.47460938e-01,  2.12890625e-01,\n",
       "        1.12792969e-01,  4.43359375e-01,  1.16210938e-01, -1.81640625e-01,\n",
       "       -8.69140625e-02,  6.25000000e-02,  2.91015625e-01, -3.08837891e-02,\n",
       "        5.15136719e-02, -5.15136719e-02,  2.00195312e-01,  5.90820312e-02,\n",
       "       -1.15234375e-01,  4.19921875e-02, -9.61914062e-02,  3.58886719e-02,\n",
       "        2.97851562e-02, -2.29492188e-01, -2.38281250e-01,  1.34887695e-02,\n",
       "        1.84570312e-01,  1.34765625e-01,  6.78710938e-02,  1.03759766e-03,\n",
       "        4.17480469e-02, -4.73632812e-02, -4.04296875e-01,  3.37890625e-01,\n",
       "       -2.43164062e-01,  1.77734375e-01, -5.39550781e-02,  3.19824219e-02,\n",
       "        4.19921875e-02,  2.83203125e-01, -6.78710938e-02,  2.95410156e-02,\n",
       "       -1.87500000e-01,  1.03027344e-01, -2.13623047e-02,  2.81250000e-01,\n",
       "        2.94189453e-02,  2.63671875e-01, -2.29492188e-02,  9.03320312e-02,\n",
       "       -4.66796875e-01, -4.95605469e-02, -1.14257812e-01,  2.09960938e-01,\n",
       "        6.29882812e-02,  1.88476562e-01,  4.61425781e-02,  1.94335938e-01,\n",
       "       -9.37500000e-02, -1.43554688e-01, -1.59179688e-01, -1.26953125e-01,\n",
       "       -1.60156250e-01,  1.83593750e-01, -1.95312500e-03, -6.00585938e-02,\n",
       "       -3.24707031e-02,  1.12792969e-01, -1.80664062e-02, -4.73632812e-02,\n",
       "       -2.08007812e-01, -1.06933594e-01,  2.39257812e-02, -1.96289062e-01,\n",
       "       -1.12304688e-01, -6.54296875e-02,  1.39648438e-01, -3.05175781e-02,\n",
       "       -2.44140625e-02, -1.24359131e-03,  6.54296875e-02,  4.02832031e-02,\n",
       "       -2.92968750e-02,  3.73535156e-02, -8.60595703e-03, -2.12402344e-02,\n",
       "       -1.98242188e-01,  2.73437500e-02, -1.28906250e-01,  2.88085938e-02,\n",
       "        5.41992188e-02,  1.95312500e-01,  1.91650391e-02, -5.51757812e-02,\n",
       "        1.47094727e-02,  1.41601562e-02,  1.83593750e-01,  9.08203125e-02,\n",
       "        2.83203125e-02,  4.76074219e-02,  8.17871094e-03, -4.37011719e-02,\n",
       "       -1.94335938e-01,  5.07812500e-02,  1.62353516e-02, -1.51367188e-02,\n",
       "        2.34375000e-01,  1.02050781e-01, -3.49121094e-02,  1.52587891e-03,\n",
       "       -1.29882812e-01,  2.22167969e-02, -1.31835938e-01, -1.75781250e-01,\n",
       "       -6.59179688e-02,  4.27246094e-02,  1.39770508e-02,  5.81054688e-02,\n",
       "        5.59082031e-02, -7.66601562e-02, -1.00585938e-01, -9.03320312e-02,\n",
       "       -8.69140625e-02,  3.32031250e-02, -3.66210938e-02,  1.68945312e-01,\n",
       "       -6.78710938e-02, -1.68457031e-02, -1.70898438e-01, -2.16796875e-01,\n",
       "       -5.64575195e-03, -7.66601562e-02, -9.13085938e-02,  2.65502930e-03,\n",
       "       -1.00097656e-01, -3.71093750e-02,  4.90722656e-02,  1.62353516e-02,\n",
       "       -8.05664062e-02,  8.85009766e-03,  7.42187500e-02, -1.39648438e-01,\n",
       "       -2.30712891e-02, -1.07421875e-02, -2.03125000e-01, -5.71289062e-02,\n",
       "       -1.64031982e-03, -1.89453125e-01, -1.64794922e-02,  6.59179688e-02,\n",
       "        3.08837891e-02,  3.34472656e-02,  4.22363281e-02, -5.70678711e-03,\n",
       "       -9.39941406e-03,  8.00781250e-02,  7.71484375e-02,  1.55029297e-02,\n",
       "       -8.44726562e-02, -1.79443359e-02, -1.46484375e-01, -4.54101562e-02,\n",
       "       -2.25830078e-02, -3.41796875e-02, -1.57226562e-01, -6.54296875e-02,\n",
       "        4.22363281e-02, -4.93164062e-02, -3.44238281e-02, -7.08007812e-02,\n",
       "       -3.73535156e-02, -9.08203125e-02, -6.17675781e-02,  2.90527344e-02,\n",
       "        3.78417969e-02, -6.29882812e-02, -1.03515625e-01, -1.36718750e-01,\n",
       "        9.66796875e-02,  1.87988281e-02, -1.28906250e-01,  2.77099609e-02,\n",
       "        7.32421875e-02,  4.46777344e-02,  4.85839844e-02, -9.13085938e-02,\n",
       "        5.61523438e-02,  6.73828125e-02,  3.88183594e-02, -3.10058594e-02,\n",
       "       -3.51562500e-02, -2.13867188e-01,  1.18164062e-01,  5.95703125e-02,\n",
       "       -1.53198242e-02,  1.14746094e-01,  1.37695312e-01, -4.71191406e-02,\n",
       "       -5.31005859e-03,  8.44726562e-02,  6.05468750e-02, -1.24511719e-01,\n",
       "       -5.90820312e-02, -1.67968750e-01,  1.23535156e-01, -1.18164062e-01,\n",
       "        4.41894531e-02, -1.33666992e-02,  5.61523438e-02, -2.85156250e-01,\n",
       "       -3.58886719e-02,  7.17773438e-02, -9.22851562e-02,  3.63769531e-02,\n",
       "        1.14746094e-01,  6.83593750e-02, -2.02636719e-02, -1.08398438e-01,\n",
       "       -5.49316406e-02, -2.08984375e-01,  8.30078125e-02,  3.95507812e-02,\n",
       "        8.30078125e-02,  2.31445312e-01,  4.76074219e-03,  3.88183594e-02,\n",
       "       -9.46044922e-03, -5.78613281e-02, -2.88085938e-02, -2.53906250e-02,\n",
       "        1.67968750e-01, -1.31835938e-01,  5.95703125e-02, -1.74804688e-01,\n",
       "        1.31835938e-01, -2.40478516e-02, -9.22851562e-02, -1.61132812e-02,\n",
       "       -2.50244141e-02,  3.73535156e-02,  7.91015625e-02, -4.66918945e-03,\n",
       "        9.42382812e-02,  9.37500000e-02,  1.04003906e-01,  7.47070312e-02,\n",
       "        2.02636719e-02, -5.98144531e-02,  9.27734375e-02,  7.51953125e-02,\n",
       "       -7.51953125e-02,  6.15234375e-02, -2.38037109e-03, -6.13403320e-03,\n",
       "       -2.51464844e-02,  1.01562500e-01,  6.25000000e-02, -4.88281250e-02,\n",
       "       -6.12792969e-02,  2.46582031e-02,  1.85546875e-02, -5.15136719e-02,\n",
       "        3.36914062e-02,  4.93164062e-02, -8.00781250e-02,  4.80957031e-02,\n",
       "       -1.19140625e-01, -1.24511719e-01, -1.44531250e-01,  4.02832031e-02,\n",
       "       -3.29589844e-02, -6.03027344e-02, -1.83105469e-02, -8.64257812e-02,\n",
       "       -3.36914062e-02, -1.32812500e-01,  1.35742188e-01, -7.51953125e-02,\n",
       "       -5.51757812e-02, -2.62451172e-02, -7.61718750e-02,  1.25000000e-01,\n",
       "        4.58984375e-02, -3.08593750e-01,  4.63867188e-02, -1.29882812e-01,\n",
       "       -3.25012207e-03, -1.26342773e-02,  1.36718750e-01,  9.08203125e-02,\n",
       "        1.25976562e-01,  1.03027344e-01,  1.36718750e-01, -7.47070312e-02,\n",
       "        6.98242188e-02,  1.36718750e-01, -1.18164062e-01,  8.78906250e-02,\n",
       "       -3.14941406e-02,  1.36718750e-01, -1.31835938e-01,  1.67968750e-01,\n",
       "        5.76782227e-03,  9.47265625e-02,  1.87988281e-02,  1.48925781e-02,\n",
       "        9.64355469e-03,  1.08886719e-01,  1.52343750e-01, -7.86132812e-02,\n",
       "       -9.57031250e-02,  5.37109375e-02,  6.44531250e-02, -1.00097656e-01,\n",
       "       -3.58886719e-02, -7.76367188e-02,  2.81250000e-01, -1.70898438e-01,\n",
       "       -1.55029297e-02,  6.93359375e-02, -8.20312500e-02, -2.19726562e-01,\n",
       "       -1.31835938e-01,  7.61718750e-02, -1.39648438e-01,  1.97265625e-01,\n",
       "        6.17675781e-02, -1.34765625e-01,  1.56250000e-01, -5.37109375e-02,\n",
       "       -5.73730469e-02, -3.54003906e-02, -1.14746094e-02,  1.09375000e-01,\n",
       "       -2.34375000e-02,  5.05371094e-02, -4.56542969e-02,  4.05273438e-02,\n",
       "        1.20117188e-01, -3.24707031e-02, -1.58203125e-01,  1.09863281e-01,\n",
       "       -4.66308594e-02, -1.45874023e-02, -3.80859375e-02, -5.32226562e-02,\n",
       "       -5.90820312e-02, -6.92749023e-03, -1.29882812e-01, -2.69775391e-02,\n",
       "       -1.09863281e-01, -6.12792969e-02,  9.57031250e-02,  1.36718750e-01]), gt_embedding=array([-2.75390625e-01,  1.35742188e-01, -1.53320312e-01,  1.19628906e-01,\n",
       "       -2.55859375e-01,  7.93457031e-03,  4.63867188e-02, -3.55468750e-01,\n",
       "       -1.14746094e-01,  3.26171875e-01,  5.85937500e-02, -3.32031250e-01,\n",
       "       -3.69140625e-01,  4.32128906e-02,  2.55859375e-01,  1.82617188e-01,\n",
       "       -1.55273438e-01, -1.71875000e-01, -1.12304688e-01, -2.05078125e-01,\n",
       "       -5.32226562e-02, -1.67968750e-01,  3.63281250e-01,  5.05371094e-02,\n",
       "       -4.58984375e-01,  1.92382812e-01, -1.87683105e-03,  6.98242188e-02,\n",
       "        1.54296875e-01, -9.37500000e-02, -1.91650391e-02,  3.39355469e-02,\n",
       "       -1.35742188e-01, -8.93554688e-02, -3.53515625e-01,  2.52685547e-02,\n",
       "       -2.61718750e-01,  2.36328125e-01,  2.71484375e-01,  3.18359375e-01,\n",
       "        8.15429688e-02,  6.78710938e-02,  3.37890625e-01,  6.59179688e-02,\n",
       "        2.02148438e-01,  1.59179688e-01,  2.24609375e-01, -1.21582031e-01,\n",
       "       -2.49023438e-01,  1.95312500e-01, -1.84570312e-01, -1.84570312e-01,\n",
       "        9.13085938e-02,  3.04687500e-01, -2.43164062e-01, -2.79296875e-01,\n",
       "       -3.59375000e-01,  1.51367188e-01,  8.88671875e-02, -2.98828125e-01,\n",
       "        2.62451172e-02,  1.21582031e-01, -1.64062500e-01,  5.61523438e-02,\n",
       "       -2.30468750e-01, -2.46093750e-01,  9.22851562e-02, -3.84765625e-01,\n",
       "       -2.85156250e-01,  3.34472656e-02, -4.39453125e-02,  4.45312500e-01,\n",
       "        4.37011719e-02,  1.53320312e-01, -7.76367188e-02, -4.12109375e-01,\n",
       "        2.11914062e-01,  6.73828125e-02, -2.77343750e-01,  3.41796875e-02,\n",
       "       -4.29687500e-01,  2.79296875e-01, -7.08007812e-02,  4.88281250e-02,\n",
       "        1.15234375e-01,  1.81640625e-01, -8.05664062e-02,  2.71484375e-01,\n",
       "       -1.21582031e-01,  4.68750000e-02,  4.46777344e-02,  2.65625000e-01,\n",
       "       -2.01171875e-01, -3.08593750e-01,  1.47460938e-01,  1.67968750e-01,\n",
       "        1.39648438e-01, -6.88476562e-02,  4.33593750e-01, -1.63085938e-01,\n",
       "       -1.52343750e-01,  4.47265625e-01,  3.47656250e-01, -6.78710938e-02,\n",
       "       -1.35742188e-01, -9.17968750e-02, -3.22265625e-01,  2.07031250e-01,\n",
       "       -1.36108398e-02,  1.00097656e-01,  1.23046875e-01, -2.30468750e-01,\n",
       "        2.04467773e-03,  7.75146484e-03,  1.52343750e-01,  9.71679688e-02,\n",
       "       -1.43554688e-01,  5.67626953e-03, -3.17382812e-02,  3.08593750e-01,\n",
       "       -9.17968750e-02,  9.66796875e-02,  1.38671875e-01,  2.96875000e-01,\n",
       "        2.88085938e-02, -4.00390625e-01, -2.96875000e-01,  6.03027344e-02,\n",
       "       -2.82287598e-04, -2.45361328e-02, -2.46093750e-01, -2.71484375e-01,\n",
       "       -1.04980469e-01, -1.55273438e-01, -7.91015625e-02, -1.36718750e-01,\n",
       "       -2.71484375e-01, -4.94140625e-01,  3.37890625e-01,  4.00390625e-01,\n",
       "        1.10839844e-01, -6.34765625e-02,  2.25585938e-01, -1.87500000e-01,\n",
       "        8.66699219e-03,  7.95898438e-02, -2.27539062e-01, -1.25122070e-02,\n",
       "       -1.30859375e-01, -2.37304688e-01,  2.57812500e-01, -4.92187500e-01,\n",
       "        2.06054688e-01,  1.80664062e-02, -3.30078125e-01, -4.33593750e-01,\n",
       "        5.17578125e-02,  2.69531250e-01, -3.80859375e-01,  2.81250000e-01,\n",
       "       -1.92382812e-01,  2.87109375e-01,  1.38671875e-01, -1.69921875e-01,\n",
       "        1.40625000e-01, -2.06054688e-01, -4.02832031e-02,  1.39648438e-01,\n",
       "        1.24511719e-01,  3.33984375e-01, -2.46093750e-01,  1.70898438e-01,\n",
       "        5.71289062e-02, -4.14062500e-01, -4.29687500e-02, -8.10546875e-02,\n",
       "        4.10156250e-01, -3.45703125e-01,  2.31445312e-01, -3.55468750e-01,\n",
       "       -1.20605469e-01, -9.96093750e-02, -8.93554688e-02,  1.86767578e-02,\n",
       "       -2.67578125e-01, -2.18505859e-02,  1.83105469e-02, -5.93261719e-02,\n",
       "        9.22851562e-02,  1.42578125e-01,  1.99218750e-01, -8.48388672e-03,\n",
       "       -7.51953125e-02, -5.27343750e-01,  3.51562500e-01,  4.02343750e-01,\n",
       "        6.22558594e-03, -3.58886719e-02,  1.04003906e-01,  3.58886719e-02,\n",
       "       -5.00000000e-01,  1.70898438e-01, -2.97851562e-02, -2.77343750e-01,\n",
       "       -4.37011719e-02,  1.34277344e-02,  1.41601562e-01, -2.87109375e-01,\n",
       "       -2.85156250e-01,  2.71484375e-01,  3.61328125e-01,  2.94921875e-01,\n",
       "       -4.21875000e-01, -4.70703125e-01, -5.56640625e-02,  1.26953125e-01,\n",
       "        1.49414062e-01,  1.90429688e-02, -5.68847656e-02,  2.80761719e-02,\n",
       "       -2.91015625e-01, -2.45117188e-01,  2.02148438e-01, -1.33789062e-01,\n",
       "       -1.19140625e-01, -2.83203125e-01, -1.54296875e-01,  2.55859375e-01,\n",
       "        4.35546875e-01, -4.00390625e-01,  1.73828125e-01, -1.73828125e-01,\n",
       "       -1.78710938e-01, -2.08984375e-01,  3.08837891e-02, -9.61914062e-02,\n",
       "        3.02734375e-01,  5.19531250e-01,  2.21252441e-03, -1.67083740e-03,\n",
       "        2.67578125e-01,  2.55859375e-01, -1.86523438e-01,  2.01171875e-01,\n",
       "       -2.18750000e-01,  2.85156250e-01, -1.49414062e-01,  3.80859375e-01,\n",
       "       -2.33398438e-01,  2.53906250e-01, -1.41601562e-01, -2.59765625e-01,\n",
       "       -2.56347656e-02,  1.26342773e-02,  3.69140625e-01, -4.64843750e-01,\n",
       "        4.95605469e-02, -5.34667969e-02,  2.59765625e-01, -2.49023438e-01,\n",
       "       -1.31835938e-01, -1.01074219e-01,  4.08203125e-01, -2.30468750e-01,\n",
       "       -3.14453125e-01, -1.96289062e-01, -4.94140625e-01, -4.10156250e-01,\n",
       "       -1.73828125e-01, -4.98046875e-02, -1.64062500e-01,  7.12890625e-02,\n",
       "        3.41796875e-01, -2.81250000e-01,  4.24194336e-03,  6.39648438e-02,\n",
       "        7.08007812e-02,  1.30859375e-01, -2.07031250e-01,  1.30859375e-01,\n",
       "       -9.13085938e-02,  9.37500000e-02, -2.08007812e-01,  1.82617188e-01,\n",
       "       -2.18750000e-01,  4.32128906e-02, -3.24218750e-01, -1.10839844e-01,\n",
       "        4.06250000e-01, -4.85839844e-02, -5.68847656e-02, -1.43554688e-01,\n",
       "       -8.30078125e-02,  2.94921875e-01, -4.29687500e-01,  7.42187500e-02,\n",
       "       -2.91015625e-01, -1.27929688e-01,  9.47265625e-02,  2.19726562e-01]), protected=array([0.25677854]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_analogy_dataset, gender_subspace = transform_data(word_vectors, analogy_dataset, use_boluk = False)\n",
    "transformed_analogy_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining the dimensionality of the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_dim = transformed_analogy_dataset[0].gt_embedding.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the dimensions of the transformed analogy dataset components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900,)\n",
      "(300,)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "# Testing the transformed analogy dataset\n",
    "assert transformed_analogy_dataset[0].analogy_embeddings.shape[0] == word_embedding_dim * 3\n",
    "assert transformed_analogy_dataset[0].gt_embedding.shape[0] == word_embedding_dim\n",
    "assert transformed_analogy_dataset[0].protected.shape[0] == 1\n",
    "\n",
    "print(transformed_analogy_dataset[0].analogy_embeddings.shape)\n",
    "print(transformed_analogy_dataset[0].gt_embedding.shape)\n",
    "print(transformed_analogy_dataset[0].protected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To run the grid-search and obtain the np.dot(w.T, g) values\n",
    "# learning_rate_list = [2 ** -12, 2 ** -6, 2 ** -3]\n",
    "# adversary_loss_weight_list = [1.0, 0.5, 0.1]\n",
    "\n",
    "# # For the saved model checkpoints pertaining to the word embedding type\n",
    "# word_embedding_type = 'GNews'\n",
    "\n",
    "# # Performing the grid search\n",
    "# utility_functions.grid_search(learning_rate_list, adversary_loss_weight_list, word_embedding_dim, gender_subspace, transformed_analogy_dataset, word_embedding_type, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag to indicate whether you want to use a pre-trained model or you want to train a model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pretrained = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case you want to use a pre-trained model, then specify the type of word embeddings upon which the model was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"GNews\" for Google News (Word2Vec)\n",
    "# \"WikipediaVec\" for Wikipedia2Vec\n",
    "\n",
    "word_embedding_type = \"GNews\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case of using a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pretrained:\n",
    "    \n",
    "    # Obtaining the saved parameters dictionary\n",
    "    pretrained_parameters = utility_functions.obtain_trained_parameters('models')\n",
    "    \n",
    "    # Obtaining the best weights for the non-debiased model\n",
    "    non_debiased_W1 = pretrained_parameters['non_debiased'][word_embedding_type][\"W1\"]\n",
    "    \n",
    "    # Creating an instance of the non-debiased model\n",
    "    non_debiased_model = AdversarialDebiasing(word_embedding_dim = word_embedding_dim, debias = False)\n",
    "    non_debiased_model.W1 = non_debiased_W1\n",
    "    \n",
    "    # Obtaining the best weights for the debiased model\n",
    "    debiased_W1 = pretrained_parameters['debiased'][word_embedding_type][\"W1\"]\n",
    "    \n",
    "    # Creating an instance of the debiased model\n",
    "    debiased_model = AdversarialDebiasing(word_embedding_dim = word_embedding_dim, debias = True)\n",
    "    debiased_model.W1 = debiased_W1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case of using a model trained from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_pretrained:\n",
    "    \n",
    "    # Best parameters from grid search\n",
    "    best_adversary_loss_weight = 0.1\n",
    "    best_learning_rate = 2 ** -6\n",
    "    \n",
    "    # Creating an instance of the non-debiased model\n",
    "    non_debiased_model = AdversarialDebiasing(word_embedding_dim = word_embedding_dim, num_epochs = 500, debias = False, \\\n",
    "                                             gender_subspace = gender_subspace, batch_size = 256, \\\n",
    "                                              adversary_loss_weight = best_adversary_loss_weight, \\\n",
    "                                             classifier_learning_rate = best_learning_rate, \\\n",
    "                                             adversary_learning_rate = best_learning_rate)\n",
    "    \n",
    "    # Fitting the non-debiased model to the training dataset\n",
    "    print(\"****************** Training the non-debiased model ********************\")\n",
    "    non_debiased_model.fit(dataset = transformed_analogy_dataset)\n",
    "    \n",
    "    # Creating an instance of the debiased model\n",
    "    debiased_model = AdversarialDebiasing(word_embedding_dim = word_embedding_dim, num_epochs = 500, debias = True, \\\n",
    "                                             gender_subspace = gender_subspace, batch_size = 256, \\\n",
    "                                              adversary_loss_weight = best_adversary_loss_weight, \\\n",
    "                                             classifier_learning_rate = best_learning_rate, \\\n",
    "                                             adversary_learning_rate = best_learning_rate)\n",
    "    \n",
    "    # Fitting the non-debiased model to the training dataset\n",
    "    print(\"****************** Training the debiased model ********************\")\n",
    "    debiased_model.fit(dataset = transformed_analogy_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-59-30c1f6a6b975>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Handling memory issues\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mword_vectors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit_sims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Predictions of the non debiased model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36minit_sims\u001b[1;34m(self, replace)\u001b[0m\n\u001b[0;32m   1352\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'vectors_norm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1353\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"precomputing L2-norms of word weight vectors\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1354\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_l2_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1356\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrelative_cosine_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwa\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m_l2_norm\u001b[1;34m(m, replace)\u001b[0m\n\u001b[0;32m   2370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2371\u001b[0m     \"\"\"\n\u001b[1;32m-> 2372\u001b[1;33m     \u001b[0mdist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2373\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2374\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[0;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0;32m     35\u001b[0m          initial=_NoValue):\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get sexism traps as word embeddings and words\n",
    "datapoints, test_analogies = qualitative_evaluation.get_datapoints(word_vectors)\n",
    "\n",
    "# Handling memory issues\n",
    "word_vectors.init_sims(replace = True)\n",
    "\n",
    "# Predictions of the non debiased model\n",
    "non_debiased_predictions = qualitative_evaluation.get_non_debiased_predictions([datapoints[0]], word_embedding_dim)\n",
    "non_debiased_most_similar_list = utility_functions.obtain_most_similar(non_debiased_predictions, word_vectors)\n",
    "\n",
    "# Predictions of the debiased model\n",
    "debiased_predictions = debiased_model.predict([datapoints[0]])\n",
    "debiased_most_similar_list = utility_functions.obtain_most_similar(debiased_predictions, word_vectors)\n",
    "\n",
    "# Print similarity results for both models\n",
    "qualitative_evaluation.print_combined_table(non_debiased_most_similar_list, debiased_most_similar_list, test_analogies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
