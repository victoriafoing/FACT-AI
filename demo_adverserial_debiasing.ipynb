{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from tabulate import tabulate\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from adversarial_debiasing import AdversarialDebiasing\n",
    "from load_data import load_data, transform_data, Datapoint\n",
    "\n",
    "from load_vectors import load_pretrained_vectors, load_vectors\n",
    "import config\n",
    "import utility_functions\n",
    "\n",
    "import gensim\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# For autoreloading changes made in other python scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "WORD2VEC_FILE = \"data/GoogleNews-vectors-negative300.bin.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def load_word2vec_format(f, max_num_words=None):\n",
    "          \"\"\"Loads word2vec data from a file handle.\n",
    "\n",
    "          Similar to gensim.models.keyedvectors.KeyedVectors.load_word2vec_format\n",
    "          but takes a file handle as input rather than a filename. This lets us use\n",
    "          GFile. Also only accepts binary files.\n",
    "\n",
    "          Args:\n",
    "            f: file handle\n",
    "            max_num_words: number of words to load. If None, load all.\n",
    "\n",
    "          Returns:\n",
    "            Word2vec data as keyedvectors.EuclideanKeyedVectors.\n",
    "          \"\"\"\n",
    "          header = f.readline()\n",
    "          vocab_size, vector_size = (\n",
    "              int(x) for x in header.rstrip().split())  # throws for invalid file format\n",
    "          print(\"vector_size\",vector_size)\n",
    "          result = gensim.models.keyedvectors.EuclideanKeyedVectors()\n",
    "          num_words = 0\n",
    "          result.vector_size = vector_size\n",
    "          result.syn0 = np.zeros((vocab_size, vector_size), dtype=np.float32)\n",
    "\n",
    "          def add_word(word, weights):\n",
    "            word_id = len(result.vocab)\n",
    "            if word in result.vocab:\n",
    "              print(\"duplicate word '%s', ignoring all but first\", word)\n",
    "              return\n",
    "            result.vocab[word] = gensim.models.keyedvectors.Vocab(\n",
    "                index=word_id, count=vocab_size - word_id)\n",
    "            result.syn0[word_id] = weights\n",
    "            result.index2word.append(word)\n",
    "\n",
    "          if max_num_words and max_num_words < vocab_size:\n",
    "            num_embeddings = max_num_words\n",
    "          else:\n",
    "            num_embeddings = vocab_size\n",
    "          print(\"Loading \",num_embeddings,\" embeddings\")\n",
    "\n",
    "          binary_len = np.dtype(np.float32).itemsize * vector_size\n",
    "          for _ in range(vocab_size):\n",
    "            # mixed text and binary: read text first, then binary\n",
    "            word = []\n",
    "            while True:\n",
    "              ch = f.read(1)\n",
    "              if ch == b' ':\n",
    "                break\n",
    "              if ch == b'':\n",
    "                raise EOFError(\"unexpected end of input; is count incorrect or file otherwise damaged?\")\n",
    "              if ch != b'\\n':  # ignore newlines in front of words (some binary files have)\n",
    "                word.append(ch)\n",
    "            word = gensim.utils.to_unicode(b''.join(word), encoding='utf-8', errors='strict')\n",
    "            weights = np.frombuffer(f.read(binary_len), dtype=np.float32)\n",
    "            add_word(word, weights)\n",
    "            num_words = num_words + 1\n",
    "            if max_num_words and num_words == max_num_words:\n",
    "              break\n",
    "          if result.syn0.shape[0] != len(result.vocab):\n",
    "            print(\n",
    "                \"duplicate words detected, shrinking matrix size from %i to %i\",\n",
    "                result.syn0.shape[0], len(result.vocab))\n",
    "          result.syn0 = np.ascontiguousarray(result.syn0[:len(result.vocab)])\n",
    "          assert (len(result.vocab), vector_size) == result.syn0.shape\n",
    "\n",
    "          print(\"loaded %s matrix\", result.syn0.shape)\n",
    "          return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vector_size 300\n",
      "Loading  2000000  embeddings\n",
      "duplicate words detected, shrinking matrix size from %i to %i 3000000 2000000\n",
      "loaded %s matrix (2000000, 300)\n"
     ]
    }
   ],
   "source": [
    "with gzip.GzipFile(fileobj=open(WORD2VEC_FILE, \"rb\", buffering=0)) as f:\n",
    "    word_vectors = load_word2vec_format(f, max_num_words=2000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/enwiki_20180420_100d.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-771430784512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading the word vectors dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pretrained_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwiki_embedding_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwiki_save_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_glove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/develop/master_develop/FACT-AI/load_vectors.py\u001b[0m in \u001b[0;36mload_pretrained_vectors\u001b[0;34m(data_path, savedir, savefile, use_glove)\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mdata_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mword_vectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msavedir\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msavefile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fact/lib/python3.7/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1496\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1497\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1498\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fact/lib/python3.7/site-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fact/lib/python3.7/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/fact/lib/python3.7/site-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/enwiki_20180420_100d.txt'"
     ]
    }
   ],
   "source": [
    "# Loading the word vectors dictionary\n",
    "word_vectors = load_pretrained_vectors(config.wiki_embedding_data_path, config.save_dir, config.wiki_save_file, config.use_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Raw_Datapoint(x1='Athens', x2='Greece', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bangkok', x2='Thailand', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Beijing', x2='China', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Berlin', x2='Germany', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Bern', x2='Switzerland', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Cairo', x2='Egypt', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Canberra', x2='Australia', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Hanoi', x2='Vietnam', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Havana', x2='Cuba', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Helsinki', x2='Finland', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Islamabad', x2='Pakistan', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Kabul', x2='Afghanistan', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='London', x2='England', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Madrid', x2='Spain', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Moscow', x2='Russia', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Oslo', x2='Norway', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Ottawa', x2='Canada', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Paris', x2='France', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Rome', x2='Italy', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Stockholm', x2='Sweden', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Tokyo', y='Japan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tehran', x2='Iran', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Athens', y='Greece', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Helsinki', y='Finland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Islamabad', y='Pakistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Kabul', y='Afghanistan', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='London', y='England', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Madrid', y='Spain', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Moscow', y='Russia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Oslo', y='Norway', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Ottawa', y='Canada', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Paris', y='France', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Rome', y='Italy', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Stockholm', y='Sweden', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Tokyo', x2='Japan', x3='Tehran', y='Iran', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Accra', y='Ghana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Algiers', y='Algeria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Amman', y='Jordan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Ankara', y='Turkey', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Antananarivo', y='Madagascar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Apia', y='Samoa', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Ashgabat', y='Turkmenistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Asmara', y='Eritrea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Astana', y='Kazakhstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Athens', y='Greece', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Baghdad', y='Iraq', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Baku', y='Azerbaijan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Bamako', y='Mali', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Bangkok', y='Thailand', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Banjul', y='Gambia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Beijing', y='China', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Beirut', y='Lebanon', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Belgrade', y='Serbia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Belmopan', y='Belize', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Berlin', y='Germany', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Bern', y='Switzerland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Bratislava', y='Slovakia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Brussels', y='Belgium', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Bucharest', y='Romania', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Budapest', y='Hungary', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Bujumbura', y='Burundi', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Cairo', y='Egypt', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Canberra', y='Australia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Caracas', y='Venezuela', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Chisinau', y='Moldova', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Conakry', y='Guinea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Copenhagen', y='Denmark', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Dakar', y='Senegal', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Damascus', y='Syria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Dhaka', y='Bangladesh', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Doha', y='Qatar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Dublin', y='Ireland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Abuja', x2='Nigeria', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Algiers', y='Algeria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Amman', y='Jordan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Ankara', y='Turkey', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Antananarivo', y='Madagascar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Apia', y='Samoa', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Ashgabat', y='Turkmenistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Asmara', y='Eritrea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Astana', y='Kazakhstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Athens', y='Greece', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Baghdad', y='Iraq', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Baku', y='Azerbaijan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Bamako', y='Mali', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Bangkok', y='Thailand', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Banjul', y='Gambia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Beijing', y='China', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Beirut', y='Lebanon', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Belgrade', y='Serbia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Belmopan', y='Belize', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Berlin', y='Germany', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Bern', y='Switzerland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Bratislava', y='Slovakia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Brussels', y='Belgium', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Bucharest', y='Romania', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Budapest', y='Hungary', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Bujumbura', y='Burundi', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Cairo', y='Egypt', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Canberra', y='Australia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Caracas', y='Venezuela', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Chisinau', y='Moldova', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Conakry', y='Guinea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Copenhagen', y='Denmark', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Dakar', y='Senegal', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Damascus', y='Syria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Dhaka', y='Bangladesh', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Doha', y='Qatar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Dublin', y='Ireland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Accra', x2='Ghana', x3='Funafuti', y='Tuvalu', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Amman', y='Jordan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Ankara', y='Turkey', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Antananarivo', y='Madagascar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Apia', y='Samoa', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Ashgabat', y='Turkmenistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Asmara', y='Eritrea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Astana', y='Kazakhstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Athens', y='Greece', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Baghdad', y='Iraq', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Baku', y='Azerbaijan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Bamako', y='Mali', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Bangkok', y='Thailand', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Banjul', y='Gambia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Beijing', y='China', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Beirut', y='Lebanon', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Belgrade', y='Serbia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Belmopan', y='Belize', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Berlin', y='Germany', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Bern', y='Switzerland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Bratislava', y='Slovakia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Brussels', y='Belgium', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Bucharest', y='Romania', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Budapest', y='Hungary', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Bujumbura', y='Burundi', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Cairo', y='Egypt', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Canberra', y='Australia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Caracas', y='Venezuela', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Chisinau', y='Moldova', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Conakry', y='Guinea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Copenhagen', y='Denmark', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Dakar', y='Senegal', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Damascus', y='Syria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Dhaka', y='Bangladesh', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Doha', y='Qatar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Dublin', y='Ireland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Funafuti', y='Tuvalu', task='capital-world'),\n",
       " Raw_Datapoint(x1='Algiers', x2='Algeria', x3='Gaborone', y='Botswana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Ankara', y='Turkey', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Antananarivo', y='Madagascar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Apia', y='Samoa', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Ashgabat', y='Turkmenistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Asmara', y='Eritrea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Astana', y='Kazakhstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Athens', y='Greece', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Baghdad', y='Iraq', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Baku', y='Azerbaijan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Bamako', y='Mali', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Bangkok', y='Thailand', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Banjul', y='Gambia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Beijing', y='China', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Beirut', y='Lebanon', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Belgrade', y='Serbia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Belmopan', y='Belize', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Berlin', y='Germany', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Bern', y='Switzerland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Bratislava', y='Slovakia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Brussels', y='Belgium', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Bucharest', y='Romania', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Budapest', y='Hungary', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Bujumbura', y='Burundi', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Cairo', y='Egypt', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Canberra', y='Australia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Caracas', y='Venezuela', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Chisinau', y='Moldova', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Conakry', y='Guinea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Copenhagen', y='Denmark', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Dakar', y='Senegal', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Damascus', y='Syria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Dhaka', y='Bangladesh', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Doha', y='Qatar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Dublin', y='Ireland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Funafuti', y='Tuvalu', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Gaborone', y='Botswana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Amman', x2='Jordan', x3='Georgetown', y='Guyana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Antananarivo', y='Madagascar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Apia', y='Samoa', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Ashgabat', y='Turkmenistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Asmara', y='Eritrea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Astana', y='Kazakhstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Athens', y='Greece', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Baghdad', y='Iraq', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Baku', y='Azerbaijan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Bamako', y='Mali', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Bangkok', y='Thailand', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Banjul', y='Gambia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Beijing', y='China', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Beirut', y='Lebanon', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Belgrade', y='Serbia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Belmopan', y='Belize', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Berlin', y='Germany', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Bern', y='Switzerland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Bratislava', y='Slovakia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Brussels', y='Belgium', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Bucharest', y='Romania', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Budapest', y='Hungary', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Bujumbura', y='Burundi', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Cairo', y='Egypt', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Canberra', y='Australia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Caracas', y='Venezuela', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Chisinau', y='Moldova', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Conakry', y='Guinea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Copenhagen', y='Denmark', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Dakar', y='Senegal', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Damascus', y='Syria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Dhaka', y='Bangladesh', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Doha', y='Qatar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Dublin', y='Ireland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Funafuti', y='Tuvalu', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Gaborone', y='Botswana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Georgetown', y='Guyana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ankara', x2='Turkey', x3='Hanoi', y='Vietnam', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Apia', y='Samoa', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Ashgabat', y='Turkmenistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Asmara', y='Eritrea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Astana', y='Kazakhstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Athens', y='Greece', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Baghdad', y='Iraq', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Baku', y='Azerbaijan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Bamako', y='Mali', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Bangkok', y='Thailand', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Banjul', y='Gambia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Beijing', y='China', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Beirut', y='Lebanon', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Belgrade', y='Serbia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Belmopan', y='Belize', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Berlin', y='Germany', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Bern', y='Switzerland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Bratislava', y='Slovakia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Brussels', y='Belgium', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Bucharest', y='Romania', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Budapest', y='Hungary', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Bujumbura', y='Burundi', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Cairo', y='Egypt', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Canberra', y='Australia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Caracas', y='Venezuela', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Chisinau', y='Moldova', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Conakry', y='Guinea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Copenhagen', y='Denmark', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Dakar', y='Senegal', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Damascus', y='Syria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Dhaka', y='Bangladesh', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Doha', y='Qatar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Dublin', y='Ireland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Funafuti', y='Tuvalu', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Gaborone', y='Botswana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Georgetown', y='Guyana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Hanoi', y='Vietnam', task='capital-world'),\n",
       " Raw_Datapoint(x1='Antananarivo', x2='Madagascar', x3='Harare', y='Zimbabwe', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Ashgabat', y='Turkmenistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Asmara', y='Eritrea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Astana', y='Kazakhstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Athens', y='Greece', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Baghdad', y='Iraq', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Baku', y='Azerbaijan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Bamako', y='Mali', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Bangkok', y='Thailand', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Banjul', y='Gambia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Beijing', y='China', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Beirut', y='Lebanon', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Belgrade', y='Serbia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Belmopan', y='Belize', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Berlin', y='Germany', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Bern', y='Switzerland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Bratislava', y='Slovakia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Brussels', y='Belgium', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Bucharest', y='Romania', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Budapest', y='Hungary', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Bujumbura', y='Burundi', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Cairo', y='Egypt', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Canberra', y='Australia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Caracas', y='Venezuela', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Chisinau', y='Moldova', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Conakry', y='Guinea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Copenhagen', y='Denmark', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Dakar', y='Senegal', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Damascus', y='Syria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Dhaka', y='Bangladesh', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Doha', y='Qatar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Dublin', y='Ireland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Funafuti', y='Tuvalu', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Gaborone', y='Botswana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Georgetown', y='Guyana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Hanoi', y='Vietnam', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Harare', y='Zimbabwe', task='capital-world'),\n",
       " Raw_Datapoint(x1='Apia', x2='Samoa', x3='Havana', y='Cuba', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Asmara', y='Eritrea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Astana', y='Kazakhstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Athens', y='Greece', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Baghdad', y='Iraq', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Baku', y='Azerbaijan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Bamako', y='Mali', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Bangkok', y='Thailand', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Banjul', y='Gambia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Beijing', y='China', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Beirut', y='Lebanon', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Belgrade', y='Serbia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Belmopan', y='Belize', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Berlin', y='Germany', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Bern', y='Switzerland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Bratislava', y='Slovakia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Brussels', y='Belgium', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Bucharest', y='Romania', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Budapest', y='Hungary', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Bujumbura', y='Burundi', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Cairo', y='Egypt', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Canberra', y='Australia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Caracas', y='Venezuela', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Chisinau', y='Moldova', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Conakry', y='Guinea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Copenhagen', y='Denmark', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Dakar', y='Senegal', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Damascus', y='Syria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Dhaka', y='Bangladesh', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Doha', y='Qatar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Dublin', y='Ireland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Funafuti', y='Tuvalu', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Gaborone', y='Botswana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Georgetown', y='Guyana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Hanoi', y='Vietnam', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Harare', y='Zimbabwe', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Havana', y='Cuba', task='capital-world'),\n",
       " Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Helsinki', y='Finland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Astana', y='Kazakhstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Athens', y='Greece', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Baghdad', y='Iraq', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Baku', y='Azerbaijan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Bamako', y='Mali', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Bangkok', y='Thailand', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Banjul', y='Gambia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Beijing', y='China', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Beirut', y='Lebanon', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Belgrade', y='Serbia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Belmopan', y='Belize', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Berlin', y='Germany', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Bern', y='Switzerland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Bratislava', y='Slovakia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Brussels', y='Belgium', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Bucharest', y='Romania', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Budapest', y='Hungary', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Bujumbura', y='Burundi', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Cairo', y='Egypt', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Canberra', y='Australia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Caracas', y='Venezuela', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Chisinau', y='Moldova', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Conakry', y='Guinea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Copenhagen', y='Denmark', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Dakar', y='Senegal', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Damascus', y='Syria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Dhaka', y='Bangladesh', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Doha', y='Qatar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Dublin', y='Ireland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Funafuti', y='Tuvalu', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Gaborone', y='Botswana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Georgetown', y='Guyana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Hanoi', y='Vietnam', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Harare', y='Zimbabwe', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Havana', y='Cuba', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Helsinki', y='Finland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Islamabad', y='Pakistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Athens', y='Greece', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Baghdad', y='Iraq', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Baku', y='Azerbaijan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Bamako', y='Mali', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Bangkok', y='Thailand', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Banjul', y='Gambia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Beijing', y='China', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Beirut', y='Lebanon', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Belgrade', y='Serbia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Belmopan', y='Belize', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Berlin', y='Germany', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Bern', y='Switzerland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Bratislava', y='Slovakia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Brussels', y='Belgium', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Bucharest', y='Romania', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Budapest', y='Hungary', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Bujumbura', y='Burundi', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Cairo', y='Egypt', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Canberra', y='Australia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Caracas', y='Venezuela', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Chisinau', y='Moldova', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Conakry', y='Guinea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Copenhagen', y='Denmark', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Dakar', y='Senegal', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Damascus', y='Syria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Dhaka', y='Bangladesh', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Doha', y='Qatar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Dublin', y='Ireland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Funafuti', y='Tuvalu', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Gaborone', y='Botswana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Georgetown', y='Guyana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Hanoi', y='Vietnam', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Harare', y='Zimbabwe', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Havana', y='Cuba', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Helsinki', y='Finland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Islamabad', y='Pakistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Jakarta', y='Indonesia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Baghdad', y='Iraq', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Baku', y='Azerbaijan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bamako', y='Mali', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bangkok', y='Thailand', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Banjul', y='Gambia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Beijing', y='China', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Beirut', y='Lebanon', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Belgrade', y='Serbia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Belmopan', y='Belize', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Berlin', y='Germany', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bern', y='Switzerland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bratislava', y='Slovakia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Brussels', y='Belgium', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bucharest', y='Romania', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Budapest', y='Hungary', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bujumbura', y='Burundi', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Cairo', y='Egypt', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Canberra', y='Australia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Caracas', y='Venezuela', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Chisinau', y='Moldova', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Conakry', y='Guinea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Copenhagen', y='Denmark', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Dakar', y='Senegal', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Damascus', y='Syria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Dhaka', y='Bangladesh', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Doha', y='Qatar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Dublin', y='Ireland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Funafuti', y='Tuvalu', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Gaborone', y='Botswana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Georgetown', y='Guyana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Hanoi', y='Vietnam', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Harare', y='Zimbabwe', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Havana', y='Cuba', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Helsinki', y='Finland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Islamabad', y='Pakistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Jakarta', y='Indonesia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Kabul', y='Afghanistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Baku', y='Azerbaijan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bamako', y='Mali', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bangkok', y='Thailand', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Banjul', y='Gambia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Beijing', y='China', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Beirut', y='Lebanon', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Belgrade', y='Serbia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Belmopan', y='Belize', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Berlin', y='Germany', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bern', y='Switzerland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bratislava', y='Slovakia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Brussels', y='Belgium', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bucharest', y='Romania', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Budapest', y='Hungary', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bujumbura', y='Burundi', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Cairo', y='Egypt', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Canberra', y='Australia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Caracas', y='Venezuela', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Chisinau', y='Moldova', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Conakry', y='Guinea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Copenhagen', y='Denmark', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Dakar', y='Senegal', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Damascus', y='Syria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Dhaka', y='Bangladesh', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Doha', y='Qatar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Dublin', y='Ireland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Funafuti', y='Tuvalu', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Gaborone', y='Botswana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Georgetown', y='Guyana', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Hanoi', y='Vietnam', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Harare', y='Zimbabwe', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Havana', y='Cuba', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Helsinki', y='Finland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Islamabad', y='Pakistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Jakarta', y='Indonesia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Kabul', y='Afghanistan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Kampala', y='Uganda', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Bamako', y='Mali', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Bangkok', y='Thailand', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Banjul', y='Gambia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Beijing', y='China', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Beirut', y='Lebanon', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Belgrade', y='Serbia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Belmopan', y='Belize', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Berlin', y='Germany', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Bern', y='Switzerland', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Bratislava', y='Slovakia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Brussels', y='Belgium', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Bucharest', y='Romania', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Budapest', y='Hungary', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Bujumbura', y='Burundi', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Cairo', y='Egypt', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Canberra', y='Australia', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Caracas', y='Venezuela', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Chisinau', y='Moldova', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Conakry', y='Guinea', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Copenhagen', y='Denmark', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Dakar', y='Senegal', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Damascus', y='Syria', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Dhaka', y='Bangladesh', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Doha', y='Qatar', task='capital-world'),\n",
       " Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Dublin', y='Ireland', task='capital-world'),\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the google analogies training dataset:\n",
    "analogy_dataset = load_data()\n",
    "analogy_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the data such that it includes the embeddings of the words in consideration\n",
    "transformed_analogy_dataset, gender_subspace = transform_data(word_vectors, analogy_dataset, use_boluk = False)\n",
    "word_embedding_dim = transformed_analogy_dataset[0].gt_embedding.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900,)\n",
      "(300,)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "# Testing the transformed analogy dataset\n",
    "print(transformed_analogy_dataset[0].analogy_embeddings.shape)\n",
    "print(transformed_analogy_dataset[0].gt_embedding.shape)\n",
    "print(transformed_analogy_dataset[0].protected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/50] Running epoch\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'quit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7ac44a84bd4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mgender_subspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgender_subspace\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m )\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mnon_debiased_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransformed_analogy_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/develop/master_develop/FACT-AI/adversarial_debiasing.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0mshuffled_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffled_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madversary_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_train_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mpredictor_lr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/develop/master_develop/FACT-AI/adversarial_debiasing.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, dataset, shuffled_ids, classifier_optimizer, adversary_optimizer, num_train_samples, epoch)\u001b[0m\n\u001b[1;32m    192\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madversary_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0mquit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;31m# Optimize the Classifier with the gradients of the classifier and adversary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'quit' is not defined"
     ]
    }
   ],
   "source": [
    "word_embedding_dim = transformed_analogy_dataset[0].gt_embedding.shape[0]\n",
    "# Training the variant of the model without debiasing\n",
    "non_debiased_model = AdversarialDebiasing(\n",
    "    word_embedding_dim=word_embedding_dim,\n",
    "    debias=False,\n",
    "    num_epochs=50,\n",
    "    gender_subspace=gender_subspace\n",
    ")\n",
    "non_debiased_model.fit(dataset=transformed_analogy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.09051673]]\n"
     ]
    }
   ],
   "source": [
    "W1 = non_debiased_model.get_model_weights()\n",
    "print(np.dot(W1.detach().numpy().T,gender_subspace.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 300)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gender_subspace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/500] Running epoch\n",
      "epoch 0; iter: 0; batch classifier loss: 0.040327; batch adversarial loss: 0.030493\n",
      "epoch 0; iter: 10; batch classifier loss: 0.039214; batch adversarial loss: 0.034037\n",
      "epoch 0; iter: 20; batch classifier loss: 0.036291; batch adversarial loss: 0.075652\n",
      "epoch 0; iter: 30; batch classifier loss: 0.148507; batch adversarial loss: 2.361297\n",
      "epoch 0; iter: 40; batch classifier loss: 0.535863; batch adversarial loss: 0.888197\n",
      "epoch 0; iter: 50; batch classifier loss: 0.183061; batch adversarial loss: 0.332109\n",
      "||w||: 2.174010753631592\n",
      "||w2||: 2.007164239883423\n",
      "w.T g: [[0.27487676]]\n",
      "[1/500] Running epoch\n",
      "epoch 1; iter: 0; batch classifier loss: 0.109137; batch adversarial loss: 0.395982\n",
      "epoch 1; iter: 10; batch classifier loss: 0.059609; batch adversarial loss: 2.302217\n",
      "epoch 1; iter: 20; batch classifier loss: 0.461144; batch adversarial loss: 0.860398\n",
      "epoch 1; iter: 30; batch classifier loss: 1.724663; batch adversarial loss: 0.478470\n",
      "epoch 1; iter: 40; batch classifier loss: 1.064442; batch adversarial loss: 1.647411\n",
      "epoch 1; iter: 50; batch classifier loss: 0.463111; batch adversarial loss: 0.391502\n",
      "[2/500] Running epoch\n",
      "epoch 2; iter: 0; batch classifier loss: 0.270039; batch adversarial loss: 0.469396\n",
      "epoch 2; iter: 10; batch classifier loss: 0.133182; batch adversarial loss: 0.908262\n",
      "epoch 2; iter: 20; batch classifier loss: 0.060235; batch adversarial loss: 0.694533\n",
      "epoch 2; iter: 30; batch classifier loss: 0.051467; batch adversarial loss: 0.639924\n",
      "epoch 2; iter: 40; batch classifier loss: 0.047085; batch adversarial loss: 0.484592\n",
      "epoch 2; iter: 50; batch classifier loss: 0.054266; batch adversarial loss: 0.551679\n",
      "[3/500] Running epoch\n",
      "epoch 3; iter: 0; batch classifier loss: 0.050514; batch adversarial loss: 0.486023\n",
      "epoch 3; iter: 10; batch classifier loss: 0.054827; batch adversarial loss: 0.508933\n",
      "epoch 3; iter: 20; batch classifier loss: 0.055554; batch adversarial loss: 0.492634\n",
      "epoch 3; iter: 30; batch classifier loss: 0.059190; batch adversarial loss: 0.521415\n",
      "epoch 3; iter: 40; batch classifier loss: 0.056226; batch adversarial loss: 0.324454\n",
      "epoch 3; iter: 50; batch classifier loss: 0.057970; batch adversarial loss: 0.311468\n",
      "[4/500] Running epoch\n",
      "epoch 4; iter: 0; batch classifier loss: 0.057845; batch adversarial loss: 0.263226\n",
      "epoch 4; iter: 10; batch classifier loss: 0.054125; batch adversarial loss: 0.257292\n",
      "epoch 4; iter: 20; batch classifier loss: 0.049999; batch adversarial loss: 0.240357\n",
      "epoch 4; iter: 30; batch classifier loss: 0.048770; batch adversarial loss: 0.224838\n",
      "epoch 4; iter: 40; batch classifier loss: 0.049551; batch adversarial loss: 0.238573\n",
      "epoch 4; iter: 50; batch classifier loss: 0.049573; batch adversarial loss: 0.206429\n",
      "[5/500] Running epoch\n",
      "epoch 5; iter: 0; batch classifier loss: 0.043866; batch adversarial loss: 0.206626\n",
      "epoch 5; iter: 10; batch classifier loss: 0.044773; batch adversarial loss: 0.197164\n",
      "epoch 5; iter: 20; batch classifier loss: 0.043707; batch adversarial loss: 0.245477\n",
      "epoch 5; iter: 30; batch classifier loss: 0.045131; batch adversarial loss: 0.211484\n",
      "epoch 5; iter: 40; batch classifier loss: 0.044681; batch adversarial loss: 0.178095\n",
      "epoch 5; iter: 50; batch classifier loss: 0.040986; batch adversarial loss: 0.144925\n",
      "[6/500] Running epoch\n",
      "epoch 6; iter: 0; batch classifier loss: 0.041229; batch adversarial loss: 0.176402\n",
      "epoch 6; iter: 10; batch classifier loss: 0.044203; batch adversarial loss: 0.164954\n",
      "epoch 6; iter: 20; batch classifier loss: 0.044543; batch adversarial loss: 0.203562\n",
      "epoch 6; iter: 30; batch classifier loss: 0.042408; batch adversarial loss: 0.164642\n",
      "epoch 6; iter: 40; batch classifier loss: 0.041455; batch adversarial loss: 0.137143\n",
      "epoch 6; iter: 50; batch classifier loss: 0.040185; batch adversarial loss: 0.140990\n",
      "[7/500] Running epoch\n",
      "epoch 7; iter: 0; batch classifier loss: 0.041533; batch adversarial loss: 0.155621\n",
      "epoch 7; iter: 10; batch classifier loss: 0.042484; batch adversarial loss: 0.162911\n",
      "epoch 7; iter: 20; batch classifier loss: 0.040171; batch adversarial loss: 0.121248\n",
      "epoch 7; iter: 30; batch classifier loss: 0.041444; batch adversarial loss: 0.142337\n",
      "epoch 7; iter: 40; batch classifier loss: 0.040153; batch adversarial loss: 0.141623\n",
      "epoch 7; iter: 50; batch classifier loss: 0.038997; batch adversarial loss: 0.105570\n",
      "[8/500] Running epoch\n",
      "epoch 8; iter: 0; batch classifier loss: 0.041373; batch adversarial loss: 0.118418\n",
      "epoch 8; iter: 10; batch classifier loss: 0.042635; batch adversarial loss: 0.119290\n",
      "epoch 8; iter: 20; batch classifier loss: 0.041585; batch adversarial loss: 0.137527\n",
      "epoch 8; iter: 30; batch classifier loss: 0.039476; batch adversarial loss: 0.114133\n",
      "epoch 8; iter: 40; batch classifier loss: 0.041708; batch adversarial loss: 0.105291\n",
      "epoch 8; iter: 50; batch classifier loss: 0.039255; batch adversarial loss: 0.103138\n",
      "[9/500] Running epoch\n",
      "epoch 9; iter: 0; batch classifier loss: 0.041646; batch adversarial loss: 0.107116\n",
      "epoch 9; iter: 10; batch classifier loss: 0.039800; batch adversarial loss: 0.110602\n",
      "epoch 9; iter: 20; batch classifier loss: 0.038368; batch adversarial loss: 0.097328\n",
      "epoch 9; iter: 30; batch classifier loss: 0.038288; batch adversarial loss: 0.094710\n",
      "epoch 9; iter: 40; batch classifier loss: 0.038405; batch adversarial loss: 0.099568\n",
      "epoch 9; iter: 50; batch classifier loss: 0.037691; batch adversarial loss: 0.096039\n",
      "[10/500] Running epoch\n",
      "epoch 10; iter: 0; batch classifier loss: 0.040268; batch adversarial loss: 0.105070\n",
      "epoch 10; iter: 10; batch classifier loss: 0.042674; batch adversarial loss: 0.089480\n",
      "epoch 10; iter: 20; batch classifier loss: 0.039953; batch adversarial loss: 0.098352\n",
      "epoch 10; iter: 30; batch classifier loss: 0.040657; batch adversarial loss: 0.085991\n",
      "epoch 10; iter: 40; batch classifier loss: 0.039089; batch adversarial loss: 0.081639\n",
      "epoch 10; iter: 50; batch classifier loss: 0.040659; batch adversarial loss: 0.094417\n",
      "||w||: 2.2834439277648926\n",
      "||w2||: 1.5221236944198608\n",
      "w.T g: [[-0.03141606]]\n",
      "[11/500] Running epoch\n",
      "epoch 11; iter: 0; batch classifier loss: 0.041043; batch adversarial loss: 0.090067\n",
      "epoch 11; iter: 10; batch classifier loss: 0.040423; batch adversarial loss: 0.086144\n",
      "epoch 11; iter: 20; batch classifier loss: 0.039056; batch adversarial loss: 0.092325\n",
      "epoch 11; iter: 30; batch classifier loss: 0.039187; batch adversarial loss: 0.081915\n",
      "epoch 11; iter: 40; batch classifier loss: 0.038451; batch adversarial loss: 0.074327\n",
      "epoch 11; iter: 50; batch classifier loss: 0.038961; batch adversarial loss: 0.071422\n",
      "[12/500] Running epoch\n",
      "epoch 12; iter: 0; batch classifier loss: 0.039633; batch adversarial loss: 0.081420\n",
      "epoch 12; iter: 10; batch classifier loss: 0.040627; batch adversarial loss: 0.080759\n",
      "epoch 12; iter: 20; batch classifier loss: 0.038708; batch adversarial loss: 0.082109\n",
      "epoch 12; iter: 30; batch classifier loss: 0.040072; batch adversarial loss: 0.074903\n",
      "epoch 12; iter: 40; batch classifier loss: 0.038572; batch adversarial loss: 0.080988\n",
      "epoch 12; iter: 50; batch classifier loss: 0.039360; batch adversarial loss: 0.074004\n",
      "[13/500] Running epoch\n",
      "epoch 13; iter: 0; batch classifier loss: 0.038159; batch adversarial loss: 0.075594\n",
      "epoch 13; iter: 10; batch classifier loss: 0.037873; batch adversarial loss: 0.076403\n",
      "epoch 13; iter: 20; batch classifier loss: 0.039706; batch adversarial loss: 0.064127\n",
      "epoch 13; iter: 30; batch classifier loss: 0.039041; batch adversarial loss: 0.075450\n",
      "epoch 13; iter: 40; batch classifier loss: 0.039334; batch adversarial loss: 0.066737\n",
      "epoch 13; iter: 50; batch classifier loss: 0.038261; batch adversarial loss: 0.074536\n",
      "[14/500] Running epoch\n",
      "epoch 14; iter: 0; batch classifier loss: 0.037578; batch adversarial loss: 0.065438\n",
      "epoch 14; iter: 10; batch classifier loss: 0.036890; batch adversarial loss: 0.063168\n",
      "epoch 14; iter: 20; batch classifier loss: 0.038754; batch adversarial loss: 0.080519\n",
      "epoch 14; iter: 30; batch classifier loss: 0.037476; batch adversarial loss: 0.058516\n",
      "epoch 14; iter: 40; batch classifier loss: 0.039331; batch adversarial loss: 0.065908\n",
      "epoch 14; iter: 50; batch classifier loss: 0.038741; batch adversarial loss: 0.058734\n",
      "[15/500] Running epoch\n",
      "epoch 15; iter: 0; batch classifier loss: 0.039616; batch adversarial loss: 0.058498\n",
      "epoch 15; iter: 10; batch classifier loss: 0.038382; batch adversarial loss: 0.057450\n",
      "epoch 15; iter: 20; batch classifier loss: 0.037708; batch adversarial loss: 0.060327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15; iter: 30; batch classifier loss: 0.037273; batch adversarial loss: 0.053396\n",
      "epoch 15; iter: 40; batch classifier loss: 0.037678; batch adversarial loss: 0.059625\n",
      "epoch 15; iter: 50; batch classifier loss: 0.037276; batch adversarial loss: 0.055768\n",
      "[16/500] Running epoch\n",
      "epoch 16; iter: 0; batch classifier loss: 0.039109; batch adversarial loss: 0.046397\n",
      "epoch 16; iter: 10; batch classifier loss: 0.040425; batch adversarial loss: 0.050679\n",
      "epoch 16; iter: 20; batch classifier loss: 0.037717; batch adversarial loss: 0.051692\n",
      "epoch 16; iter: 30; batch classifier loss: 0.037383; batch adversarial loss: 0.067998\n",
      "epoch 16; iter: 40; batch classifier loss: 0.037204; batch adversarial loss: 0.051346\n",
      "epoch 16; iter: 50; batch classifier loss: 0.038242; batch adversarial loss: 0.053789\n",
      "[17/500] Running epoch\n",
      "epoch 17; iter: 0; batch classifier loss: 0.037816; batch adversarial loss: 0.047932\n",
      "epoch 17; iter: 10; batch classifier loss: 0.037960; batch adversarial loss: 0.057060\n",
      "epoch 17; iter: 20; batch classifier loss: 0.035575; batch adversarial loss: 0.055937\n",
      "epoch 17; iter: 30; batch classifier loss: 0.036271; batch adversarial loss: 0.056041\n",
      "epoch 17; iter: 40; batch classifier loss: 0.036271; batch adversarial loss: 0.055483\n",
      "epoch 17; iter: 50; batch classifier loss: 0.036557; batch adversarial loss: 0.051936\n",
      "[18/500] Running epoch\n",
      "epoch 18; iter: 0; batch classifier loss: 0.037912; batch adversarial loss: 0.058177\n",
      "epoch 18; iter: 10; batch classifier loss: 0.038291; batch adversarial loss: 0.048440\n",
      "epoch 18; iter: 20; batch classifier loss: 0.039300; batch adversarial loss: 0.047800\n",
      "epoch 18; iter: 30; batch classifier loss: 0.037779; batch adversarial loss: 0.055437\n",
      "epoch 18; iter: 40; batch classifier loss: 0.037693; batch adversarial loss: 0.051855\n",
      "epoch 18; iter: 50; batch classifier loss: 0.037717; batch adversarial loss: 0.051849\n",
      "[19/500] Running epoch\n",
      "epoch 19; iter: 0; batch classifier loss: 0.036900; batch adversarial loss: 0.049999\n",
      "epoch 19; iter: 10; batch classifier loss: 0.039631; batch adversarial loss: 0.067640\n",
      "epoch 19; iter: 20; batch classifier loss: 0.038181; batch adversarial loss: 0.041535\n",
      "epoch 19; iter: 30; batch classifier loss: 0.038730; batch adversarial loss: 0.047961\n",
      "epoch 19; iter: 40; batch classifier loss: 0.036042; batch adversarial loss: 0.045403\n",
      "epoch 19; iter: 50; batch classifier loss: 0.038810; batch adversarial loss: 0.047597\n",
      "[20/500] Running epoch\n",
      "epoch 20; iter: 0; batch classifier loss: 0.041189; batch adversarial loss: 0.051635\n",
      "epoch 20; iter: 10; batch classifier loss: 0.037011; batch adversarial loss: 0.049437\n",
      "epoch 20; iter: 20; batch classifier loss: 0.036777; batch adversarial loss: 0.048841\n",
      "epoch 20; iter: 30; batch classifier loss: 0.038077; batch adversarial loss: 0.044939\n",
      "epoch 20; iter: 40; batch classifier loss: 0.036588; batch adversarial loss: 0.049157\n",
      "epoch 20; iter: 50; batch classifier loss: 0.037035; batch adversarial loss: 0.048854\n",
      "||w||: 1.815954566001892\n",
      "||w2||: 1.118347406387329\n",
      "w.T g: [[-0.03501081]]\n",
      "[21/500] Running epoch\n",
      "epoch 21; iter: 0; batch classifier loss: 0.037645; batch adversarial loss: 0.047771\n",
      "epoch 21; iter: 10; batch classifier loss: 0.036762; batch adversarial loss: 0.045378\n",
      "epoch 21; iter: 20; batch classifier loss: 0.036903; batch adversarial loss: 0.043257\n",
      "epoch 21; iter: 30; batch classifier loss: 0.035508; batch adversarial loss: 0.040649\n",
      "epoch 21; iter: 40; batch classifier loss: 0.035565; batch adversarial loss: 0.047793\n",
      "epoch 21; iter: 50; batch classifier loss: 0.037565; batch adversarial loss: 0.048066\n",
      "[22/500] Running epoch\n",
      "epoch 22; iter: 0; batch classifier loss: 0.039776; batch adversarial loss: 0.055225\n",
      "epoch 22; iter: 10; batch classifier loss: 0.039095; batch adversarial loss: 0.047870\n",
      "epoch 22; iter: 20; batch classifier loss: 0.039052; batch adversarial loss: 0.050512\n",
      "epoch 22; iter: 30; batch classifier loss: 0.038256; batch adversarial loss: 0.044110\n",
      "epoch 22; iter: 40; batch classifier loss: 0.038916; batch adversarial loss: 0.055593\n",
      "epoch 22; iter: 50; batch classifier loss: 0.039495; batch adversarial loss: 0.053380\n",
      "[23/500] Running epoch\n",
      "epoch 23; iter: 0; batch classifier loss: 0.039578; batch adversarial loss: 0.042687\n",
      "epoch 23; iter: 10; batch classifier loss: 0.036745; batch adversarial loss: 0.041869\n",
      "epoch 23; iter: 20; batch classifier loss: 0.038599; batch adversarial loss: 0.042554\n",
      "epoch 23; iter: 30; batch classifier loss: 0.037176; batch adversarial loss: 0.042450\n",
      "epoch 23; iter: 40; batch classifier loss: 0.037975; batch adversarial loss: 0.039625\n",
      "epoch 23; iter: 50; batch classifier loss: 0.036853; batch adversarial loss: 0.050594\n",
      "[24/500] Running epoch\n",
      "epoch 24; iter: 0; batch classifier loss: 0.037748; batch adversarial loss: 0.037895\n",
      "epoch 24; iter: 10; batch classifier loss: 0.039432; batch adversarial loss: 0.037472\n",
      "epoch 24; iter: 20; batch classifier loss: 0.037784; batch adversarial loss: 0.039172\n",
      "epoch 24; iter: 30; batch classifier loss: 0.037009; batch adversarial loss: 0.038727\n",
      "epoch 24; iter: 40; batch classifier loss: 0.034450; batch adversarial loss: 0.038712\n",
      "epoch 24; iter: 50; batch classifier loss: 0.036203; batch adversarial loss: 0.038463\n",
      "[25/500] Running epoch\n",
      "epoch 25; iter: 0; batch classifier loss: 0.036954; batch adversarial loss: 0.043213\n",
      "epoch 25; iter: 10; batch classifier loss: 0.040664; batch adversarial loss: 0.041613\n",
      "epoch 25; iter: 20; batch classifier loss: 0.039224; batch adversarial loss: 0.037624\n",
      "epoch 25; iter: 30; batch classifier loss: 0.038689; batch adversarial loss: 0.043077\n",
      "epoch 25; iter: 40; batch classifier loss: 0.036511; batch adversarial loss: 0.037173\n",
      "epoch 25; iter: 50; batch classifier loss: 0.036251; batch adversarial loss: 0.036615\n",
      "[26/500] Running epoch\n",
      "epoch 26; iter: 0; batch classifier loss: 0.035598; batch adversarial loss: 0.033377\n",
      "epoch 26; iter: 10; batch classifier loss: 0.037223; batch adversarial loss: 0.031366\n",
      "epoch 26; iter: 20; batch classifier loss: 0.037357; batch adversarial loss: 0.037993\n",
      "epoch 26; iter: 30; batch classifier loss: 0.037484; batch adversarial loss: 0.039857\n",
      "epoch 26; iter: 40; batch classifier loss: 0.037266; batch adversarial loss: 0.042778\n",
      "epoch 26; iter: 50; batch classifier loss: 0.037672; batch adversarial loss: 0.042807\n",
      "[27/500] Running epoch\n",
      "epoch 27; iter: 0; batch classifier loss: 0.038594; batch adversarial loss: 0.041244\n",
      "epoch 27; iter: 10; batch classifier loss: 0.038182; batch adversarial loss: 0.032253\n",
      "epoch 27; iter: 20; batch classifier loss: 0.035361; batch adversarial loss: 0.035805\n",
      "epoch 27; iter: 30; batch classifier loss: 0.038176; batch adversarial loss: 0.040206\n",
      "epoch 27; iter: 40; batch classifier loss: 0.038879; batch adversarial loss: 0.038064\n",
      "epoch 27; iter: 50; batch classifier loss: 0.038318; batch adversarial loss: 0.034367\n",
      "[28/500] Running epoch\n",
      "epoch 28; iter: 0; batch classifier loss: 0.037114; batch adversarial loss: 0.027850\n",
      "epoch 28; iter: 10; batch classifier loss: 0.038783; batch adversarial loss: 0.035319\n",
      "epoch 28; iter: 20; batch classifier loss: 0.039547; batch adversarial loss: 0.036264\n",
      "epoch 28; iter: 30; batch classifier loss: 0.040052; batch adversarial loss: 0.040593\n",
      "epoch 28; iter: 40; batch classifier loss: 0.036237; batch adversarial loss: 0.035861\n",
      "epoch 28; iter: 50; batch classifier loss: 0.037057; batch adversarial loss: 0.029155\n",
      "[29/500] Running epoch\n",
      "epoch 29; iter: 0; batch classifier loss: 0.038044; batch adversarial loss: 0.034937\n",
      "epoch 29; iter: 10; batch classifier loss: 0.036338; batch adversarial loss: 0.032743\n",
      "epoch 29; iter: 20; batch classifier loss: 0.040000; batch adversarial loss: 0.034932\n",
      "epoch 29; iter: 30; batch classifier loss: 0.037394; batch adversarial loss: 0.029696\n",
      "epoch 29; iter: 40; batch classifier loss: 0.036769; batch adversarial loss: 0.031038\n",
      "epoch 29; iter: 50; batch classifier loss: 0.036674; batch adversarial loss: 0.031650\n",
      "[30/500] Running epoch\n",
      "epoch 30; iter: 0; batch classifier loss: 0.037098; batch adversarial loss: 0.036673\n",
      "epoch 30; iter: 10; batch classifier loss: 0.036265; batch adversarial loss: 0.031183\n",
      "epoch 30; iter: 20; batch classifier loss: 0.037578; batch adversarial loss: 0.037830\n",
      "epoch 30; iter: 30; batch classifier loss: 0.040057; batch adversarial loss: 0.033316\n",
      "epoch 30; iter: 40; batch classifier loss: 0.038362; batch adversarial loss: 0.035397\n",
      "epoch 30; iter: 50; batch classifier loss: 0.037406; batch adversarial loss: 0.034617\n",
      "||w||: 1.6200439929962158\n",
      "||w2||: 0.908297598361969\n",
      "w.T g: [[0.01888472]]\n",
      "[31/500] Running epoch\n",
      "epoch 31; iter: 0; batch classifier loss: 0.035730; batch adversarial loss: 0.027872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31; iter: 10; batch classifier loss: 0.038582; batch adversarial loss: 0.037158\n",
      "epoch 31; iter: 20; batch classifier loss: 0.037240; batch adversarial loss: 0.038853\n",
      "epoch 31; iter: 30; batch classifier loss: 0.041650; batch adversarial loss: 0.036140\n",
      "epoch 31; iter: 40; batch classifier loss: 0.039817; batch adversarial loss: 0.031727\n",
      "epoch 31; iter: 50; batch classifier loss: 0.037454; batch adversarial loss: 0.028943\n",
      "[32/500] Running epoch\n",
      "epoch 32; iter: 0; batch classifier loss: 0.037247; batch adversarial loss: 0.028948\n",
      "epoch 32; iter: 10; batch classifier loss: 0.037336; batch adversarial loss: 0.038201\n",
      "epoch 32; iter: 20; batch classifier loss: 0.037989; batch adversarial loss: 0.029963\n",
      "epoch 32; iter: 30; batch classifier loss: 0.037868; batch adversarial loss: 0.028966\n",
      "epoch 32; iter: 40; batch classifier loss: 0.037890; batch adversarial loss: 0.033809\n",
      "epoch 32; iter: 50; batch classifier loss: 0.037136; batch adversarial loss: 0.026785\n",
      "[33/500] Running epoch\n",
      "epoch 33; iter: 0; batch classifier loss: 0.037097; batch adversarial loss: 0.032583\n",
      "epoch 33; iter: 10; batch classifier loss: 0.036754; batch adversarial loss: 0.029345\n",
      "epoch 33; iter: 20; batch classifier loss: 0.040969; batch adversarial loss: 0.033259\n",
      "epoch 33; iter: 30; batch classifier loss: 0.036690; batch adversarial loss: 0.030755\n",
      "epoch 33; iter: 40; batch classifier loss: 0.037886; batch adversarial loss: 0.030964\n",
      "epoch 33; iter: 50; batch classifier loss: 0.039756; batch adversarial loss: 0.028294\n",
      "[34/500] Running epoch\n",
      "epoch 34; iter: 0; batch classifier loss: 0.037053; batch adversarial loss: 0.031936\n",
      "epoch 34; iter: 10; batch classifier loss: 0.035742; batch adversarial loss: 0.032522\n",
      "epoch 34; iter: 20; batch classifier loss: 0.037620; batch adversarial loss: 0.032845\n",
      "epoch 34; iter: 30; batch classifier loss: 0.036634; batch adversarial loss: 0.032885\n",
      "epoch 34; iter: 40; batch classifier loss: 0.036663; batch adversarial loss: 0.031418\n",
      "epoch 34; iter: 50; batch classifier loss: 0.037350; batch adversarial loss: 0.031101\n",
      "[35/500] Running epoch\n",
      "epoch 35; iter: 0; batch classifier loss: 0.037461; batch adversarial loss: 0.034322\n",
      "epoch 35; iter: 10; batch classifier loss: 0.038140; batch adversarial loss: 0.028405\n",
      "epoch 35; iter: 20; batch classifier loss: 0.037165; batch adversarial loss: 0.031113\n",
      "epoch 35; iter: 30; batch classifier loss: 0.037532; batch adversarial loss: 0.028472\n",
      "epoch 35; iter: 40; batch classifier loss: 0.034963; batch adversarial loss: 0.027889\n",
      "epoch 35; iter: 50; batch classifier loss: 0.039074; batch adversarial loss: 0.031978\n",
      "[36/500] Running epoch\n",
      "epoch 36; iter: 0; batch classifier loss: 0.036353; batch adversarial loss: 0.029083\n",
      "epoch 36; iter: 10; batch classifier loss: 0.040373; batch adversarial loss: 0.027509\n",
      "epoch 36; iter: 20; batch classifier loss: 0.038298; batch adversarial loss: 0.030912\n",
      "epoch 36; iter: 30; batch classifier loss: 0.039388; batch adversarial loss: 0.026125\n",
      "epoch 36; iter: 40; batch classifier loss: 0.036465; batch adversarial loss: 0.030087\n",
      "epoch 36; iter: 50; batch classifier loss: 0.039658; batch adversarial loss: 0.027403\n",
      "[37/500] Running epoch\n",
      "epoch 37; iter: 0; batch classifier loss: 0.038874; batch adversarial loss: 0.027414\n",
      "epoch 37; iter: 10; batch classifier loss: 0.038486; batch adversarial loss: 0.025543\n",
      "epoch 37; iter: 20; batch classifier loss: 0.040217; batch adversarial loss: 0.033219\n",
      "epoch 37; iter: 30; batch classifier loss: 0.037775; batch adversarial loss: 0.024684\n",
      "epoch 37; iter: 40; batch classifier loss: 0.036658; batch adversarial loss: 0.028034\n",
      "epoch 37; iter: 50; batch classifier loss: 0.038231; batch adversarial loss: 0.027726\n",
      "[38/500] Running epoch\n",
      "epoch 38; iter: 0; batch classifier loss: 0.038377; batch adversarial loss: 0.031382\n",
      "epoch 38; iter: 10; batch classifier loss: 0.038338; batch adversarial loss: 0.026838\n",
      "epoch 38; iter: 20; batch classifier loss: 0.035909; batch adversarial loss: 0.029649\n",
      "epoch 38; iter: 30; batch classifier loss: 0.038967; batch adversarial loss: 0.030955\n",
      "epoch 38; iter: 40; batch classifier loss: 0.036004; batch adversarial loss: 0.027917\n",
      "epoch 38; iter: 50; batch classifier loss: 0.040318; batch adversarial loss: 0.032962\n",
      "[39/500] Running epoch\n",
      "epoch 39; iter: 0; batch classifier loss: 0.039466; batch adversarial loss: 0.025646\n",
      "epoch 39; iter: 10; batch classifier loss: 0.036291; batch adversarial loss: 0.028381\n",
      "epoch 39; iter: 20; batch classifier loss: 0.039092; batch adversarial loss: 0.024809\n",
      "epoch 39; iter: 30; batch classifier loss: 0.036513; batch adversarial loss: 0.030324\n",
      "epoch 39; iter: 40; batch classifier loss: 0.038014; batch adversarial loss: 0.025498\n",
      "epoch 39; iter: 50; batch classifier loss: 0.037092; batch adversarial loss: 0.027375\n",
      "[40/500] Running epoch\n",
      "epoch 40; iter: 0; batch classifier loss: 0.039910; batch adversarial loss: 0.024511\n",
      "epoch 40; iter: 10; batch classifier loss: 0.036447; batch adversarial loss: 0.029021\n",
      "epoch 40; iter: 20; batch classifier loss: 0.039127; batch adversarial loss: 0.028350\n",
      "epoch 40; iter: 30; batch classifier loss: 0.035555; batch adversarial loss: 0.028252\n",
      "epoch 40; iter: 40; batch classifier loss: 0.038404; batch adversarial loss: 0.022907\n",
      "epoch 40; iter: 50; batch classifier loss: 0.038496; batch adversarial loss: 0.026740\n",
      "||w||: 1.535642147064209\n",
      "||w2||: 0.792453408241272\n",
      "w.T g: [[0.08047372]]\n",
      "[41/500] Running epoch\n",
      "epoch 41; iter: 0; batch classifier loss: 0.037794; batch adversarial loss: 0.024222\n",
      "epoch 41; iter: 10; batch classifier loss: 0.038021; batch adversarial loss: 0.030386\n",
      "epoch 41; iter: 20; batch classifier loss: 0.040511; batch adversarial loss: 0.034266\n",
      "epoch 41; iter: 30; batch classifier loss: 0.039057; batch adversarial loss: 0.025400\n",
      "epoch 41; iter: 40; batch classifier loss: 0.036193; batch adversarial loss: 0.027295\n",
      "epoch 41; iter: 50; batch classifier loss: 0.037845; batch adversarial loss: 0.029800\n",
      "[42/500] Running epoch\n",
      "epoch 42; iter: 0; batch classifier loss: 0.038412; batch adversarial loss: 0.025694\n",
      "epoch 42; iter: 10; batch classifier loss: 0.039164; batch adversarial loss: 0.027547\n",
      "epoch 42; iter: 20; batch classifier loss: 0.037660; batch adversarial loss: 0.024313\n",
      "epoch 42; iter: 30; batch classifier loss: 0.035370; batch adversarial loss: 0.025097\n",
      "epoch 42; iter: 40; batch classifier loss: 0.039250; batch adversarial loss: 0.026022\n",
      "epoch 42; iter: 50; batch classifier loss: 0.035415; batch adversarial loss: 0.026771\n",
      "[43/500] Running epoch\n",
      "epoch 43; iter: 0; batch classifier loss: 0.038673; batch adversarial loss: 0.027506\n",
      "epoch 43; iter: 10; batch classifier loss: 0.036435; batch adversarial loss: 0.025442\n",
      "epoch 43; iter: 20; batch classifier loss: 0.037534; batch adversarial loss: 0.024109\n",
      "epoch 43; iter: 30; batch classifier loss: 0.034930; batch adversarial loss: 0.022478\n",
      "epoch 43; iter: 40; batch classifier loss: 0.039280; batch adversarial loss: 0.024926\n",
      "epoch 43; iter: 50; batch classifier loss: 0.039234; batch adversarial loss: 0.027004\n",
      "[44/500] Running epoch\n",
      "epoch 44; iter: 0; batch classifier loss: 0.036863; batch adversarial loss: 0.025122\n",
      "epoch 44; iter: 10; batch classifier loss: 0.036558; batch adversarial loss: 0.024774\n",
      "epoch 44; iter: 20; batch classifier loss: 0.037869; batch adversarial loss: 0.023652\n",
      "epoch 44; iter: 30; batch classifier loss: 0.036211; batch adversarial loss: 0.023188\n",
      "epoch 44; iter: 40; batch classifier loss: 0.038154; batch adversarial loss: 0.022513\n",
      "epoch 44; iter: 50; batch classifier loss: 0.036261; batch adversarial loss: 0.025542\n",
      "[45/500] Running epoch\n",
      "epoch 45; iter: 0; batch classifier loss: 0.037309; batch adversarial loss: 0.028117\n",
      "epoch 45; iter: 10; batch classifier loss: 0.037458; batch adversarial loss: 0.025145\n",
      "epoch 45; iter: 20; batch classifier loss: 0.037267; batch adversarial loss: 0.025078\n",
      "epoch 45; iter: 30; batch classifier loss: 0.037408; batch adversarial loss: 0.022089\n",
      "epoch 45; iter: 40; batch classifier loss: 0.038590; batch adversarial loss: 0.021998\n",
      "epoch 45; iter: 50; batch classifier loss: 0.037324; batch adversarial loss: 0.024786\n",
      "[46/500] Running epoch\n",
      "epoch 46; iter: 0; batch classifier loss: 0.037149; batch adversarial loss: 0.024993\n",
      "epoch 46; iter: 10; batch classifier loss: 0.036337; batch adversarial loss: 0.025417\n",
      "epoch 46; iter: 20; batch classifier loss: 0.037544; batch adversarial loss: 0.027238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46; iter: 30; batch classifier loss: 0.036477; batch adversarial loss: 0.024078\n",
      "epoch 46; iter: 40; batch classifier loss: 0.036915; batch adversarial loss: 0.024886\n",
      "epoch 46; iter: 50; batch classifier loss: 0.036371; batch adversarial loss: 0.024623\n",
      "[47/500] Running epoch\n",
      "epoch 47; iter: 0; batch classifier loss: 0.038069; batch adversarial loss: 0.022509\n",
      "epoch 47; iter: 10; batch classifier loss: 0.037159; batch adversarial loss: 0.021662\n",
      "epoch 47; iter: 20; batch classifier loss: 0.036852; batch adversarial loss: 0.021403\n",
      "epoch 47; iter: 30; batch classifier loss: 0.036001; batch adversarial loss: 0.026396\n",
      "epoch 47; iter: 40; batch classifier loss: 0.037143; batch adversarial loss: 0.024533\n",
      "epoch 47; iter: 50; batch classifier loss: 0.038081; batch adversarial loss: 0.021424\n",
      "[48/500] Running epoch\n",
      "epoch 48; iter: 0; batch classifier loss: 0.038379; batch adversarial loss: 0.023278\n",
      "epoch 48; iter: 10; batch classifier loss: 0.038973; batch adversarial loss: 0.023350\n",
      "epoch 48; iter: 20; batch classifier loss: 0.035985; batch adversarial loss: 0.027426\n",
      "epoch 48; iter: 30; batch classifier loss: 0.037115; batch adversarial loss: 0.028130\n",
      "epoch 48; iter: 40; batch classifier loss: 0.036879; batch adversarial loss: 0.026531\n",
      "epoch 48; iter: 50; batch classifier loss: 0.037700; batch adversarial loss: 0.022056\n",
      "[49/500] Running epoch\n",
      "epoch 49; iter: 0; batch classifier loss: 0.037909; batch adversarial loss: 0.022171\n",
      "epoch 49; iter: 10; batch classifier loss: 0.038113; batch adversarial loss: 0.021649\n",
      "epoch 49; iter: 20; batch classifier loss: 0.038044; batch adversarial loss: 0.025043\n",
      "epoch 49; iter: 30; batch classifier loss: 0.038681; batch adversarial loss: 0.020945\n",
      "epoch 49; iter: 40; batch classifier loss: 0.036608; batch adversarial loss: 0.025585\n",
      "epoch 49; iter: 50; batch classifier loss: 0.039775; batch adversarial loss: 0.029599\n",
      "[50/500] Running epoch\n",
      "epoch 50; iter: 0; batch classifier loss: 0.036615; batch adversarial loss: 0.020658\n",
      "epoch 50; iter: 10; batch classifier loss: 0.036737; batch adversarial loss: 0.019080\n",
      "epoch 50; iter: 20; batch classifier loss: 0.037711; batch adversarial loss: 0.022066\n",
      "epoch 50; iter: 30; batch classifier loss: 0.036284; batch adversarial loss: 0.023861\n",
      "epoch 50; iter: 40; batch classifier loss: 0.036517; batch adversarial loss: 0.026801\n",
      "epoch 50; iter: 50; batch classifier loss: 0.036748; batch adversarial loss: 0.026093\n",
      "||w||: 1.489763617515564\n",
      "||w2||: 0.7285364270210266\n",
      "w.T g: [[0.13242881]]\n",
      "[51/500] Running epoch\n",
      "epoch 51; iter: 0; batch classifier loss: 0.037391; batch adversarial loss: 0.019980\n",
      "epoch 51; iter: 10; batch classifier loss: 0.039639; batch adversarial loss: 0.026843\n",
      "epoch 51; iter: 20; batch classifier loss: 0.037661; batch adversarial loss: 0.031924\n",
      "epoch 51; iter: 30; batch classifier loss: 0.040153; batch adversarial loss: 0.025273\n",
      "epoch 51; iter: 40; batch classifier loss: 0.036680; batch adversarial loss: 0.022271\n",
      "epoch 51; iter: 50; batch classifier loss: 0.038787; batch adversarial loss: 0.021928\n",
      "[52/500] Running epoch\n",
      "epoch 52; iter: 0; batch classifier loss: 0.035647; batch adversarial loss: 0.024720\n",
      "epoch 52; iter: 10; batch classifier loss: 0.036702; batch adversarial loss: 0.019240\n",
      "epoch 52; iter: 20; batch classifier loss: 0.036919; batch adversarial loss: 0.027720\n",
      "epoch 52; iter: 30; batch classifier loss: 0.038466; batch adversarial loss: 0.027288\n",
      "epoch 52; iter: 40; batch classifier loss: 0.040056; batch adversarial loss: 0.029279\n",
      "epoch 52; iter: 50; batch classifier loss: 0.037143; batch adversarial loss: 0.020215\n",
      "[53/500] Running epoch\n",
      "epoch 53; iter: 0; batch classifier loss: 0.037747; batch adversarial loss: 0.020872\n",
      "epoch 53; iter: 10; batch classifier loss: 0.037220; batch adversarial loss: 0.021512\n",
      "epoch 53; iter: 20; batch classifier loss: 0.039211; batch adversarial loss: 0.024750\n",
      "epoch 53; iter: 30; batch classifier loss: 0.038774; batch adversarial loss: 0.026746\n",
      "epoch 53; iter: 40; batch classifier loss: 0.040038; batch adversarial loss: 0.024617\n",
      "epoch 53; iter: 50; batch classifier loss: 0.035918; batch adversarial loss: 0.024341\n",
      "[54/500] Running epoch\n",
      "epoch 54; iter: 0; batch classifier loss: 0.037409; batch adversarial loss: 0.025269\n",
      "epoch 54; iter: 10; batch classifier loss: 0.037339; batch adversarial loss: 0.022695\n",
      "epoch 54; iter: 20; batch classifier loss: 0.037396; batch adversarial loss: 0.020069\n",
      "epoch 54; iter: 30; batch classifier loss: 0.037491; batch adversarial loss: 0.020699\n",
      "epoch 54; iter: 40; batch classifier loss: 0.038161; batch adversarial loss: 0.022464\n",
      "epoch 54; iter: 50; batch classifier loss: 0.036355; batch adversarial loss: 0.023231\n",
      "[55/500] Running epoch\n",
      "epoch 55; iter: 0; batch classifier loss: 0.034043; batch adversarial loss: 0.018569\n",
      "epoch 55; iter: 10; batch classifier loss: 0.038716; batch adversarial loss: 0.024617\n",
      "epoch 55; iter: 20; batch classifier loss: 0.035225; batch adversarial loss: 0.021611\n",
      "epoch 55; iter: 30; batch classifier loss: 0.037302; batch adversarial loss: 0.021888\n",
      "epoch 55; iter: 40; batch classifier loss: 0.039215; batch adversarial loss: 0.021673\n",
      "epoch 55; iter: 50; batch classifier loss: 0.036987; batch adversarial loss: 0.029208\n",
      "[56/500] Running epoch\n",
      "epoch 56; iter: 0; batch classifier loss: 0.036606; batch adversarial loss: 0.022893\n",
      "epoch 56; iter: 10; batch classifier loss: 0.039333; batch adversarial loss: 0.022779\n",
      "epoch 56; iter: 20; batch classifier loss: 0.039265; batch adversarial loss: 0.021438\n",
      "epoch 56; iter: 30; batch classifier loss: 0.040396; batch adversarial loss: 0.023642\n",
      "epoch 56; iter: 40; batch classifier loss: 0.039097; batch adversarial loss: 0.024062\n",
      "epoch 56; iter: 50; batch classifier loss: 0.036935; batch adversarial loss: 0.022816\n",
      "[57/500] Running epoch\n",
      "epoch 57; iter: 0; batch classifier loss: 0.037365; batch adversarial loss: 0.023844\n",
      "epoch 57; iter: 10; batch classifier loss: 0.039258; batch adversarial loss: 0.024927\n",
      "epoch 57; iter: 20; batch classifier loss: 0.039285; batch adversarial loss: 0.024361\n",
      "epoch 57; iter: 30; batch classifier loss: 0.037565; batch adversarial loss: 0.023952\n",
      "epoch 57; iter: 40; batch classifier loss: 0.038293; batch adversarial loss: 0.023539\n",
      "epoch 57; iter: 50; batch classifier loss: 0.037517; batch adversarial loss: 0.021877\n",
      "[58/500] Running epoch\n",
      "epoch 58; iter: 0; batch classifier loss: 0.037161; batch adversarial loss: 0.023441\n",
      "epoch 58; iter: 10; batch classifier loss: 0.037417; batch adversarial loss: 0.023836\n",
      "epoch 58; iter: 20; batch classifier loss: 0.037408; batch adversarial loss: 0.019194\n",
      "epoch 58; iter: 30; batch classifier loss: 0.038430; batch adversarial loss: 0.021493\n",
      "epoch 58; iter: 40; batch classifier loss: 0.039164; batch adversarial loss: 0.024252\n",
      "epoch 58; iter: 50; batch classifier loss: 0.037010; batch adversarial loss: 0.023608\n",
      "[59/500] Running epoch\n",
      "epoch 59; iter: 0; batch classifier loss: 0.036337; batch adversarial loss: 0.022923\n",
      "epoch 59; iter: 10; batch classifier loss: 0.038085; batch adversarial loss: 0.019771\n",
      "epoch 59; iter: 20; batch classifier loss: 0.036914; batch adversarial loss: 0.023182\n",
      "epoch 59; iter: 30; batch classifier loss: 0.037799; batch adversarial loss: 0.025017\n",
      "epoch 59; iter: 40; batch classifier loss: 0.035857; batch adversarial loss: 0.020344\n",
      "epoch 59; iter: 50; batch classifier loss: 0.040076; batch adversarial loss: 0.019240\n",
      "[60/500] Running epoch\n",
      "epoch 60; iter: 0; batch classifier loss: 0.037675; batch adversarial loss: 0.019099\n",
      "epoch 60; iter: 10; batch classifier loss: 0.035838; batch adversarial loss: 0.018480\n",
      "epoch 60; iter: 20; batch classifier loss: 0.036457; batch adversarial loss: 0.022132\n",
      "epoch 60; iter: 30; batch classifier loss: 0.038257; batch adversarial loss: 0.021720\n",
      "epoch 60; iter: 40; batch classifier loss: 0.037740; batch adversarial loss: 0.025626\n",
      "epoch 60; iter: 50; batch classifier loss: 0.038282; batch adversarial loss: 0.023923\n",
      "||w||: 1.4557212591171265\n",
      "||w2||: 0.6934994459152222\n",
      "w.T g: [[0.17216151]]\n",
      "[61/500] Running epoch\n",
      "epoch 61; iter: 0; batch classifier loss: 0.037621; batch adversarial loss: 0.022722\n",
      "epoch 61; iter: 10; batch classifier loss: 0.037396; batch adversarial loss: 0.019870\n",
      "epoch 61; iter: 20; batch classifier loss: 0.037285; batch adversarial loss: 0.020244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61; iter: 30; batch classifier loss: 0.039215; batch adversarial loss: 0.023563\n",
      "epoch 61; iter: 40; batch classifier loss: 0.036207; batch adversarial loss: 0.021414\n",
      "epoch 61; iter: 50; batch classifier loss: 0.036493; batch adversarial loss: 0.021226\n",
      "[62/500] Running epoch\n",
      "epoch 62; iter: 0; batch classifier loss: 0.037449; batch adversarial loss: 0.020198\n",
      "epoch 62; iter: 10; batch classifier loss: 0.036582; batch adversarial loss: 0.021288\n",
      "epoch 62; iter: 20; batch classifier loss: 0.036178; batch adversarial loss: 0.019353\n",
      "epoch 62; iter: 30; batch classifier loss: 0.038888; batch adversarial loss: 0.025021\n",
      "epoch 62; iter: 40; batch classifier loss: 0.037660; batch adversarial loss: 0.021394\n",
      "epoch 62; iter: 50; batch classifier loss: 0.040290; batch adversarial loss: 0.020765\n",
      "[63/500] Running epoch\n",
      "epoch 63; iter: 0; batch classifier loss: 0.037768; batch adversarial loss: 0.023223\n",
      "epoch 63; iter: 10; batch classifier loss: 0.034802; batch adversarial loss: 0.020304\n",
      "epoch 63; iter: 20; batch classifier loss: 0.037529; batch adversarial loss: 0.022497\n",
      "epoch 63; iter: 30; batch classifier loss: 0.037669; batch adversarial loss: 0.020583\n",
      "epoch 63; iter: 40; batch classifier loss: 0.039131; batch adversarial loss: 0.021901\n",
      "epoch 63; iter: 50; batch classifier loss: 0.037991; batch adversarial loss: 0.019676\n",
      "[64/500] Running epoch\n",
      "epoch 64; iter: 0; batch classifier loss: 0.038047; batch adversarial loss: 0.023287\n",
      "epoch 64; iter: 10; batch classifier loss: 0.038172; batch adversarial loss: 0.022257\n",
      "epoch 64; iter: 20; batch classifier loss: 0.036021; batch adversarial loss: 0.020605\n",
      "epoch 64; iter: 30; batch classifier loss: 0.035635; batch adversarial loss: 0.020457\n",
      "epoch 64; iter: 40; batch classifier loss: 0.037726; batch adversarial loss: 0.022296\n",
      "epoch 64; iter: 50; batch classifier loss: 0.035607; batch adversarial loss: 0.019542\n",
      "[65/500] Running epoch\n",
      "epoch 65; iter: 0; batch classifier loss: 0.038075; batch adversarial loss: 0.021113\n",
      "epoch 65; iter: 10; batch classifier loss: 0.038619; batch adversarial loss: 0.024228\n",
      "epoch 65; iter: 20; batch classifier loss: 0.035965; batch adversarial loss: 0.020478\n",
      "epoch 65; iter: 30; batch classifier loss: 0.039436; batch adversarial loss: 0.021930\n",
      "epoch 65; iter: 40; batch classifier loss: 0.037002; batch adversarial loss: 0.021520\n",
      "epoch 65; iter: 50; batch classifier loss: 0.036271; batch adversarial loss: 0.019752\n",
      "[66/500] Running epoch\n",
      "epoch 66; iter: 0; batch classifier loss: 0.038552; batch adversarial loss: 0.020565\n",
      "epoch 66; iter: 10; batch classifier loss: 0.036183; batch adversarial loss: 0.019931\n",
      "epoch 66; iter: 20; batch classifier loss: 0.036378; batch adversarial loss: 0.020321\n",
      "epoch 66; iter: 30; batch classifier loss: 0.038090; batch adversarial loss: 0.020940\n",
      "epoch 66; iter: 40; batch classifier loss: 0.036613; batch adversarial loss: 0.019289\n",
      "epoch 66; iter: 50; batch classifier loss: 0.035876; batch adversarial loss: 0.019106\n",
      "[67/500] Running epoch\n",
      "epoch 67; iter: 0; batch classifier loss: 0.039577; batch adversarial loss: 0.020482\n",
      "epoch 67; iter: 10; batch classifier loss: 0.037089; batch adversarial loss: 0.020348\n",
      "epoch 67; iter: 20; batch classifier loss: 0.038300; batch adversarial loss: 0.018718\n",
      "epoch 67; iter: 30; batch classifier loss: 0.038237; batch adversarial loss: 0.019828\n",
      "epoch 67; iter: 40; batch classifier loss: 0.039387; batch adversarial loss: 0.021165\n",
      "epoch 67; iter: 50; batch classifier loss: 0.037423; batch adversarial loss: 0.019378\n",
      "[68/500] Running epoch\n",
      "epoch 68; iter: 0; batch classifier loss: 0.037411; batch adversarial loss: 0.018629\n",
      "epoch 68; iter: 10; batch classifier loss: 0.036937; batch adversarial loss: 0.023544\n",
      "epoch 68; iter: 20; batch classifier loss: 0.039082; batch adversarial loss: 0.021763\n",
      "epoch 68; iter: 30; batch classifier loss: 0.035685; batch adversarial loss: 0.020655\n",
      "epoch 68; iter: 40; batch classifier loss: 0.038749; batch adversarial loss: 0.018450\n",
      "epoch 68; iter: 50; batch classifier loss: 0.038161; batch adversarial loss: 0.022580\n",
      "[69/500] Running epoch\n",
      "epoch 69; iter: 0; batch classifier loss: 0.036464; batch adversarial loss: 0.018264\n",
      "epoch 69; iter: 10; batch classifier loss: 0.037137; batch adversarial loss: 0.021129\n",
      "epoch 69; iter: 20; batch classifier loss: 0.037380; batch adversarial loss: 0.019184\n",
      "epoch 69; iter: 30; batch classifier loss: 0.036854; batch adversarial loss: 0.022542\n",
      "epoch 69; iter: 40; batch classifier loss: 0.040207; batch adversarial loss: 0.023718\n",
      "epoch 69; iter: 50; batch classifier loss: 0.036546; batch adversarial loss: 0.019988\n",
      "[70/500] Running epoch\n",
      "epoch 70; iter: 0; batch classifier loss: 0.037761; batch adversarial loss: 0.023125\n",
      "epoch 70; iter: 10; batch classifier loss: 0.038033; batch adversarial loss: 0.020122\n",
      "epoch 70; iter: 20; batch classifier loss: 0.035791; batch adversarial loss: 0.021032\n",
      "epoch 70; iter: 30; batch classifier loss: 0.037440; batch adversarial loss: 0.021325\n",
      "epoch 70; iter: 40; batch classifier loss: 0.036521; batch adversarial loss: 0.022354\n",
      "epoch 70; iter: 50; batch classifier loss: 0.037769; batch adversarial loss: 0.019572\n",
      "||w||: 1.4249099493026733\n",
      "||w2||: 0.6737120747566223\n",
      "w.T g: [[0.20001104]]\n",
      "[71/500] Running epoch\n",
      "epoch 71; iter: 0; batch classifier loss: 0.037109; batch adversarial loss: 0.018334\n",
      "epoch 71; iter: 10; batch classifier loss: 0.037349; batch adversarial loss: 0.017538\n",
      "epoch 71; iter: 20; batch classifier loss: 0.036950; batch adversarial loss: 0.020530\n",
      "epoch 71; iter: 30; batch classifier loss: 0.039923; batch adversarial loss: 0.023521\n",
      "epoch 71; iter: 40; batch classifier loss: 0.037180; batch adversarial loss: 0.019970\n",
      "epoch 71; iter: 50; batch classifier loss: 0.035102; batch adversarial loss: 0.019722\n",
      "[72/500] Running epoch\n",
      "epoch 72; iter: 0; batch classifier loss: 0.037725; batch adversarial loss: 0.021005\n",
      "epoch 72; iter: 10; batch classifier loss: 0.039211; batch adversarial loss: 0.021552\n",
      "epoch 72; iter: 20; batch classifier loss: 0.036909; batch adversarial loss: 0.022522\n",
      "epoch 72; iter: 30; batch classifier loss: 0.035576; batch adversarial loss: 0.021858\n",
      "epoch 72; iter: 40; batch classifier loss: 0.037121; batch adversarial loss: 0.019836\n",
      "epoch 72; iter: 50; batch classifier loss: 0.036893; batch adversarial loss: 0.020722\n",
      "[73/500] Running epoch\n",
      "epoch 73; iter: 0; batch classifier loss: 0.039376; batch adversarial loss: 0.017615\n",
      "epoch 73; iter: 10; batch classifier loss: 0.036853; batch adversarial loss: 0.020384\n",
      "epoch 73; iter: 20; batch classifier loss: 0.036663; batch adversarial loss: 0.022541\n",
      "epoch 73; iter: 30; batch classifier loss: 0.037726; batch adversarial loss: 0.020671\n",
      "epoch 73; iter: 40; batch classifier loss: 0.038147; batch adversarial loss: 0.020830\n",
      "epoch 73; iter: 50; batch classifier loss: 0.037139; batch adversarial loss: 0.020607\n",
      "[74/500] Running epoch\n",
      "epoch 74; iter: 0; batch classifier loss: 0.036036; batch adversarial loss: 0.021872\n",
      "epoch 74; iter: 10; batch classifier loss: 0.038360; batch adversarial loss: 0.018347\n",
      "epoch 74; iter: 20; batch classifier loss: 0.039170; batch adversarial loss: 0.017353\n",
      "epoch 74; iter: 30; batch classifier loss: 0.039981; batch adversarial loss: 0.020656\n",
      "epoch 74; iter: 40; batch classifier loss: 0.038081; batch adversarial loss: 0.017740\n",
      "epoch 74; iter: 50; batch classifier loss: 0.035662; batch adversarial loss: 0.018327\n",
      "[75/500] Running epoch\n",
      "epoch 75; iter: 0; batch classifier loss: 0.035707; batch adversarial loss: 0.019931\n",
      "epoch 75; iter: 10; batch classifier loss: 0.038345; batch adversarial loss: 0.019759\n",
      "epoch 75; iter: 20; batch classifier loss: 0.037125; batch adversarial loss: 0.020291\n",
      "epoch 75; iter: 30; batch classifier loss: 0.036636; batch adversarial loss: 0.023438\n",
      "epoch 75; iter: 40; batch classifier loss: 0.039135; batch adversarial loss: 0.020563\n",
      "epoch 75; iter: 50; batch classifier loss: 0.037588; batch adversarial loss: 0.016624\n",
      "[76/500] Running epoch\n",
      "epoch 76; iter: 0; batch classifier loss: 0.037575; batch adversarial loss: 0.021213\n",
      "epoch 76; iter: 10; batch classifier loss: 0.036345; batch adversarial loss: 0.015598\n",
      "epoch 76; iter: 20; batch classifier loss: 0.035609; batch adversarial loss: 0.017779\n",
      "epoch 76; iter: 30; batch classifier loss: 0.039613; batch adversarial loss: 0.018846\n",
      "epoch 76; iter: 40; batch classifier loss: 0.037467; batch adversarial loss: 0.020855\n",
      "epoch 76; iter: 50; batch classifier loss: 0.036210; batch adversarial loss: 0.018380\n",
      "[77/500] Running epoch\n",
      "epoch 77; iter: 0; batch classifier loss: 0.038151; batch adversarial loss: 0.016613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77; iter: 10; batch classifier loss: 0.036563; batch adversarial loss: 0.021752\n",
      "epoch 77; iter: 20; batch classifier loss: 0.037000; batch adversarial loss: 0.022184\n",
      "epoch 77; iter: 30; batch classifier loss: 0.036449; batch adversarial loss: 0.020349\n",
      "epoch 77; iter: 40; batch classifier loss: 0.037244; batch adversarial loss: 0.018442\n",
      "epoch 77; iter: 50; batch classifier loss: 0.037976; batch adversarial loss: 0.017964\n",
      "[78/500] Running epoch\n",
      "epoch 78; iter: 0; batch classifier loss: 0.037432; batch adversarial loss: 0.021855\n",
      "epoch 78; iter: 10; batch classifier loss: 0.036916; batch adversarial loss: 0.021336\n",
      "epoch 78; iter: 20; batch classifier loss: 0.037886; batch adversarial loss: 0.018925\n",
      "epoch 78; iter: 30; batch classifier loss: 0.036675; batch adversarial loss: 0.021772\n",
      "epoch 78; iter: 40; batch classifier loss: 0.037812; batch adversarial loss: 0.018862\n",
      "epoch 78; iter: 50; batch classifier loss: 0.038741; batch adversarial loss: 0.020674\n",
      "[79/500] Running epoch\n",
      "epoch 79; iter: 0; batch classifier loss: 0.037037; batch adversarial loss: 0.018267\n",
      "epoch 79; iter: 10; batch classifier loss: 0.037391; batch adversarial loss: 0.017261\n",
      "epoch 79; iter: 20; batch classifier loss: 0.037842; batch adversarial loss: 0.019489\n",
      "epoch 79; iter: 30; batch classifier loss: 0.036426; batch adversarial loss: 0.019447\n",
      "epoch 79; iter: 40; batch classifier loss: 0.036240; batch adversarial loss: 0.025010\n",
      "epoch 79; iter: 50; batch classifier loss: 0.039086; batch adversarial loss: 0.020052\n",
      "[80/500] Running epoch\n",
      "epoch 80; iter: 0; batch classifier loss: 0.038195; batch adversarial loss: 0.018521\n",
      "epoch 80; iter: 10; batch classifier loss: 0.037199; batch adversarial loss: 0.019728\n",
      "epoch 80; iter: 20; batch classifier loss: 0.039486; batch adversarial loss: 0.020337\n",
      "epoch 80; iter: 30; batch classifier loss: 0.038080; batch adversarial loss: 0.022078\n",
      "epoch 80; iter: 40; batch classifier loss: 0.035528; batch adversarial loss: 0.022704\n",
      "epoch 80; iter: 50; batch classifier loss: 0.038640; batch adversarial loss: 0.019596\n",
      "||w||: 1.397599697113037\n",
      "||w2||: 0.6599228978157043\n",
      "w.T g: [[0.21976366]]\n",
      "[81/500] Running epoch\n",
      "epoch 81; iter: 0; batch classifier loss: 0.038685; batch adversarial loss: 0.018142\n",
      "epoch 81; iter: 10; batch classifier loss: 0.037056; batch adversarial loss: 0.017720\n",
      "epoch 81; iter: 20; batch classifier loss: 0.035231; batch adversarial loss: 0.023714\n",
      "epoch 81; iter: 30; batch classifier loss: 0.036299; batch adversarial loss: 0.019055\n",
      "epoch 81; iter: 40; batch classifier loss: 0.038868; batch adversarial loss: 0.018837\n",
      "epoch 81; iter: 50; batch classifier loss: 0.038715; batch adversarial loss: 0.018158\n",
      "[82/500] Running epoch\n",
      "epoch 82; iter: 0; batch classifier loss: 0.037890; batch adversarial loss: 0.017977\n",
      "epoch 82; iter: 10; batch classifier loss: 0.035826; batch adversarial loss: 0.016366\n",
      "epoch 82; iter: 20; batch classifier loss: 0.037211; batch adversarial loss: 0.022432\n",
      "epoch 82; iter: 30; batch classifier loss: 0.037917; batch adversarial loss: 0.019779\n",
      "epoch 82; iter: 40; batch classifier loss: 0.040148; batch adversarial loss: 0.026842\n",
      "epoch 82; iter: 50; batch classifier loss: 0.037587; batch adversarial loss: 0.023327\n",
      "[83/500] Running epoch\n",
      "epoch 83; iter: 0; batch classifier loss: 0.039507; batch adversarial loss: 0.017888\n",
      "epoch 83; iter: 10; batch classifier loss: 0.035590; batch adversarial loss: 0.022436\n",
      "epoch 83; iter: 20; batch classifier loss: 0.037903; batch adversarial loss: 0.019461\n",
      "epoch 83; iter: 30; batch classifier loss: 0.036883; batch adversarial loss: 0.021369\n",
      "epoch 83; iter: 40; batch classifier loss: 0.036556; batch adversarial loss: 0.018424\n",
      "epoch 83; iter: 50; batch classifier loss: 0.039749; batch adversarial loss: 0.018759\n",
      "[84/500] Running epoch\n",
      "epoch 84; iter: 0; batch classifier loss: 0.038474; batch adversarial loss: 0.021149\n",
      "epoch 84; iter: 10; batch classifier loss: 0.038615; batch adversarial loss: 0.019631\n",
      "epoch 84; iter: 20; batch classifier loss: 0.037346; batch adversarial loss: 0.017353\n",
      "epoch 84; iter: 30; batch classifier loss: 0.037994; batch adversarial loss: 0.022682\n",
      "epoch 84; iter: 40; batch classifier loss: 0.038575; batch adversarial loss: 0.022640\n",
      "epoch 84; iter: 50; batch classifier loss: 0.037959; batch adversarial loss: 0.019521\n",
      "[85/500] Running epoch\n",
      "epoch 85; iter: 0; batch classifier loss: 0.038738; batch adversarial loss: 0.021233\n",
      "epoch 85; iter: 10; batch classifier loss: 0.038416; batch adversarial loss: 0.017444\n",
      "epoch 85; iter: 20; batch classifier loss: 0.037056; batch adversarial loss: 0.019377\n",
      "epoch 85; iter: 30; batch classifier loss: 0.038047; batch adversarial loss: 0.016369\n",
      "epoch 85; iter: 40; batch classifier loss: 0.038841; batch adversarial loss: 0.022649\n",
      "epoch 85; iter: 50; batch classifier loss: 0.037526; batch adversarial loss: 0.019503\n",
      "[86/500] Running epoch\n",
      "epoch 86; iter: 0; batch classifier loss: 0.037203; batch adversarial loss: 0.018019\n",
      "epoch 86; iter: 10; batch classifier loss: 0.036681; batch adversarial loss: 0.019102\n",
      "epoch 86; iter: 20; batch classifier loss: 0.037778; batch adversarial loss: 0.015149\n",
      "epoch 86; iter: 30; batch classifier loss: 0.037550; batch adversarial loss: 0.022973\n",
      "epoch 86; iter: 40; batch classifier loss: 0.037001; batch adversarial loss: 0.022465\n",
      "epoch 86; iter: 50; batch classifier loss: 0.038949; batch adversarial loss: 0.023359\n",
      "[87/500] Running epoch\n",
      "epoch 87; iter: 0; batch classifier loss: 0.036704; batch adversarial loss: 0.017340\n",
      "epoch 87; iter: 10; batch classifier loss: 0.037299; batch adversarial loss: 0.018774\n",
      "epoch 87; iter: 20; batch classifier loss: 0.034903; batch adversarial loss: 0.017572\n",
      "epoch 87; iter: 30; batch classifier loss: 0.040032; batch adversarial loss: 0.018561\n",
      "epoch 87; iter: 40; batch classifier loss: 0.038566; batch adversarial loss: 0.022400\n",
      "epoch 87; iter: 50; batch classifier loss: 0.035632; batch adversarial loss: 0.021615\n",
      "[88/500] Running epoch\n",
      "epoch 88; iter: 0; batch classifier loss: 0.037975; batch adversarial loss: 0.017893\n",
      "epoch 88; iter: 10; batch classifier loss: 0.039495; batch adversarial loss: 0.019405\n",
      "epoch 88; iter: 20; batch classifier loss: 0.036411; batch adversarial loss: 0.020528\n",
      "epoch 88; iter: 30; batch classifier loss: 0.038914; batch adversarial loss: 0.018039\n",
      "epoch 88; iter: 40; batch classifier loss: 0.039879; batch adversarial loss: 0.022238\n",
      "epoch 88; iter: 50; batch classifier loss: 0.038349; batch adversarial loss: 0.023476\n",
      "[89/500] Running epoch\n",
      "epoch 89; iter: 0; batch classifier loss: 0.037355; batch adversarial loss: 0.021454\n",
      "epoch 89; iter: 10; batch classifier loss: 0.039626; batch adversarial loss: 0.020400\n",
      "epoch 89; iter: 20; batch classifier loss: 0.037588; batch adversarial loss: 0.017225\n",
      "epoch 89; iter: 30; batch classifier loss: 0.038849; batch adversarial loss: 0.021482\n",
      "epoch 89; iter: 40; batch classifier loss: 0.036554; batch adversarial loss: 0.023492\n",
      "epoch 89; iter: 50; batch classifier loss: 0.037404; batch adversarial loss: 0.017895\n",
      "[90/500] Running epoch\n",
      "epoch 90; iter: 0; batch classifier loss: 0.037248; batch adversarial loss: 0.020562\n",
      "epoch 90; iter: 10; batch classifier loss: 0.040001; batch adversarial loss: 0.018678\n",
      "epoch 90; iter: 20; batch classifier loss: 0.037774; batch adversarial loss: 0.021342\n",
      "epoch 90; iter: 30; batch classifier loss: 0.035876; batch adversarial loss: 0.018558\n",
      "epoch 90; iter: 40; batch classifier loss: 0.036418; batch adversarial loss: 0.019772\n",
      "epoch 90; iter: 50; batch classifier loss: 0.037665; batch adversarial loss: 0.021902\n",
      "||w||: 1.3744808435440063\n",
      "||w2||: 0.6511523723602295\n",
      "w.T g: [[0.23521702]]\n",
      "[91/500] Running epoch\n",
      "epoch 91; iter: 0; batch classifier loss: 0.035121; batch adversarial loss: 0.020424\n",
      "epoch 91; iter: 10; batch classifier loss: 0.038373; batch adversarial loss: 0.022253\n",
      "epoch 91; iter: 20; batch classifier loss: 0.036799; batch adversarial loss: 0.019101\n",
      "epoch 91; iter: 30; batch classifier loss: 0.039162; batch adversarial loss: 0.016778\n",
      "epoch 91; iter: 40; batch classifier loss: 0.035317; batch adversarial loss: 0.018101\n",
      "epoch 91; iter: 50; batch classifier loss: 0.037241; batch adversarial loss: 0.019580\n",
      "[92/500] Running epoch\n",
      "epoch 92; iter: 0; batch classifier loss: 0.036580; batch adversarial loss: 0.021489\n",
      "epoch 92; iter: 10; batch classifier loss: 0.035818; batch adversarial loss: 0.021938\n",
      "epoch 92; iter: 20; batch classifier loss: 0.035713; batch adversarial loss: 0.018772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92; iter: 30; batch classifier loss: 0.037016; batch adversarial loss: 0.019859\n",
      "epoch 92; iter: 40; batch classifier loss: 0.036824; batch adversarial loss: 0.019459\n",
      "epoch 92; iter: 50; batch classifier loss: 0.037702; batch adversarial loss: 0.019622\n",
      "[93/500] Running epoch\n",
      "epoch 93; iter: 0; batch classifier loss: 0.038187; batch adversarial loss: 0.019841\n",
      "epoch 93; iter: 10; batch classifier loss: 0.037713; batch adversarial loss: 0.022024\n",
      "epoch 93; iter: 20; batch classifier loss: 0.037475; batch adversarial loss: 0.016823\n",
      "epoch 93; iter: 30; batch classifier loss: 0.034985; batch adversarial loss: 0.017220\n",
      "epoch 93; iter: 40; batch classifier loss: 0.036668; batch adversarial loss: 0.017174\n",
      "epoch 93; iter: 50; batch classifier loss: 0.037405; batch adversarial loss: 0.018295\n",
      "[94/500] Running epoch\n",
      "epoch 94; iter: 0; batch classifier loss: 0.038459; batch adversarial loss: 0.017677\n",
      "epoch 94; iter: 10; batch classifier loss: 0.038102; batch adversarial loss: 0.018725\n",
      "epoch 94; iter: 20; batch classifier loss: 0.037799; batch adversarial loss: 0.020847\n",
      "epoch 94; iter: 30; batch classifier loss: 0.038144; batch adversarial loss: 0.020431\n",
      "epoch 94; iter: 40; batch classifier loss: 0.040421; batch adversarial loss: 0.023241\n",
      "epoch 94; iter: 50; batch classifier loss: 0.038151; batch adversarial loss: 0.022944\n",
      "[95/500] Running epoch\n",
      "epoch 95; iter: 0; batch classifier loss: 0.038156; batch adversarial loss: 0.020700\n",
      "epoch 95; iter: 10; batch classifier loss: 0.036574; batch adversarial loss: 0.018980\n",
      "epoch 95; iter: 20; batch classifier loss: 0.039376; batch adversarial loss: 0.023417\n",
      "epoch 95; iter: 30; batch classifier loss: 0.035375; batch adversarial loss: 0.018908\n",
      "epoch 95; iter: 40; batch classifier loss: 0.037210; batch adversarial loss: 0.023401\n",
      "epoch 95; iter: 50; batch classifier loss: 0.035966; batch adversarial loss: 0.018457\n",
      "[96/500] Running epoch\n",
      "epoch 96; iter: 0; batch classifier loss: 0.035935; batch adversarial loss: 0.017082\n",
      "epoch 96; iter: 10; batch classifier loss: 0.037458; batch adversarial loss: 0.021735\n",
      "epoch 96; iter: 20; batch classifier loss: 0.038492; batch adversarial loss: 0.019282\n",
      "epoch 96; iter: 30; batch classifier loss: 0.040518; batch adversarial loss: 0.020112\n",
      "epoch 96; iter: 40; batch classifier loss: 0.038192; batch adversarial loss: 0.020942\n",
      "epoch 96; iter: 50; batch classifier loss: 0.038494; batch adversarial loss: 0.022837\n",
      "[97/500] Running epoch\n",
      "epoch 97; iter: 0; batch classifier loss: 0.038337; batch adversarial loss: 0.020464\n",
      "epoch 97; iter: 10; batch classifier loss: 0.037281; batch adversarial loss: 0.018965\n",
      "epoch 97; iter: 20; batch classifier loss: 0.037881; batch adversarial loss: 0.018740\n",
      "epoch 97; iter: 30; batch classifier loss: 0.037248; batch adversarial loss: 0.021791\n",
      "epoch 97; iter: 40; batch classifier loss: 0.037318; batch adversarial loss: 0.021370\n",
      "epoch 97; iter: 50; batch classifier loss: 0.034519; batch adversarial loss: 0.017221\n",
      "[98/500] Running epoch\n",
      "epoch 98; iter: 0; batch classifier loss: 0.036735; batch adversarial loss: 0.015229\n",
      "epoch 98; iter: 10; batch classifier loss: 0.037671; batch adversarial loss: 0.017143\n",
      "epoch 98; iter: 20; batch classifier loss: 0.038224; batch adversarial loss: 0.017781\n",
      "epoch 98; iter: 30; batch classifier loss: 0.036708; batch adversarial loss: 0.020342\n",
      "epoch 98; iter: 40; batch classifier loss: 0.038191; batch adversarial loss: 0.021780\n",
      "epoch 98; iter: 50; batch classifier loss: 0.037231; batch adversarial loss: 0.020795\n",
      "[99/500] Running epoch\n",
      "epoch 99; iter: 0; batch classifier loss: 0.038375; batch adversarial loss: 0.018661\n",
      "epoch 99; iter: 10; batch classifier loss: 0.036842; batch adversarial loss: 0.019159\n",
      "epoch 99; iter: 20; batch classifier loss: 0.037667; batch adversarial loss: 0.023139\n",
      "epoch 99; iter: 30; batch classifier loss: 0.038203; batch adversarial loss: 0.018298\n",
      "epoch 99; iter: 40; batch classifier loss: 0.036949; batch adversarial loss: 0.018947\n",
      "epoch 99; iter: 50; batch classifier loss: 0.038197; batch adversarial loss: 0.020737\n",
      "[100/500] Running epoch\n",
      "epoch 100; iter: 0; batch classifier loss: 0.036086; batch adversarial loss: 0.017698\n",
      "epoch 100; iter: 10; batch classifier loss: 0.035969; batch adversarial loss: 0.018676\n",
      "epoch 100; iter: 20; batch classifier loss: 0.038954; batch adversarial loss: 0.020607\n",
      "epoch 100; iter: 30; batch classifier loss: 0.035905; batch adversarial loss: 0.016587\n",
      "epoch 100; iter: 40; batch classifier loss: 0.037048; batch adversarial loss: 0.018413\n",
      "epoch 100; iter: 50; batch classifier loss: 0.037524; batch adversarial loss: 0.016827\n",
      "||w||: 1.3556625843048096\n",
      "||w2||: 0.6446247696876526\n",
      "w.T g: [[0.24763217]]\n",
      "[101/500] Running epoch\n",
      "epoch 101; iter: 0; batch classifier loss: 0.036917; batch adversarial loss: 0.020473\n",
      "epoch 101; iter: 10; batch classifier loss: 0.036781; batch adversarial loss: 0.021599\n",
      "epoch 101; iter: 20; batch classifier loss: 0.034834; batch adversarial loss: 0.021410\n",
      "epoch 101; iter: 30; batch classifier loss: 0.038346; batch adversarial loss: 0.018883\n",
      "epoch 101; iter: 40; batch classifier loss: 0.038791; batch adversarial loss: 0.022015\n",
      "epoch 101; iter: 50; batch classifier loss: 0.037442; batch adversarial loss: 0.017855\n",
      "[102/500] Running epoch\n",
      "epoch 102; iter: 0; batch classifier loss: 0.038287; batch adversarial loss: 0.019418\n",
      "epoch 102; iter: 10; batch classifier loss: 0.037987; batch adversarial loss: 0.022644\n",
      "epoch 102; iter: 20; batch classifier loss: 0.040181; batch adversarial loss: 0.017535\n",
      "epoch 102; iter: 30; batch classifier loss: 0.039160; batch adversarial loss: 0.018314\n",
      "epoch 102; iter: 40; batch classifier loss: 0.037299; batch adversarial loss: 0.015194\n",
      "epoch 102; iter: 50; batch classifier loss: 0.037057; batch adversarial loss: 0.021480\n",
      "[103/500] Running epoch\n",
      "epoch 103; iter: 0; batch classifier loss: 0.038689; batch adversarial loss: 0.020836\n",
      "epoch 103; iter: 10; batch classifier loss: 0.036664; batch adversarial loss: 0.017991\n",
      "epoch 103; iter: 20; batch classifier loss: 0.037788; batch adversarial loss: 0.021400\n",
      "epoch 103; iter: 30; batch classifier loss: 0.035935; batch adversarial loss: 0.019198\n",
      "epoch 103; iter: 40; batch classifier loss: 0.037576; batch adversarial loss: 0.018951\n",
      "epoch 103; iter: 50; batch classifier loss: 0.037856; batch adversarial loss: 0.025180\n",
      "[104/500] Running epoch\n",
      "epoch 104; iter: 0; batch classifier loss: 0.036988; batch adversarial loss: 0.019417\n",
      "epoch 104; iter: 10; batch classifier loss: 0.041463; batch adversarial loss: 0.021730\n",
      "epoch 104; iter: 20; batch classifier loss: 0.037842; batch adversarial loss: 0.019165\n",
      "epoch 104; iter: 30; batch classifier loss: 0.035643; batch adversarial loss: 0.018544\n",
      "epoch 104; iter: 40; batch classifier loss: 0.038085; batch adversarial loss: 0.021239\n",
      "epoch 104; iter: 50; batch classifier loss: 0.037126; batch adversarial loss: 0.020977\n",
      "[105/500] Running epoch\n",
      "epoch 105; iter: 0; batch classifier loss: 0.035840; batch adversarial loss: 0.018909\n",
      "epoch 105; iter: 10; batch classifier loss: 0.035018; batch adversarial loss: 0.022520\n",
      "epoch 105; iter: 20; batch classifier loss: 0.035549; batch adversarial loss: 0.020400\n",
      "epoch 105; iter: 30; batch classifier loss: 0.039901; batch adversarial loss: 0.021232\n",
      "epoch 105; iter: 40; batch classifier loss: 0.037251; batch adversarial loss: 0.018864\n",
      "epoch 105; iter: 50; batch classifier loss: 0.036663; batch adversarial loss: 0.019090\n",
      "[106/500] Running epoch\n",
      "epoch 106; iter: 0; batch classifier loss: 0.037723; batch adversarial loss: 0.023363\n",
      "epoch 106; iter: 10; batch classifier loss: 0.037503; batch adversarial loss: 0.023923\n",
      "epoch 106; iter: 20; batch classifier loss: 0.038780; batch adversarial loss: 0.020179\n",
      "epoch 106; iter: 30; batch classifier loss: 0.037477; batch adversarial loss: 0.021022\n",
      "epoch 106; iter: 40; batch classifier loss: 0.037294; batch adversarial loss: 0.019425\n",
      "epoch 106; iter: 50; batch classifier loss: 0.037963; batch adversarial loss: 0.023024\n",
      "[107/500] Running epoch\n",
      "epoch 107; iter: 0; batch classifier loss: 0.036112; batch adversarial loss: 0.018157\n",
      "epoch 107; iter: 10; batch classifier loss: 0.038873; batch adversarial loss: 0.022987\n",
      "epoch 107; iter: 20; batch classifier loss: 0.038220; batch adversarial loss: 0.017233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 107; iter: 30; batch classifier loss: 0.036514; batch adversarial loss: 0.019567\n",
      "epoch 107; iter: 40; batch classifier loss: 0.036935; batch adversarial loss: 0.020718\n",
      "epoch 107; iter: 50; batch classifier loss: 0.038953; batch adversarial loss: 0.020290\n",
      "[108/500] Running epoch\n",
      "epoch 108; iter: 0; batch classifier loss: 0.037473; batch adversarial loss: 0.018391\n",
      "epoch 108; iter: 10; batch classifier loss: 0.036851; batch adversarial loss: 0.019757\n",
      "epoch 108; iter: 20; batch classifier loss: 0.037585; batch adversarial loss: 0.016553\n",
      "epoch 108; iter: 30; batch classifier loss: 0.038277; batch adversarial loss: 0.022122\n",
      "epoch 108; iter: 40; batch classifier loss: 0.037020; batch adversarial loss: 0.022938\n",
      "epoch 108; iter: 50; batch classifier loss: 0.036973; batch adversarial loss: 0.019293\n",
      "[109/500] Running epoch\n",
      "epoch 109; iter: 0; batch classifier loss: 0.038041; batch adversarial loss: 0.017020\n",
      "epoch 109; iter: 10; batch classifier loss: 0.039113; batch adversarial loss: 0.020896\n",
      "epoch 109; iter: 20; batch classifier loss: 0.038741; batch adversarial loss: 0.019105\n",
      "epoch 109; iter: 30; batch classifier loss: 0.037939; batch adversarial loss: 0.020757\n",
      "epoch 109; iter: 40; batch classifier loss: 0.037924; batch adversarial loss: 0.016900\n",
      "epoch 109; iter: 50; batch classifier loss: 0.038323; batch adversarial loss: 0.019041\n",
      "[110/500] Running epoch\n",
      "epoch 110; iter: 0; batch classifier loss: 0.035950; batch adversarial loss: 0.021669\n",
      "epoch 110; iter: 10; batch classifier loss: 0.035982; batch adversarial loss: 0.016006\n",
      "epoch 110; iter: 20; batch classifier loss: 0.036744; batch adversarial loss: 0.021120\n",
      "epoch 110; iter: 30; batch classifier loss: 0.035231; batch adversarial loss: 0.018270\n",
      "epoch 110; iter: 40; batch classifier loss: 0.037524; batch adversarial loss: 0.019327\n",
      "epoch 110; iter: 50; batch classifier loss: 0.039094; batch adversarial loss: 0.019987\n",
      "||w||: 1.3405122756958008\n",
      "||w2||: 0.6381573677062988\n",
      "w.T g: [[0.25733607]]\n",
      "[111/500] Running epoch\n",
      "epoch 111; iter: 0; batch classifier loss: 0.038613; batch adversarial loss: 0.022428\n",
      "epoch 111; iter: 10; batch classifier loss: 0.037956; batch adversarial loss: 0.018317\n",
      "epoch 111; iter: 20; batch classifier loss: 0.039758; batch adversarial loss: 0.021352\n",
      "epoch 111; iter: 30; batch classifier loss: 0.036814; batch adversarial loss: 0.018908\n",
      "epoch 111; iter: 40; batch classifier loss: 0.036406; batch adversarial loss: 0.022982\n",
      "epoch 111; iter: 50; batch classifier loss: 0.035875; batch adversarial loss: 0.018777\n",
      "[112/500] Running epoch\n",
      "epoch 112; iter: 0; batch classifier loss: 0.038193; batch adversarial loss: 0.020166\n",
      "epoch 112; iter: 10; batch classifier loss: 0.038796; batch adversarial loss: 0.019968\n",
      "epoch 112; iter: 20; batch classifier loss: 0.037017; batch adversarial loss: 0.015169\n",
      "epoch 112; iter: 30; batch classifier loss: 0.037114; batch adversarial loss: 0.019019\n",
      "epoch 112; iter: 40; batch classifier loss: 0.036799; batch adversarial loss: 0.017391\n",
      "epoch 112; iter: 50; batch classifier loss: 0.035897; batch adversarial loss: 0.019385\n",
      "[113/500] Running epoch\n",
      "epoch 113; iter: 0; batch classifier loss: 0.037671; batch adversarial loss: 0.021844\n",
      "epoch 113; iter: 10; batch classifier loss: 0.038574; batch adversarial loss: 0.019659\n",
      "epoch 113; iter: 20; batch classifier loss: 0.038775; batch adversarial loss: 0.019287\n",
      "epoch 113; iter: 30; batch classifier loss: 0.037373; batch adversarial loss: 0.024655\n",
      "epoch 113; iter: 40; batch classifier loss: 0.037249; batch adversarial loss: 0.021077\n",
      "epoch 113; iter: 50; batch classifier loss: 0.034825; batch adversarial loss: 0.017781\n",
      "[114/500] Running epoch\n",
      "epoch 114; iter: 0; batch classifier loss: 0.037284; batch adversarial loss: 0.017803\n",
      "epoch 114; iter: 10; batch classifier loss: 0.039886; batch adversarial loss: 0.021038\n",
      "epoch 114; iter: 20; batch classifier loss: 0.037279; batch adversarial loss: 0.019811\n",
      "epoch 114; iter: 30; batch classifier loss: 0.037618; batch adversarial loss: 0.018000\n",
      "epoch 114; iter: 40; batch classifier loss: 0.038838; batch adversarial loss: 0.020239\n",
      "epoch 114; iter: 50; batch classifier loss: 0.036248; batch adversarial loss: 0.018392\n",
      "[115/500] Running epoch\n",
      "epoch 115; iter: 0; batch classifier loss: 0.036098; batch adversarial loss: 0.019027\n",
      "epoch 115; iter: 10; batch classifier loss: 0.038284; batch adversarial loss: 0.019718\n",
      "epoch 115; iter: 20; batch classifier loss: 0.035532; batch adversarial loss: 0.018041\n",
      "epoch 115; iter: 30; batch classifier loss: 0.036809; batch adversarial loss: 0.023956\n",
      "epoch 115; iter: 40; batch classifier loss: 0.037913; batch adversarial loss: 0.015769\n",
      "epoch 115; iter: 50; batch classifier loss: 0.035899; batch adversarial loss: 0.017437\n",
      "[116/500] Running epoch\n",
      "epoch 116; iter: 0; batch classifier loss: 0.037684; batch adversarial loss: 0.019586\n",
      "epoch 116; iter: 10; batch classifier loss: 0.037566; batch adversarial loss: 0.023400\n",
      "epoch 116; iter: 20; batch classifier loss: 0.037668; batch adversarial loss: 0.021034\n",
      "epoch 116; iter: 30; batch classifier loss: 0.037548; batch adversarial loss: 0.020819\n",
      "epoch 116; iter: 40; batch classifier loss: 0.037922; batch adversarial loss: 0.018748\n",
      "epoch 116; iter: 50; batch classifier loss: 0.037666; batch adversarial loss: 0.021520\n",
      "[117/500] Running epoch\n",
      "epoch 117; iter: 0; batch classifier loss: 0.039113; batch adversarial loss: 0.021544\n",
      "epoch 117; iter: 10; batch classifier loss: 0.036532; batch adversarial loss: 0.016338\n",
      "epoch 117; iter: 20; batch classifier loss: 0.036950; batch adversarial loss: 0.017494\n",
      "epoch 117; iter: 30; batch classifier loss: 0.037194; batch adversarial loss: 0.020261\n",
      "epoch 117; iter: 40; batch classifier loss: 0.038435; batch adversarial loss: 0.018645\n",
      "epoch 117; iter: 50; batch classifier loss: 0.037574; batch adversarial loss: 0.019083\n",
      "[118/500] Running epoch\n",
      "epoch 118; iter: 0; batch classifier loss: 0.037903; batch adversarial loss: 0.020243\n",
      "epoch 118; iter: 10; batch classifier loss: 0.037820; batch adversarial loss: 0.018705\n",
      "epoch 118; iter: 20; batch classifier loss: 0.038834; batch adversarial loss: 0.022009\n",
      "epoch 118; iter: 30; batch classifier loss: 0.038018; batch adversarial loss: 0.021179\n",
      "epoch 118; iter: 40; batch classifier loss: 0.035680; batch adversarial loss: 0.018081\n",
      "epoch 118; iter: 50; batch classifier loss: 0.034311; batch adversarial loss: 0.017504\n",
      "[119/500] Running epoch\n",
      "epoch 119; iter: 0; batch classifier loss: 0.036953; batch adversarial loss: 0.020458\n",
      "epoch 119; iter: 10; batch classifier loss: 0.035314; batch adversarial loss: 0.020766\n",
      "epoch 119; iter: 20; batch classifier loss: 0.037520; batch adversarial loss: 0.019319\n",
      "epoch 119; iter: 30; batch classifier loss: 0.037437; batch adversarial loss: 0.018950\n",
      "epoch 119; iter: 40; batch classifier loss: 0.037216; batch adversarial loss: 0.019774\n",
      "epoch 119; iter: 50; batch classifier loss: 0.037521; batch adversarial loss: 0.019039\n",
      "[120/500] Running epoch\n",
      "epoch 120; iter: 0; batch classifier loss: 0.035631; batch adversarial loss: 0.018073\n",
      "epoch 120; iter: 10; batch classifier loss: 0.037735; batch adversarial loss: 0.024750\n",
      "epoch 120; iter: 20; batch classifier loss: 0.036770; batch adversarial loss: 0.016893\n",
      "epoch 120; iter: 30; batch classifier loss: 0.036837; batch adversarial loss: 0.019909\n",
      "epoch 120; iter: 40; batch classifier loss: 0.038423; batch adversarial loss: 0.020132\n",
      "epoch 120; iter: 50; batch classifier loss: 0.037449; batch adversarial loss: 0.020852\n",
      "||w||: 1.3287080526351929\n",
      "||w2||: 0.6331186890602112\n",
      "w.T g: [[0.26589358]]\n",
      "[121/500] Running epoch\n",
      "epoch 121; iter: 0; batch classifier loss: 0.036949; batch adversarial loss: 0.019913\n",
      "epoch 121; iter: 10; batch classifier loss: 0.036092; batch adversarial loss: 0.016664\n",
      "epoch 121; iter: 20; batch classifier loss: 0.037577; batch adversarial loss: 0.022002\n",
      "epoch 121; iter: 30; batch classifier loss: 0.037945; batch adversarial loss: 0.018194\n",
      "epoch 121; iter: 40; batch classifier loss: 0.037645; batch adversarial loss: 0.021813\n",
      "epoch 121; iter: 50; batch classifier loss: 0.038760; batch adversarial loss: 0.018987\n",
      "[122/500] Running epoch\n",
      "epoch 122; iter: 0; batch classifier loss: 0.037802; batch adversarial loss: 0.022435\n",
      "epoch 122; iter: 10; batch classifier loss: 0.038460; batch adversarial loss: 0.023260\n",
      "epoch 122; iter: 20; batch classifier loss: 0.037471; batch adversarial loss: 0.019601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 122; iter: 30; batch classifier loss: 0.038472; batch adversarial loss: 0.019102\n",
      "epoch 122; iter: 40; batch classifier loss: 0.037563; batch adversarial loss: 0.018570\n",
      "epoch 122; iter: 50; batch classifier loss: 0.037011; batch adversarial loss: 0.017748\n",
      "[123/500] Running epoch\n",
      "epoch 123; iter: 0; batch classifier loss: 0.038836; batch adversarial loss: 0.020349\n",
      "epoch 123; iter: 10; batch classifier loss: 0.041004; batch adversarial loss: 0.021614\n",
      "epoch 123; iter: 20; batch classifier loss: 0.039931; batch adversarial loss: 0.018530\n",
      "epoch 123; iter: 30; batch classifier loss: 0.036573; batch adversarial loss: 0.021688\n",
      "epoch 123; iter: 40; batch classifier loss: 0.037387; batch adversarial loss: 0.020634\n",
      "epoch 123; iter: 50; batch classifier loss: 0.038422; batch adversarial loss: 0.023550\n",
      "[124/500] Running epoch\n",
      "epoch 124; iter: 0; batch classifier loss: 0.035252; batch adversarial loss: 0.022938\n",
      "epoch 124; iter: 10; batch classifier loss: 0.036738; batch adversarial loss: 0.016156\n",
      "epoch 124; iter: 20; batch classifier loss: 0.040275; batch adversarial loss: 0.019497\n",
      "epoch 124; iter: 30; batch classifier loss: 0.036856; batch adversarial loss: 0.022461\n",
      "epoch 124; iter: 40; batch classifier loss: 0.036442; batch adversarial loss: 0.019857\n",
      "epoch 124; iter: 50; batch classifier loss: 0.037922; batch adversarial loss: 0.023018\n",
      "[125/500] Running epoch\n",
      "epoch 125; iter: 0; batch classifier loss: 0.035526; batch adversarial loss: 0.020810\n",
      "epoch 125; iter: 10; batch classifier loss: 0.036385; batch adversarial loss: 0.020486\n",
      "epoch 125; iter: 20; batch classifier loss: 0.038232; batch adversarial loss: 0.019652\n",
      "epoch 125; iter: 30; batch classifier loss: 0.037831; batch adversarial loss: 0.021215\n",
      "epoch 125; iter: 40; batch classifier loss: 0.038212; batch adversarial loss: 0.022205\n",
      "epoch 125; iter: 50; batch classifier loss: 0.035929; batch adversarial loss: 0.020238\n",
      "[126/500] Running epoch\n",
      "epoch 126; iter: 0; batch classifier loss: 0.036076; batch adversarial loss: 0.021501\n",
      "epoch 126; iter: 10; batch classifier loss: 0.036172; batch adversarial loss: 0.017670\n",
      "epoch 126; iter: 20; batch classifier loss: 0.038331; batch adversarial loss: 0.021551\n",
      "epoch 126; iter: 30; batch classifier loss: 0.038111; batch adversarial loss: 0.021558\n",
      "epoch 126; iter: 40; batch classifier loss: 0.038828; batch adversarial loss: 0.020081\n",
      "epoch 126; iter: 50; batch classifier loss: 0.037257; batch adversarial loss: 0.019738\n",
      "[127/500] Running epoch\n",
      "epoch 127; iter: 0; batch classifier loss: 0.037774; batch adversarial loss: 0.020179\n",
      "epoch 127; iter: 10; batch classifier loss: 0.035291; batch adversarial loss: 0.018395\n",
      "epoch 127; iter: 20; batch classifier loss: 0.037302; batch adversarial loss: 0.021447\n",
      "epoch 127; iter: 30; batch classifier loss: 0.036557; batch adversarial loss: 0.019935\n",
      "epoch 127; iter: 40; batch classifier loss: 0.036546; batch adversarial loss: 0.024891\n",
      "epoch 127; iter: 50; batch classifier loss: 0.039191; batch adversarial loss: 0.023285\n",
      "[128/500] Running epoch\n",
      "epoch 128; iter: 0; batch classifier loss: 0.037682; batch adversarial loss: 0.020513\n",
      "epoch 128; iter: 10; batch classifier loss: 0.035719; batch adversarial loss: 0.017742\n",
      "epoch 128; iter: 20; batch classifier loss: 0.036860; batch adversarial loss: 0.018632\n",
      "epoch 128; iter: 30; batch classifier loss: 0.038223; batch adversarial loss: 0.023258\n",
      "epoch 128; iter: 40; batch classifier loss: 0.037841; batch adversarial loss: 0.021274\n",
      "epoch 128; iter: 50; batch classifier loss: 0.037723; batch adversarial loss: 0.021195\n",
      "[129/500] Running epoch\n",
      "epoch 129; iter: 0; batch classifier loss: 0.035624; batch adversarial loss: 0.018051\n",
      "epoch 129; iter: 10; batch classifier loss: 0.036198; batch adversarial loss: 0.023163\n",
      "epoch 129; iter: 20; batch classifier loss: 0.038292; batch adversarial loss: 0.017039\n",
      "epoch 129; iter: 30; batch classifier loss: 0.038003; batch adversarial loss: 0.017217\n",
      "epoch 129; iter: 40; batch classifier loss: 0.037540; batch adversarial loss: 0.017419\n",
      "epoch 129; iter: 50; batch classifier loss: 0.038923; batch adversarial loss: 0.020004\n",
      "[130/500] Running epoch\n",
      "epoch 130; iter: 0; batch classifier loss: 0.038020; batch adversarial loss: 0.022091\n",
      "epoch 130; iter: 10; batch classifier loss: 0.036100; batch adversarial loss: 0.019842\n",
      "epoch 130; iter: 20; batch classifier loss: 0.035958; batch adversarial loss: 0.023023\n",
      "epoch 130; iter: 30; batch classifier loss: 0.036444; batch adversarial loss: 0.014948\n",
      "epoch 130; iter: 40; batch classifier loss: 0.039139; batch adversarial loss: 0.019241\n",
      "epoch 130; iter: 50; batch classifier loss: 0.039926; batch adversarial loss: 0.017677\n",
      "||w||: 1.3196827173233032\n",
      "||w2||: 0.6284699440002441\n",
      "w.T g: [[0.27290036]]\n",
      "[131/500] Running epoch\n",
      "epoch 131; iter: 0; batch classifier loss: 0.035862; batch adversarial loss: 0.018986\n",
      "epoch 131; iter: 10; batch classifier loss: 0.037767; batch adversarial loss: 0.018543\n",
      "epoch 131; iter: 20; batch classifier loss: 0.040032; batch adversarial loss: 0.018925\n",
      "epoch 131; iter: 30; batch classifier loss: 0.037029; batch adversarial loss: 0.022127\n",
      "epoch 131; iter: 40; batch classifier loss: 0.037444; batch adversarial loss: 0.019146\n",
      "epoch 131; iter: 50; batch classifier loss: 0.038452; batch adversarial loss: 0.018408\n",
      "[132/500] Running epoch\n",
      "epoch 132; iter: 0; batch classifier loss: 0.037456; batch adversarial loss: 0.021357\n",
      "epoch 132; iter: 10; batch classifier loss: 0.035180; batch adversarial loss: 0.017610\n",
      "epoch 132; iter: 20; batch classifier loss: 0.037862; batch adversarial loss: 0.020708\n",
      "epoch 132; iter: 30; batch classifier loss: 0.039507; batch adversarial loss: 0.019078\n",
      "epoch 132; iter: 40; batch classifier loss: 0.039579; batch adversarial loss: 0.023310\n",
      "epoch 132; iter: 50; batch classifier loss: 0.037479; batch adversarial loss: 0.023044\n",
      "[133/500] Running epoch\n",
      "epoch 133; iter: 0; batch classifier loss: 0.037402; batch adversarial loss: 0.021665\n",
      "epoch 133; iter: 10; batch classifier loss: 0.037995; batch adversarial loss: 0.019233\n",
      "epoch 133; iter: 20; batch classifier loss: 0.037588; batch adversarial loss: 0.020087\n",
      "epoch 133; iter: 30; batch classifier loss: 0.037230; batch adversarial loss: 0.020448\n",
      "epoch 133; iter: 40; batch classifier loss: 0.038384; batch adversarial loss: 0.020859\n",
      "epoch 133; iter: 50; batch classifier loss: 0.039139; batch adversarial loss: 0.021346\n",
      "[134/500] Running epoch\n",
      "epoch 134; iter: 0; batch classifier loss: 0.036137; batch adversarial loss: 0.024275\n",
      "epoch 134; iter: 10; batch classifier loss: 0.037139; batch adversarial loss: 0.022692\n",
      "epoch 134; iter: 20; batch classifier loss: 0.037826; batch adversarial loss: 0.018046\n",
      "epoch 134; iter: 30; batch classifier loss: 0.038117; batch adversarial loss: 0.020989\n",
      "epoch 134; iter: 40; batch classifier loss: 0.037734; batch adversarial loss: 0.026946\n",
      "epoch 134; iter: 50; batch classifier loss: 0.038597; batch adversarial loss: 0.019884\n",
      "[135/500] Running epoch\n",
      "epoch 135; iter: 0; batch classifier loss: 0.037860; batch adversarial loss: 0.019930\n",
      "epoch 135; iter: 10; batch classifier loss: 0.040278; batch adversarial loss: 0.021874\n",
      "epoch 135; iter: 20; batch classifier loss: 0.037420; batch adversarial loss: 0.020404\n",
      "epoch 135; iter: 30; batch classifier loss: 0.035879; batch adversarial loss: 0.019203\n",
      "epoch 135; iter: 40; batch classifier loss: 0.039264; batch adversarial loss: 0.019601\n",
      "epoch 135; iter: 50; batch classifier loss: 0.034485; batch adversarial loss: 0.021223\n",
      "[136/500] Running epoch\n",
      "epoch 136; iter: 0; batch classifier loss: 0.035751; batch adversarial loss: 0.016663\n",
      "epoch 136; iter: 10; batch classifier loss: 0.039175; batch adversarial loss: 0.019541\n",
      "epoch 136; iter: 20; batch classifier loss: 0.038097; batch adversarial loss: 0.019474\n",
      "epoch 136; iter: 30; batch classifier loss: 0.034717; batch adversarial loss: 0.016913\n",
      "epoch 136; iter: 40; batch classifier loss: 0.037660; batch adversarial loss: 0.021550\n",
      "epoch 136; iter: 50; batch classifier loss: 0.037090; batch adversarial loss: 0.018257\n",
      "[137/500] Running epoch\n",
      "epoch 137; iter: 0; batch classifier loss: 0.037824; batch adversarial loss: 0.017995\n",
      "epoch 137; iter: 10; batch classifier loss: 0.035605; batch adversarial loss: 0.019628\n",
      "epoch 137; iter: 20; batch classifier loss: 0.037106; batch adversarial loss: 0.020019\n",
      "epoch 137; iter: 30; batch classifier loss: 0.035807; batch adversarial loss: 0.022835\n",
      "epoch 137; iter: 40; batch classifier loss: 0.038422; batch adversarial loss: 0.017527\n",
      "epoch 137; iter: 50; batch classifier loss: 0.037230; batch adversarial loss: 0.020806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138/500] Running epoch\n",
      "epoch 138; iter: 0; batch classifier loss: 0.036548; batch adversarial loss: 0.025689\n",
      "epoch 138; iter: 10; batch classifier loss: 0.037904; batch adversarial loss: 0.022422\n",
      "epoch 138; iter: 20; batch classifier loss: 0.036672; batch adversarial loss: 0.019746\n",
      "epoch 138; iter: 30; batch classifier loss: 0.039179; batch adversarial loss: 0.023775\n",
      "epoch 138; iter: 40; batch classifier loss: 0.035970; batch adversarial loss: 0.020592\n",
      "epoch 138; iter: 50; batch classifier loss: 0.037566; batch adversarial loss: 0.019710\n",
      "[139/500] Running epoch\n",
      "epoch 139; iter: 0; batch classifier loss: 0.036748; batch adversarial loss: 0.017422\n",
      "epoch 139; iter: 10; batch classifier loss: 0.037822; batch adversarial loss: 0.023005\n",
      "epoch 139; iter: 20; batch classifier loss: 0.036206; batch adversarial loss: 0.019548\n",
      "epoch 139; iter: 30; batch classifier loss: 0.037888; batch adversarial loss: 0.022494\n",
      "epoch 139; iter: 40; batch classifier loss: 0.037124; batch adversarial loss: 0.024776\n",
      "epoch 139; iter: 50; batch classifier loss: 0.037020; batch adversarial loss: 0.021038\n",
      "[140/500] Running epoch\n",
      "epoch 140; iter: 0; batch classifier loss: 0.037452; batch adversarial loss: 0.022269\n",
      "epoch 140; iter: 10; batch classifier loss: 0.037914; batch adversarial loss: 0.022935\n",
      "epoch 140; iter: 20; batch classifier loss: 0.040774; batch adversarial loss: 0.023099\n",
      "epoch 140; iter: 30; batch classifier loss: 0.037802; batch adversarial loss: 0.020070\n",
      "epoch 140; iter: 40; batch classifier loss: 0.036903; batch adversarial loss: 0.020528\n",
      "epoch 140; iter: 50; batch classifier loss: 0.038247; batch adversarial loss: 0.021941\n",
      "||w||: 1.3131353855133057\n",
      "||w2||: 0.6230714321136475\n",
      "w.T g: [[0.27875204]]\n",
      "[141/500] Running epoch\n",
      "epoch 141; iter: 0; batch classifier loss: 0.037841; batch adversarial loss: 0.020356\n",
      "epoch 141; iter: 10; batch classifier loss: 0.037851; batch adversarial loss: 0.019820\n",
      "epoch 141; iter: 20; batch classifier loss: 0.039119; batch adversarial loss: 0.020547\n",
      "epoch 141; iter: 30; batch classifier loss: 0.036103; batch adversarial loss: 0.018758\n",
      "epoch 141; iter: 40; batch classifier loss: 0.035246; batch adversarial loss: 0.019648\n",
      "epoch 141; iter: 50; batch classifier loss: 0.038726; batch adversarial loss: 0.026534\n",
      "[142/500] Running epoch\n",
      "epoch 142; iter: 0; batch classifier loss: 0.037227; batch adversarial loss: 0.019018\n",
      "epoch 142; iter: 10; batch classifier loss: 0.038086; batch adversarial loss: 0.021691\n",
      "epoch 142; iter: 20; batch classifier loss: 0.037855; batch adversarial loss: 0.020590\n",
      "epoch 142; iter: 30; batch classifier loss: 0.037412; batch adversarial loss: 0.022238\n",
      "epoch 142; iter: 40; batch classifier loss: 0.036101; batch adversarial loss: 0.020015\n",
      "epoch 142; iter: 50; batch classifier loss: 0.037992; batch adversarial loss: 0.021047\n",
      "[143/500] Running epoch\n",
      "epoch 143; iter: 0; batch classifier loss: 0.037816; batch adversarial loss: 0.022311\n",
      "epoch 143; iter: 10; batch classifier loss: 0.035591; batch adversarial loss: 0.019956\n",
      "epoch 143; iter: 20; batch classifier loss: 0.036844; batch adversarial loss: 0.020910\n",
      "epoch 143; iter: 30; batch classifier loss: 0.035889; batch adversarial loss: 0.021295\n",
      "epoch 143; iter: 40; batch classifier loss: 0.036796; batch adversarial loss: 0.021064\n",
      "epoch 143; iter: 50; batch classifier loss: 0.035914; batch adversarial loss: 0.020525\n",
      "[144/500] Running epoch\n",
      "epoch 144; iter: 0; batch classifier loss: 0.036441; batch adversarial loss: 0.020242\n",
      "epoch 144; iter: 10; batch classifier loss: 0.039028; batch adversarial loss: 0.015528\n",
      "epoch 144; iter: 20; batch classifier loss: 0.039482; batch adversarial loss: 0.021354\n",
      "epoch 144; iter: 30; batch classifier loss: 0.038607; batch adversarial loss: 0.021475\n",
      "epoch 144; iter: 40; batch classifier loss: 0.036333; batch adversarial loss: 0.019173\n",
      "epoch 144; iter: 50; batch classifier loss: 0.038227; batch adversarial loss: 0.019512\n",
      "[145/500] Running epoch\n",
      "epoch 145; iter: 0; batch classifier loss: 0.037031; batch adversarial loss: 0.020957\n",
      "epoch 145; iter: 10; batch classifier loss: 0.036556; batch adversarial loss: 0.019983\n",
      "epoch 145; iter: 20; batch classifier loss: 0.036730; batch adversarial loss: 0.024377\n",
      "epoch 145; iter: 30; batch classifier loss: 0.036549; batch adversarial loss: 0.020915\n",
      "epoch 145; iter: 40; batch classifier loss: 0.036460; batch adversarial loss: 0.019498\n",
      "epoch 145; iter: 50; batch classifier loss: 0.038026; batch adversarial loss: 0.021909\n",
      "[146/500] Running epoch\n",
      "epoch 146; iter: 0; batch classifier loss: 0.038914; batch adversarial loss: 0.019492\n",
      "epoch 146; iter: 10; batch classifier loss: 0.035737; batch adversarial loss: 0.021611\n",
      "epoch 146; iter: 20; batch classifier loss: 0.040194; batch adversarial loss: 0.021219\n",
      "epoch 146; iter: 30; batch classifier loss: 0.037177; batch adversarial loss: 0.022971\n",
      "epoch 146; iter: 40; batch classifier loss: 0.036047; batch adversarial loss: 0.017489\n",
      "epoch 146; iter: 50; batch classifier loss: 0.037536; batch adversarial loss: 0.021430\n",
      "[147/500] Running epoch\n",
      "epoch 147; iter: 0; batch classifier loss: 0.036402; batch adversarial loss: 0.019032\n",
      "epoch 147; iter: 10; batch classifier loss: 0.038323; batch adversarial loss: 0.019715\n",
      "epoch 147; iter: 20; batch classifier loss: 0.038117; batch adversarial loss: 0.019738\n",
      "epoch 147; iter: 30; batch classifier loss: 0.037096; batch adversarial loss: 0.017906\n",
      "epoch 147; iter: 40; batch classifier loss: 0.036754; batch adversarial loss: 0.021281\n",
      "epoch 147; iter: 50; batch classifier loss: 0.037908; batch adversarial loss: 0.020383\n",
      "[148/500] Running epoch\n",
      "epoch 148; iter: 0; batch classifier loss: 0.036454; batch adversarial loss: 0.019410\n",
      "epoch 148; iter: 10; batch classifier loss: 0.038145; batch adversarial loss: 0.021616\n",
      "epoch 148; iter: 20; batch classifier loss: 0.037531; batch adversarial loss: 0.021534\n",
      "epoch 148; iter: 30; batch classifier loss: 0.035192; batch adversarial loss: 0.017840\n",
      "epoch 148; iter: 40; batch classifier loss: 0.037266; batch adversarial loss: 0.022927\n",
      "epoch 148; iter: 50; batch classifier loss: 0.035811; batch adversarial loss: 0.019950\n",
      "[149/500] Running epoch\n",
      "epoch 149; iter: 0; batch classifier loss: 0.038435; batch adversarial loss: 0.020476\n",
      "epoch 149; iter: 10; batch classifier loss: 0.036974; batch adversarial loss: 0.023227\n",
      "epoch 149; iter: 20; batch classifier loss: 0.037681; batch adversarial loss: 0.019765\n",
      "epoch 149; iter: 30; batch classifier loss: 0.038259; batch adversarial loss: 0.023038\n",
      "epoch 149; iter: 40; batch classifier loss: 0.038345; batch adversarial loss: 0.022422\n",
      "epoch 149; iter: 50; batch classifier loss: 0.037999; batch adversarial loss: 0.020769\n",
      "[150/500] Running epoch\n",
      "epoch 150; iter: 0; batch classifier loss: 0.037449; batch adversarial loss: 0.022982\n",
      "epoch 150; iter: 10; batch classifier loss: 0.036837; batch adversarial loss: 0.019187\n",
      "epoch 150; iter: 20; batch classifier loss: 0.036376; batch adversarial loss: 0.020368\n",
      "epoch 150; iter: 30; batch classifier loss: 0.036533; batch adversarial loss: 0.023807\n",
      "epoch 150; iter: 40; batch classifier loss: 0.039971; batch adversarial loss: 0.024818\n",
      "epoch 150; iter: 50; batch classifier loss: 0.039722; batch adversarial loss: 0.023057\n",
      "||w||: 1.308354139328003\n",
      "||w2||: 0.6181700825691223\n",
      "w.T g: [[0.28393195]]\n",
      "[151/500] Running epoch\n",
      "epoch 151; iter: 0; batch classifier loss: 0.036489; batch adversarial loss: 0.022405\n",
      "epoch 151; iter: 10; batch classifier loss: 0.039207; batch adversarial loss: 0.021032\n",
      "epoch 151; iter: 20; batch classifier loss: 0.037262; batch adversarial loss: 0.025189\n",
      "epoch 151; iter: 30; batch classifier loss: 0.039404; batch adversarial loss: 0.024588\n",
      "epoch 151; iter: 40; batch classifier loss: 0.037290; batch adversarial loss: 0.022351\n",
      "epoch 151; iter: 50; batch classifier loss: 0.039115; batch adversarial loss: 0.021357\n",
      "[152/500] Running epoch\n",
      "epoch 152; iter: 0; batch classifier loss: 0.039250; batch adversarial loss: 0.019650\n",
      "epoch 152; iter: 10; batch classifier loss: 0.037443; batch adversarial loss: 0.021553\n",
      "epoch 152; iter: 20; batch classifier loss: 0.035518; batch adversarial loss: 0.018220\n",
      "epoch 152; iter: 30; batch classifier loss: 0.040632; batch adversarial loss: 0.024723\n",
      "epoch 152; iter: 40; batch classifier loss: 0.039380; batch adversarial loss: 0.021324\n",
      "epoch 152; iter: 50; batch classifier loss: 0.037474; batch adversarial loss: 0.023060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153/500] Running epoch\n",
      "epoch 153; iter: 0; batch classifier loss: 0.037892; batch adversarial loss: 0.020487\n",
      "epoch 153; iter: 10; batch classifier loss: 0.037462; batch adversarial loss: 0.023386\n",
      "epoch 153; iter: 20; batch classifier loss: 0.037385; batch adversarial loss: 0.022706\n",
      "epoch 153; iter: 30; batch classifier loss: 0.036226; batch adversarial loss: 0.020459\n",
      "epoch 153; iter: 40; batch classifier loss: 0.035609; batch adversarial loss: 0.025105\n",
      "epoch 153; iter: 50; batch classifier loss: 0.038753; batch adversarial loss: 0.018667\n",
      "[154/500] Running epoch\n",
      "epoch 154; iter: 0; batch classifier loss: 0.038047; batch adversarial loss: 0.022878\n",
      "epoch 154; iter: 10; batch classifier loss: 0.037001; batch adversarial loss: 0.021041\n",
      "epoch 154; iter: 20; batch classifier loss: 0.036239; batch adversarial loss: 0.021360\n",
      "epoch 154; iter: 30; batch classifier loss: 0.037540; batch adversarial loss: 0.020053\n",
      "epoch 154; iter: 40; batch classifier loss: 0.036968; batch adversarial loss: 0.019547\n",
      "epoch 154; iter: 50; batch classifier loss: 0.039440; batch adversarial loss: 0.024545\n",
      "[155/500] Running epoch\n",
      "epoch 155; iter: 0; batch classifier loss: 0.037636; batch adversarial loss: 0.018710\n",
      "epoch 155; iter: 10; batch classifier loss: 0.037462; batch adversarial loss: 0.020124\n",
      "epoch 155; iter: 20; batch classifier loss: 0.037656; batch adversarial loss: 0.026223\n",
      "epoch 155; iter: 30; batch classifier loss: 0.038355; batch adversarial loss: 0.020340\n",
      "epoch 155; iter: 40; batch classifier loss: 0.036530; batch adversarial loss: 0.020254\n",
      "epoch 155; iter: 50; batch classifier loss: 0.037023; batch adversarial loss: 0.018233\n",
      "[156/500] Running epoch\n",
      "epoch 156; iter: 0; batch classifier loss: 0.036316; batch adversarial loss: 0.018826\n",
      "epoch 156; iter: 10; batch classifier loss: 0.037619; batch adversarial loss: 0.022769\n",
      "epoch 156; iter: 20; batch classifier loss: 0.036941; batch adversarial loss: 0.019159\n",
      "epoch 156; iter: 30; batch classifier loss: 0.040064; batch adversarial loss: 0.028291\n",
      "epoch 156; iter: 40; batch classifier loss: 0.037154; batch adversarial loss: 0.021600\n",
      "epoch 156; iter: 50; batch classifier loss: 0.038907; batch adversarial loss: 0.022944\n",
      "[157/500] Running epoch\n",
      "epoch 157; iter: 0; batch classifier loss: 0.038386; batch adversarial loss: 0.022704\n",
      "epoch 157; iter: 10; batch classifier loss: 0.036116; batch adversarial loss: 0.019195\n",
      "epoch 157; iter: 20; batch classifier loss: 0.039236; batch adversarial loss: 0.025641\n",
      "epoch 157; iter: 30; batch classifier loss: 0.035697; batch adversarial loss: 0.020049\n",
      "epoch 157; iter: 40; batch classifier loss: 0.037765; batch adversarial loss: 0.018598\n",
      "epoch 157; iter: 50; batch classifier loss: 0.036641; batch adversarial loss: 0.019067\n",
      "[158/500] Running epoch\n",
      "epoch 158; iter: 0; batch classifier loss: 0.035462; batch adversarial loss: 0.020114\n",
      "epoch 158; iter: 10; batch classifier loss: 0.037326; batch adversarial loss: 0.022634\n",
      "epoch 158; iter: 20; batch classifier loss: 0.036654; batch adversarial loss: 0.019110\n",
      "epoch 158; iter: 30; batch classifier loss: 0.038649; batch adversarial loss: 0.025413\n",
      "epoch 158; iter: 40; batch classifier loss: 0.036767; batch adversarial loss: 0.018813\n",
      "epoch 158; iter: 50; batch classifier loss: 0.037759; batch adversarial loss: 0.021130\n",
      "[159/500] Running epoch\n",
      "epoch 159; iter: 0; batch classifier loss: 0.037069; batch adversarial loss: 0.018924\n",
      "epoch 159; iter: 10; batch classifier loss: 0.036223; batch adversarial loss: 0.023513\n",
      "epoch 159; iter: 20; batch classifier loss: 0.039173; batch adversarial loss: 0.024176\n",
      "epoch 159; iter: 30; batch classifier loss: 0.039737; batch adversarial loss: 0.020627\n",
      "epoch 159; iter: 40; batch classifier loss: 0.036186; batch adversarial loss: 0.022070\n",
      "epoch 159; iter: 50; batch classifier loss: 0.037784; batch adversarial loss: 0.020397\n",
      "[160/500] Running epoch\n",
      "epoch 160; iter: 0; batch classifier loss: 0.038036; batch adversarial loss: 0.021416\n",
      "epoch 160; iter: 10; batch classifier loss: 0.036813; batch adversarial loss: 0.019500\n",
      "epoch 160; iter: 20; batch classifier loss: 0.036052; batch adversarial loss: 0.022840\n",
      "epoch 160; iter: 30; batch classifier loss: 0.038659; batch adversarial loss: 0.021585\n",
      "epoch 160; iter: 40; batch classifier loss: 0.039110; batch adversarial loss: 0.020777\n",
      "epoch 160; iter: 50; batch classifier loss: 0.039579; batch adversarial loss: 0.021063\n",
      "||w||: 1.3050575256347656\n",
      "||w2||: 0.6135368943214417\n",
      "w.T g: [[0.28823033]]\n",
      "[161/500] Running epoch\n",
      "epoch 161; iter: 0; batch classifier loss: 0.038500; batch adversarial loss: 0.022806\n",
      "epoch 161; iter: 10; batch classifier loss: 0.036430; batch adversarial loss: 0.019943\n",
      "epoch 161; iter: 20; batch classifier loss: 0.038549; batch adversarial loss: 0.022093\n",
      "epoch 161; iter: 30; batch classifier loss: 0.038738; batch adversarial loss: 0.026113\n",
      "epoch 161; iter: 40; batch classifier loss: 0.037641; batch adversarial loss: 0.019480\n",
      "epoch 161; iter: 50; batch classifier loss: 0.036257; batch adversarial loss: 0.021616\n",
      "[162/500] Running epoch\n",
      "epoch 162; iter: 0; batch classifier loss: 0.037131; batch adversarial loss: 0.020636\n",
      "epoch 162; iter: 10; batch classifier loss: 0.037740; batch adversarial loss: 0.020018\n",
      "epoch 162; iter: 20; batch classifier loss: 0.037621; batch adversarial loss: 0.021607\n",
      "epoch 162; iter: 30; batch classifier loss: 0.036657; batch adversarial loss: 0.018761\n",
      "epoch 162; iter: 40; batch classifier loss: 0.035737; batch adversarial loss: 0.022113\n",
      "epoch 162; iter: 50; batch classifier loss: 0.037451; batch adversarial loss: 0.021275\n",
      "[163/500] Running epoch\n",
      "epoch 163; iter: 0; batch classifier loss: 0.039480; batch adversarial loss: 0.025383\n",
      "epoch 163; iter: 10; batch classifier loss: 0.035950; batch adversarial loss: 0.021757\n",
      "epoch 163; iter: 20; batch classifier loss: 0.039256; batch adversarial loss: 0.023937\n",
      "epoch 163; iter: 30; batch classifier loss: 0.038809; batch adversarial loss: 0.022618\n",
      "epoch 163; iter: 40; batch classifier loss: 0.035570; batch adversarial loss: 0.023489\n",
      "epoch 163; iter: 50; batch classifier loss: 0.035260; batch adversarial loss: 0.021327\n",
      "[164/500] Running epoch\n",
      "epoch 164; iter: 0; batch classifier loss: 0.038778; batch adversarial loss: 0.026768\n",
      "epoch 164; iter: 10; batch classifier loss: 0.037570; batch adversarial loss: 0.021319\n",
      "epoch 164; iter: 20; batch classifier loss: 0.037903; batch adversarial loss: 0.020783\n",
      "epoch 164; iter: 30; batch classifier loss: 0.038613; batch adversarial loss: 0.020736\n",
      "epoch 164; iter: 40; batch classifier loss: 0.039308; batch adversarial loss: 0.023539\n",
      "epoch 164; iter: 50; batch classifier loss: 0.036380; batch adversarial loss: 0.023893\n",
      "[165/500] Running epoch\n",
      "epoch 165; iter: 0; batch classifier loss: 0.036883; batch adversarial loss: 0.021165\n",
      "epoch 165; iter: 10; batch classifier loss: 0.038874; batch adversarial loss: 0.021081\n",
      "epoch 165; iter: 20; batch classifier loss: 0.037049; batch adversarial loss: 0.021151\n",
      "epoch 165; iter: 30; batch classifier loss: 0.040096; batch adversarial loss: 0.023161\n",
      "epoch 165; iter: 40; batch classifier loss: 0.037911; batch adversarial loss: 0.024143\n",
      "epoch 165; iter: 50; batch classifier loss: 0.038070; batch adversarial loss: 0.026866\n",
      "[166/500] Running epoch\n",
      "epoch 166; iter: 0; batch classifier loss: 0.036364; batch adversarial loss: 0.020896\n",
      "epoch 166; iter: 10; batch classifier loss: 0.037677; batch adversarial loss: 0.016324\n",
      "epoch 166; iter: 20; batch classifier loss: 0.037717; batch adversarial loss: 0.021384\n",
      "epoch 166; iter: 30; batch classifier loss: 0.036824; batch adversarial loss: 0.020316\n",
      "epoch 166; iter: 40; batch classifier loss: 0.039324; batch adversarial loss: 0.021484\n",
      "epoch 166; iter: 50; batch classifier loss: 0.039512; batch adversarial loss: 0.022050\n",
      "[167/500] Running epoch\n",
      "epoch 167; iter: 0; batch classifier loss: 0.039999; batch adversarial loss: 0.019971\n",
      "epoch 167; iter: 10; batch classifier loss: 0.037681; batch adversarial loss: 0.022199\n",
      "epoch 167; iter: 20; batch classifier loss: 0.036442; batch adversarial loss: 0.021941\n",
      "epoch 167; iter: 30; batch classifier loss: 0.037408; batch adversarial loss: 0.024554\n",
      "epoch 167; iter: 40; batch classifier loss: 0.037954; batch adversarial loss: 0.021680\n",
      "epoch 167; iter: 50; batch classifier loss: 0.039492; batch adversarial loss: 0.025981\n",
      "[168/500] Running epoch\n",
      "epoch 168; iter: 0; batch classifier loss: 0.037669; batch adversarial loss: 0.024341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 168; iter: 10; batch classifier loss: 0.036836; batch adversarial loss: 0.019861\n",
      "epoch 168; iter: 20; batch classifier loss: 0.037201; batch adversarial loss: 0.022077\n",
      "epoch 168; iter: 30; batch classifier loss: 0.036990; batch adversarial loss: 0.021290\n",
      "epoch 168; iter: 40; batch classifier loss: 0.037108; batch adversarial loss: 0.023540\n",
      "epoch 168; iter: 50; batch classifier loss: 0.037801; batch adversarial loss: 0.018646\n",
      "[169/500] Running epoch\n",
      "epoch 169; iter: 0; batch classifier loss: 0.037075; batch adversarial loss: 0.021089\n",
      "epoch 169; iter: 10; batch classifier loss: 0.037887; batch adversarial loss: 0.018663\n",
      "epoch 169; iter: 20; batch classifier loss: 0.035705; batch adversarial loss: 0.019537\n",
      "epoch 169; iter: 30; batch classifier loss: 0.037495; batch adversarial loss: 0.023230\n",
      "epoch 169; iter: 40; batch classifier loss: 0.036789; batch adversarial loss: 0.022162\n",
      "epoch 169; iter: 50; batch classifier loss: 0.036244; batch adversarial loss: 0.023658\n",
      "[170/500] Running epoch\n",
      "epoch 170; iter: 0; batch classifier loss: 0.037731; batch adversarial loss: 0.024897\n",
      "epoch 170; iter: 10; batch classifier loss: 0.039275; batch adversarial loss: 0.019956\n",
      "epoch 170; iter: 20; batch classifier loss: 0.038788; batch adversarial loss: 0.022160\n",
      "epoch 170; iter: 30; batch classifier loss: 0.038734; batch adversarial loss: 0.024402\n",
      "epoch 170; iter: 40; batch classifier loss: 0.037896; batch adversarial loss: 0.019999\n",
      "epoch 170; iter: 50; batch classifier loss: 0.036717; batch adversarial loss: 0.022999\n",
      "||w||: 1.3025832176208496\n",
      "||w2||: 0.6098334193229675\n",
      "w.T g: [[0.29173714]]\n",
      "[171/500] Running epoch\n",
      "epoch 171; iter: 0; batch classifier loss: 0.035922; batch adversarial loss: 0.023148\n",
      "epoch 171; iter: 10; batch classifier loss: 0.036763; batch adversarial loss: 0.020730\n",
      "epoch 171; iter: 20; batch classifier loss: 0.035088; batch adversarial loss: 0.023299\n",
      "epoch 171; iter: 30; batch classifier loss: 0.038249; batch adversarial loss: 0.018034\n",
      "epoch 171; iter: 40; batch classifier loss: 0.038177; batch adversarial loss: 0.022644\n",
      "epoch 171; iter: 50; batch classifier loss: 0.037280; batch adversarial loss: 0.025543\n",
      "[172/500] Running epoch\n",
      "epoch 172; iter: 0; batch classifier loss: 0.039287; batch adversarial loss: 0.020525\n",
      "epoch 172; iter: 10; batch classifier loss: 0.037321; batch adversarial loss: 0.022296\n",
      "epoch 172; iter: 20; batch classifier loss: 0.038672; batch adversarial loss: 0.024151\n",
      "epoch 172; iter: 30; batch classifier loss: 0.038368; batch adversarial loss: 0.022248\n",
      "epoch 172; iter: 40; batch classifier loss: 0.036744; batch adversarial loss: 0.020969\n",
      "epoch 172; iter: 50; batch classifier loss: 0.036488; batch adversarial loss: 0.021523\n",
      "[173/500] Running epoch\n",
      "epoch 173; iter: 0; batch classifier loss: 0.036620; batch adversarial loss: 0.020605\n",
      "epoch 173; iter: 10; batch classifier loss: 0.037066; batch adversarial loss: 0.020870\n",
      "epoch 173; iter: 20; batch classifier loss: 0.035108; batch adversarial loss: 0.019215\n",
      "epoch 173; iter: 30; batch classifier loss: 0.038619; batch adversarial loss: 0.020002\n",
      "epoch 173; iter: 40; batch classifier loss: 0.037311; batch adversarial loss: 0.022525\n",
      "epoch 173; iter: 50; batch classifier loss: 0.035154; batch adversarial loss: 0.021662\n",
      "[174/500] Running epoch\n",
      "epoch 174; iter: 0; batch classifier loss: 0.035981; batch adversarial loss: 0.023751\n",
      "epoch 174; iter: 10; batch classifier loss: 0.040644; batch adversarial loss: 0.021374\n",
      "epoch 174; iter: 20; batch classifier loss: 0.038731; batch adversarial loss: 0.023255\n",
      "epoch 174; iter: 30; batch classifier loss: 0.037020; batch adversarial loss: 0.021557\n",
      "epoch 174; iter: 40; batch classifier loss: 0.036599; batch adversarial loss: 0.018938\n",
      "epoch 174; iter: 50; batch classifier loss: 0.039071; batch adversarial loss: 0.022983\n",
      "[175/500] Running epoch\n",
      "epoch 175; iter: 0; batch classifier loss: 0.037711; batch adversarial loss: 0.018052\n",
      "epoch 175; iter: 10; batch classifier loss: 0.037303; batch adversarial loss: 0.022506\n",
      "epoch 175; iter: 20; batch classifier loss: 0.039115; batch adversarial loss: 0.024526\n",
      "epoch 175; iter: 30; batch classifier loss: 0.039198; batch adversarial loss: 0.024614\n",
      "epoch 175; iter: 40; batch classifier loss: 0.039261; batch adversarial loss: 0.021485\n",
      "epoch 175; iter: 50; batch classifier loss: 0.038598; batch adversarial loss: 0.024238\n",
      "[176/500] Running epoch\n",
      "epoch 176; iter: 0; batch classifier loss: 0.040015; batch adversarial loss: 0.020766\n",
      "epoch 176; iter: 10; batch classifier loss: 0.038472; batch adversarial loss: 0.024400\n",
      "epoch 176; iter: 20; batch classifier loss: 0.038355; batch adversarial loss: 0.020582\n",
      "epoch 176; iter: 30; batch classifier loss: 0.037606; batch adversarial loss: 0.021826\n",
      "epoch 176; iter: 40; batch classifier loss: 0.038809; batch adversarial loss: 0.022651\n",
      "epoch 176; iter: 50; batch classifier loss: 0.037172; batch adversarial loss: 0.021639\n",
      "[177/500] Running epoch\n",
      "epoch 177; iter: 0; batch classifier loss: 0.037718; batch adversarial loss: 0.019104\n",
      "epoch 177; iter: 10; batch classifier loss: 0.036806; batch adversarial loss: 0.022500\n",
      "epoch 177; iter: 20; batch classifier loss: 0.034672; batch adversarial loss: 0.018033\n",
      "epoch 177; iter: 30; batch classifier loss: 0.035625; batch adversarial loss: 0.022973\n",
      "epoch 177; iter: 40; batch classifier loss: 0.036639; batch adversarial loss: 0.019525\n",
      "epoch 177; iter: 50; batch classifier loss: 0.038173; batch adversarial loss: 0.027763\n",
      "[178/500] Running epoch\n",
      "epoch 178; iter: 0; batch classifier loss: 0.037687; batch adversarial loss: 0.024204\n",
      "epoch 178; iter: 10; batch classifier loss: 0.038755; batch adversarial loss: 0.019804\n",
      "epoch 178; iter: 20; batch classifier loss: 0.039142; batch adversarial loss: 0.023542\n",
      "epoch 178; iter: 30; batch classifier loss: 0.037326; batch adversarial loss: 0.025613\n",
      "epoch 178; iter: 40; batch classifier loss: 0.036037; batch adversarial loss: 0.026906\n",
      "epoch 178; iter: 50; batch classifier loss: 0.037384; batch adversarial loss: 0.017943\n",
      "[179/500] Running epoch\n",
      "epoch 179; iter: 0; batch classifier loss: 0.038032; batch adversarial loss: 0.023442\n",
      "epoch 179; iter: 10; batch classifier loss: 0.039062; batch adversarial loss: 0.021315\n",
      "epoch 179; iter: 20; batch classifier loss: 0.037274; batch adversarial loss: 0.026811\n",
      "epoch 179; iter: 30; batch classifier loss: 0.037224; batch adversarial loss: 0.018939\n",
      "epoch 179; iter: 40; batch classifier loss: 0.038076; batch adversarial loss: 0.021520\n",
      "epoch 179; iter: 50; batch classifier loss: 0.038638; batch adversarial loss: 0.021287\n",
      "[180/500] Running epoch\n",
      "epoch 180; iter: 0; batch classifier loss: 0.037347; batch adversarial loss: 0.023016\n",
      "epoch 180; iter: 10; batch classifier loss: 0.037698; batch adversarial loss: 0.023945\n",
      "epoch 180; iter: 20; batch classifier loss: 0.036541; batch adversarial loss: 0.019372\n",
      "epoch 180; iter: 30; batch classifier loss: 0.038425; batch adversarial loss: 0.024148\n",
      "epoch 180; iter: 40; batch classifier loss: 0.034838; batch adversarial loss: 0.021893\n",
      "epoch 180; iter: 50; batch classifier loss: 0.037031; batch adversarial loss: 0.020870\n",
      "||w||: 1.3008469343185425\n",
      "||w2||: 0.6064148545265198\n",
      "w.T g: [[0.29465107]]\n",
      "[181/500] Running epoch\n",
      "epoch 181; iter: 0; batch classifier loss: 0.035996; batch adversarial loss: 0.020798\n",
      "epoch 181; iter: 10; batch classifier loss: 0.038432; batch adversarial loss: 0.021086\n",
      "epoch 181; iter: 20; batch classifier loss: 0.038884; batch adversarial loss: 0.024559\n",
      "epoch 181; iter: 30; batch classifier loss: 0.036733; batch adversarial loss: 0.020475\n",
      "epoch 181; iter: 40; batch classifier loss: 0.039221; batch adversarial loss: 0.021952\n",
      "epoch 181; iter: 50; batch classifier loss: 0.039554; batch adversarial loss: 0.019971\n",
      "[182/500] Running epoch\n",
      "epoch 182; iter: 0; batch classifier loss: 0.037221; batch adversarial loss: 0.019395\n",
      "epoch 182; iter: 10; batch classifier loss: 0.036601; batch adversarial loss: 0.025219\n",
      "epoch 182; iter: 20; batch classifier loss: 0.037090; batch adversarial loss: 0.025512\n",
      "epoch 182; iter: 30; batch classifier loss: 0.037876; batch adversarial loss: 0.022465\n",
      "epoch 182; iter: 40; batch classifier loss: 0.037554; batch adversarial loss: 0.020486\n",
      "epoch 182; iter: 50; batch classifier loss: 0.039459; batch adversarial loss: 0.023577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183/500] Running epoch\n",
      "epoch 183; iter: 0; batch classifier loss: 0.036502; batch adversarial loss: 0.018550\n",
      "epoch 183; iter: 10; batch classifier loss: 0.039621; batch adversarial loss: 0.021599\n",
      "epoch 183; iter: 20; batch classifier loss: 0.035464; batch adversarial loss: 0.022895\n",
      "epoch 183; iter: 30; batch classifier loss: 0.038854; batch adversarial loss: 0.022654\n",
      "epoch 183; iter: 40; batch classifier loss: 0.038256; batch adversarial loss: 0.020428\n",
      "epoch 183; iter: 50; batch classifier loss: 0.037283; batch adversarial loss: 0.023533\n",
      "[184/500] Running epoch\n",
      "epoch 184; iter: 0; batch classifier loss: 0.038012; batch adversarial loss: 0.021492\n",
      "epoch 184; iter: 10; batch classifier loss: 0.036224; batch adversarial loss: 0.019864\n",
      "epoch 184; iter: 20; batch classifier loss: 0.037044; batch adversarial loss: 0.025044\n",
      "epoch 184; iter: 30; batch classifier loss: 0.038656; batch adversarial loss: 0.024442\n",
      "epoch 184; iter: 40; batch classifier loss: 0.039213; batch adversarial loss: 0.025056\n",
      "epoch 184; iter: 50; batch classifier loss: 0.039239; batch adversarial loss: 0.020723\n",
      "[185/500] Running epoch\n",
      "epoch 185; iter: 0; batch classifier loss: 0.037783; batch adversarial loss: 0.019680\n",
      "epoch 185; iter: 10; batch classifier loss: 0.039062; batch adversarial loss: 0.023481\n",
      "epoch 185; iter: 20; batch classifier loss: 0.034954; batch adversarial loss: 0.022474\n",
      "epoch 185; iter: 30; batch classifier loss: 0.038271; batch adversarial loss: 0.025190\n",
      "epoch 185; iter: 40; batch classifier loss: 0.038491; batch adversarial loss: 0.021054\n",
      "epoch 185; iter: 50; batch classifier loss: 0.035088; batch adversarial loss: 0.024864\n",
      "[186/500] Running epoch\n",
      "epoch 186; iter: 0; batch classifier loss: 0.039299; batch adversarial loss: 0.023113\n",
      "epoch 186; iter: 10; batch classifier loss: 0.035936; batch adversarial loss: 0.018618\n",
      "epoch 186; iter: 20; batch classifier loss: 0.036648; batch adversarial loss: 0.022790\n",
      "epoch 186; iter: 30; batch classifier loss: 0.036354; batch adversarial loss: 0.022092\n",
      "epoch 186; iter: 40; batch classifier loss: 0.035253; batch adversarial loss: 0.019398\n",
      "epoch 186; iter: 50; batch classifier loss: 0.040154; batch adversarial loss: 0.023179\n",
      "[187/500] Running epoch\n",
      "epoch 187; iter: 0; batch classifier loss: 0.039872; batch adversarial loss: 0.021188\n",
      "epoch 187; iter: 10; batch classifier loss: 0.034328; batch adversarial loss: 0.021398\n",
      "epoch 187; iter: 20; batch classifier loss: 0.037101; batch adversarial loss: 0.020366\n",
      "epoch 187; iter: 30; batch classifier loss: 0.036653; batch adversarial loss: 0.022277\n",
      "epoch 187; iter: 40; batch classifier loss: 0.037269; batch adversarial loss: 0.023580\n",
      "epoch 187; iter: 50; batch classifier loss: 0.038121; batch adversarial loss: 0.022978\n",
      "[188/500] Running epoch\n",
      "epoch 188; iter: 0; batch classifier loss: 0.038749; batch adversarial loss: 0.025920\n",
      "epoch 188; iter: 10; batch classifier loss: 0.036992; batch adversarial loss: 0.024818\n",
      "epoch 188; iter: 20; batch classifier loss: 0.037800; batch adversarial loss: 0.022621\n",
      "epoch 188; iter: 30; batch classifier loss: 0.036537; batch adversarial loss: 0.023101\n",
      "epoch 188; iter: 40; batch classifier loss: 0.035784; batch adversarial loss: 0.021608\n",
      "epoch 188; iter: 50; batch classifier loss: 0.038606; batch adversarial loss: 0.024073\n",
      "[189/500] Running epoch\n",
      "epoch 189; iter: 0; batch classifier loss: 0.041859; batch adversarial loss: 0.025806\n",
      "epoch 189; iter: 10; batch classifier loss: 0.038524; batch adversarial loss: 0.022103\n",
      "epoch 189; iter: 20; batch classifier loss: 0.037458; batch adversarial loss: 0.022028\n",
      "epoch 189; iter: 30; batch classifier loss: 0.039259; batch adversarial loss: 0.025650\n",
      "epoch 189; iter: 40; batch classifier loss: 0.039079; batch adversarial loss: 0.022330\n",
      "epoch 189; iter: 50; batch classifier loss: 0.039129; batch adversarial loss: 0.025965\n",
      "[190/500] Running epoch\n",
      "epoch 190; iter: 0; batch classifier loss: 0.036209; batch adversarial loss: 0.022491\n",
      "epoch 190; iter: 10; batch classifier loss: 0.036931; batch adversarial loss: 0.020243\n",
      "epoch 190; iter: 20; batch classifier loss: 0.037538; batch adversarial loss: 0.022459\n",
      "epoch 190; iter: 30; batch classifier loss: 0.039022; batch adversarial loss: 0.023806\n",
      "epoch 190; iter: 40; batch classifier loss: 0.038100; batch adversarial loss: 0.020781\n",
      "epoch 190; iter: 50; batch classifier loss: 0.037621; batch adversarial loss: 0.022680\n",
      "||w||: 1.299694299697876\n",
      "||w2||: 0.6038211584091187\n",
      "w.T g: [[0.29708222]]\n",
      "[191/500] Running epoch\n",
      "epoch 191; iter: 0; batch classifier loss: 0.035498; batch adversarial loss: 0.022530\n",
      "epoch 191; iter: 10; batch classifier loss: 0.037337; batch adversarial loss: 0.021414\n",
      "epoch 191; iter: 20; batch classifier loss: 0.037356; batch adversarial loss: 0.022918\n",
      "epoch 191; iter: 30; batch classifier loss: 0.039682; batch adversarial loss: 0.022077\n",
      "epoch 191; iter: 40; batch classifier loss: 0.038560; batch adversarial loss: 0.022056\n",
      "epoch 191; iter: 50; batch classifier loss: 0.038103; batch adversarial loss: 0.024259\n",
      "[192/500] Running epoch\n",
      "epoch 192; iter: 0; batch classifier loss: 0.038702; batch adversarial loss: 0.021488\n",
      "epoch 192; iter: 10; batch classifier loss: 0.036495; batch adversarial loss: 0.020718\n",
      "epoch 192; iter: 20; batch classifier loss: 0.037419; batch adversarial loss: 0.020668\n",
      "epoch 192; iter: 30; batch classifier loss: 0.036234; batch adversarial loss: 0.022930\n",
      "epoch 192; iter: 40; batch classifier loss: 0.038610; batch adversarial loss: 0.023882\n",
      "epoch 192; iter: 50; batch classifier loss: 0.039473; batch adversarial loss: 0.023723\n",
      "[193/500] Running epoch\n",
      "epoch 193; iter: 0; batch classifier loss: 0.037518; batch adversarial loss: 0.024726\n",
      "epoch 193; iter: 10; batch classifier loss: 0.039037; batch adversarial loss: 0.021043\n",
      "epoch 193; iter: 20; batch classifier loss: 0.035446; batch adversarial loss: 0.021725\n",
      "epoch 193; iter: 30; batch classifier loss: 0.036029; batch adversarial loss: 0.022926\n",
      "epoch 193; iter: 40; batch classifier loss: 0.037615; batch adversarial loss: 0.023768\n",
      "epoch 193; iter: 50; batch classifier loss: 0.040207; batch adversarial loss: 0.028300\n",
      "[194/500] Running epoch\n",
      "epoch 194; iter: 0; batch classifier loss: 0.034754; batch adversarial loss: 0.017650\n",
      "epoch 194; iter: 10; batch classifier loss: 0.037571; batch adversarial loss: 0.020561\n",
      "epoch 194; iter: 20; batch classifier loss: 0.038341; batch adversarial loss: 0.022739\n",
      "epoch 194; iter: 30; batch classifier loss: 0.038052; batch adversarial loss: 0.023586\n",
      "epoch 194; iter: 40; batch classifier loss: 0.038724; batch adversarial loss: 0.019837\n",
      "epoch 194; iter: 50; batch classifier loss: 0.036317; batch adversarial loss: 0.023293\n",
      "[195/500] Running epoch\n",
      "epoch 195; iter: 0; batch classifier loss: 0.036785; batch adversarial loss: 0.018677\n",
      "epoch 195; iter: 10; batch classifier loss: 0.037686; batch adversarial loss: 0.021802\n",
      "epoch 195; iter: 20; batch classifier loss: 0.037012; batch adversarial loss: 0.024542\n",
      "epoch 195; iter: 30; batch classifier loss: 0.039471; batch adversarial loss: 0.023740\n",
      "epoch 195; iter: 40; batch classifier loss: 0.036823; batch adversarial loss: 0.022816\n",
      "epoch 195; iter: 50; batch classifier loss: 0.036469; batch adversarial loss: 0.019418\n",
      "[196/500] Running epoch\n",
      "epoch 196; iter: 0; batch classifier loss: 0.038004; batch adversarial loss: 0.021983\n",
      "epoch 196; iter: 10; batch classifier loss: 0.038019; batch adversarial loss: 0.022636\n",
      "epoch 196; iter: 20; batch classifier loss: 0.037659; batch adversarial loss: 0.021923\n",
      "epoch 196; iter: 30; batch classifier loss: 0.036234; batch adversarial loss: 0.022559\n",
      "epoch 196; iter: 40; batch classifier loss: 0.041026; batch adversarial loss: 0.021603\n",
      "epoch 196; iter: 50; batch classifier loss: 0.038932; batch adversarial loss: 0.023363\n",
      "[197/500] Running epoch\n",
      "epoch 197; iter: 0; batch classifier loss: 0.036596; batch adversarial loss: 0.022813\n",
      "epoch 197; iter: 10; batch classifier loss: 0.037446; batch adversarial loss: 0.021499\n",
      "epoch 197; iter: 20; batch classifier loss: 0.037191; batch adversarial loss: 0.024499\n",
      "epoch 197; iter: 30; batch classifier loss: 0.037703; batch adversarial loss: 0.022472\n",
      "epoch 197; iter: 40; batch classifier loss: 0.037440; batch adversarial loss: 0.020529\n",
      "epoch 197; iter: 50; batch classifier loss: 0.037835; batch adversarial loss: 0.022610\n",
      "[198/500] Running epoch\n",
      "epoch 198; iter: 0; batch classifier loss: 0.037450; batch adversarial loss: 0.022776\n",
      "epoch 198; iter: 10; batch classifier loss: 0.036785; batch adversarial loss: 0.018596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198; iter: 20; batch classifier loss: 0.038673; batch adversarial loss: 0.024528\n",
      "epoch 198; iter: 30; batch classifier loss: 0.038078; batch adversarial loss: 0.025645\n",
      "epoch 198; iter: 40; batch classifier loss: 0.036796; batch adversarial loss: 0.022762\n",
      "epoch 198; iter: 50; batch classifier loss: 0.036773; batch adversarial loss: 0.023187\n",
      "[199/500] Running epoch\n",
      "epoch 199; iter: 0; batch classifier loss: 0.035643; batch adversarial loss: 0.021279\n",
      "epoch 199; iter: 10; batch classifier loss: 0.039625; batch adversarial loss: 0.024917\n",
      "epoch 199; iter: 20; batch classifier loss: 0.038001; batch adversarial loss: 0.023332\n",
      "epoch 199; iter: 30; batch classifier loss: 0.037601; batch adversarial loss: 0.021395\n",
      "epoch 199; iter: 40; batch classifier loss: 0.035728; batch adversarial loss: 0.025372\n",
      "epoch 199; iter: 50; batch classifier loss: 0.037440; batch adversarial loss: 0.021709\n",
      "[200/500] Running epoch\n",
      "epoch 200; iter: 0; batch classifier loss: 0.038960; batch adversarial loss: 0.021624\n",
      "epoch 200; iter: 10; batch classifier loss: 0.036349; batch adversarial loss: 0.022026\n",
      "epoch 200; iter: 20; batch classifier loss: 0.038168; batch adversarial loss: 0.020620\n",
      "epoch 200; iter: 30; batch classifier loss: 0.037574; batch adversarial loss: 0.020962\n",
      "epoch 200; iter: 40; batch classifier loss: 0.037159; batch adversarial loss: 0.024890\n",
      "epoch 200; iter: 50; batch classifier loss: 0.035915; batch adversarial loss: 0.020062\n",
      "||w||: 1.2989145517349243\n",
      "||w2||: 0.6017588376998901\n",
      "w.T g: [[0.29899959]]\n",
      "[201/500] Running epoch\n",
      "epoch 201; iter: 0; batch classifier loss: 0.040178; batch adversarial loss: 0.026037\n",
      "epoch 201; iter: 10; batch classifier loss: 0.037685; batch adversarial loss: 0.022705\n",
      "epoch 201; iter: 20; batch classifier loss: 0.035195; batch adversarial loss: 0.023149\n",
      "epoch 201; iter: 30; batch classifier loss: 0.036520; batch adversarial loss: 0.022225\n",
      "epoch 201; iter: 40; batch classifier loss: 0.037713; batch adversarial loss: 0.019973\n",
      "epoch 201; iter: 50; batch classifier loss: 0.036687; batch adversarial loss: 0.026459\n",
      "[202/500] Running epoch\n",
      "epoch 202; iter: 0; batch classifier loss: 0.037839; batch adversarial loss: 0.023467\n",
      "epoch 202; iter: 10; batch classifier loss: 0.035582; batch adversarial loss: 0.023053\n",
      "epoch 202; iter: 20; batch classifier loss: 0.036383; batch adversarial loss: 0.022028\n",
      "epoch 202; iter: 30; batch classifier loss: 0.036536; batch adversarial loss: 0.022909\n",
      "epoch 202; iter: 40; batch classifier loss: 0.040309; batch adversarial loss: 0.020330\n",
      "epoch 202; iter: 50; batch classifier loss: 0.039588; batch adversarial loss: 0.026841\n",
      "[203/500] Running epoch\n",
      "epoch 203; iter: 0; batch classifier loss: 0.038316; batch adversarial loss: 0.020170\n",
      "epoch 203; iter: 10; batch classifier loss: 0.038214; batch adversarial loss: 0.023121\n",
      "epoch 203; iter: 20; batch classifier loss: 0.037333; batch adversarial loss: 0.024733\n",
      "epoch 203; iter: 30; batch classifier loss: 0.037115; batch adversarial loss: 0.020842\n",
      "epoch 203; iter: 40; batch classifier loss: 0.037770; batch adversarial loss: 0.022501\n",
      "epoch 203; iter: 50; batch classifier loss: 0.036498; batch adversarial loss: 0.022203\n",
      "[204/500] Running epoch\n",
      "epoch 204; iter: 0; batch classifier loss: 0.036569; batch adversarial loss: 0.022024\n",
      "epoch 204; iter: 10; batch classifier loss: 0.039509; batch adversarial loss: 0.028580\n",
      "epoch 204; iter: 20; batch classifier loss: 0.037532; batch adversarial loss: 0.022289\n",
      "epoch 204; iter: 30; batch classifier loss: 0.037312; batch adversarial loss: 0.021463\n",
      "epoch 204; iter: 40; batch classifier loss: 0.037108; batch adversarial loss: 0.020667\n",
      "epoch 204; iter: 50; batch classifier loss: 0.036624; batch adversarial loss: 0.019461\n",
      "[205/500] Running epoch\n",
      "epoch 205; iter: 0; batch classifier loss: 0.038375; batch adversarial loss: 0.028322\n",
      "epoch 205; iter: 10; batch classifier loss: 0.036664; batch adversarial loss: 0.025919\n",
      "epoch 205; iter: 20; batch classifier loss: 0.038327; batch adversarial loss: 0.024319\n",
      "epoch 205; iter: 30; batch classifier loss: 0.036601; batch adversarial loss: 0.020957\n",
      "epoch 205; iter: 40; batch classifier loss: 0.035514; batch adversarial loss: 0.021749\n",
      "epoch 205; iter: 50; batch classifier loss: 0.034608; batch adversarial loss: 0.021757\n",
      "[206/500] Running epoch\n",
      "epoch 206; iter: 0; batch classifier loss: 0.038789; batch adversarial loss: 0.025525\n",
      "epoch 206; iter: 10; batch classifier loss: 0.036551; batch adversarial loss: 0.023069\n",
      "epoch 206; iter: 20; batch classifier loss: 0.038709; batch adversarial loss: 0.024087\n",
      "epoch 206; iter: 30; batch classifier loss: 0.037009; batch adversarial loss: 0.020884\n",
      "epoch 206; iter: 40; batch classifier loss: 0.038375; batch adversarial loss: 0.017460\n",
      "epoch 206; iter: 50; batch classifier loss: 0.037827; batch adversarial loss: 0.025554\n",
      "[207/500] Running epoch\n",
      "epoch 207; iter: 0; batch classifier loss: 0.039805; batch adversarial loss: 0.022841\n",
      "epoch 207; iter: 10; batch classifier loss: 0.036711; batch adversarial loss: 0.022808\n",
      "epoch 207; iter: 20; batch classifier loss: 0.035473; batch adversarial loss: 0.022580\n",
      "epoch 207; iter: 30; batch classifier loss: 0.036779; batch adversarial loss: 0.021325\n",
      "epoch 207; iter: 40; batch classifier loss: 0.036043; batch adversarial loss: 0.020302\n",
      "epoch 207; iter: 50; batch classifier loss: 0.036385; batch adversarial loss: 0.018685\n",
      "[208/500] Running epoch\n",
      "epoch 208; iter: 0; batch classifier loss: 0.039643; batch adversarial loss: 0.020067\n",
      "epoch 208; iter: 10; batch classifier loss: 0.037371; batch adversarial loss: 0.024558\n",
      "epoch 208; iter: 20; batch classifier loss: 0.036694; batch adversarial loss: 0.020315\n",
      "epoch 208; iter: 30; batch classifier loss: 0.036941; batch adversarial loss: 0.021574\n",
      "epoch 208; iter: 40; batch classifier loss: 0.037340; batch adversarial loss: 0.025717\n",
      "epoch 208; iter: 50; batch classifier loss: 0.036327; batch adversarial loss: 0.021299\n",
      "[209/500] Running epoch\n",
      "epoch 209; iter: 0; batch classifier loss: 0.036437; batch adversarial loss: 0.023805\n",
      "epoch 209; iter: 10; batch classifier loss: 0.041889; batch adversarial loss: 0.028668\n",
      "epoch 209; iter: 20; batch classifier loss: 0.036307; batch adversarial loss: 0.023801\n",
      "epoch 209; iter: 30; batch classifier loss: 0.036519; batch adversarial loss: 0.025044\n",
      "epoch 209; iter: 40; batch classifier loss: 0.036659; batch adversarial loss: 0.022293\n",
      "epoch 209; iter: 50; batch classifier loss: 0.036130; batch adversarial loss: 0.019627\n",
      "[210/500] Running epoch\n",
      "epoch 210; iter: 0; batch classifier loss: 0.039026; batch adversarial loss: 0.024751\n",
      "epoch 210; iter: 10; batch classifier loss: 0.036437; batch adversarial loss: 0.029867\n",
      "epoch 210; iter: 20; batch classifier loss: 0.035967; batch adversarial loss: 0.022844\n",
      "epoch 210; iter: 30; batch classifier loss: 0.038043; batch adversarial loss: 0.024825\n",
      "epoch 210; iter: 40; batch classifier loss: 0.039630; batch adversarial loss: 0.023729\n",
      "epoch 210; iter: 50; batch classifier loss: 0.037655; batch adversarial loss: 0.020896\n",
      "||w||: 1.298410415649414\n",
      "||w2||: 0.60023432970047\n",
      "w.T g: [[0.3004845]]\n",
      "[211/500] Running epoch\n",
      "epoch 211; iter: 0; batch classifier loss: 0.038045; batch adversarial loss: 0.024733\n",
      "epoch 211; iter: 10; batch classifier loss: 0.034224; batch adversarial loss: 0.019331\n",
      "epoch 211; iter: 20; batch classifier loss: 0.037910; batch adversarial loss: 0.023619\n",
      "epoch 211; iter: 30; batch classifier loss: 0.038570; batch adversarial loss: 0.022091\n",
      "epoch 211; iter: 40; batch classifier loss: 0.037575; batch adversarial loss: 0.030047\n",
      "epoch 211; iter: 50; batch classifier loss: 0.036853; batch adversarial loss: 0.021176\n",
      "[212/500] Running epoch\n",
      "epoch 212; iter: 0; batch classifier loss: 0.038783; batch adversarial loss: 0.023914\n",
      "epoch 212; iter: 10; batch classifier loss: 0.038868; batch adversarial loss: 0.025170\n",
      "epoch 212; iter: 20; batch classifier loss: 0.037653; batch adversarial loss: 0.023483\n",
      "epoch 212; iter: 30; batch classifier loss: 0.037566; batch adversarial loss: 0.024529\n",
      "epoch 212; iter: 40; batch classifier loss: 0.036511; batch adversarial loss: 0.021769\n",
      "epoch 212; iter: 50; batch classifier loss: 0.038468; batch adversarial loss: 0.024887\n",
      "[213/500] Running epoch\n",
      "epoch 213; iter: 0; batch classifier loss: 0.037935; batch adversarial loss: 0.026657\n",
      "epoch 213; iter: 10; batch classifier loss: 0.041397; batch adversarial loss: 0.025836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 213; iter: 20; batch classifier loss: 0.038709; batch adversarial loss: 0.024234\n",
      "epoch 213; iter: 30; batch classifier loss: 0.036725; batch adversarial loss: 0.017481\n",
      "epoch 213; iter: 40; batch classifier loss: 0.039175; batch adversarial loss: 0.026817\n",
      "epoch 213; iter: 50; batch classifier loss: 0.039201; batch adversarial loss: 0.022372\n",
      "[214/500] Running epoch\n",
      "epoch 214; iter: 0; batch classifier loss: 0.035897; batch adversarial loss: 0.022986\n",
      "epoch 214; iter: 10; batch classifier loss: 0.036854; batch adversarial loss: 0.023055\n",
      "epoch 214; iter: 20; batch classifier loss: 0.039311; batch adversarial loss: 0.026592\n",
      "epoch 214; iter: 30; batch classifier loss: 0.037410; batch adversarial loss: 0.022341\n",
      "epoch 214; iter: 40; batch classifier loss: 0.035630; batch adversarial loss: 0.017763\n",
      "epoch 214; iter: 50; batch classifier loss: 0.035882; batch adversarial loss: 0.023346\n",
      "[215/500] Running epoch\n",
      "epoch 215; iter: 0; batch classifier loss: 0.038292; batch adversarial loss: 0.023882\n",
      "epoch 215; iter: 10; batch classifier loss: 0.036055; batch adversarial loss: 0.022279\n",
      "epoch 215; iter: 20; batch classifier loss: 0.038576; batch adversarial loss: 0.026870\n",
      "epoch 215; iter: 30; batch classifier loss: 0.037331; batch adversarial loss: 0.021900\n",
      "epoch 215; iter: 40; batch classifier loss: 0.039092; batch adversarial loss: 0.025211\n",
      "epoch 215; iter: 50; batch classifier loss: 0.037928; batch adversarial loss: 0.020516\n",
      "[216/500] Running epoch\n",
      "epoch 216; iter: 0; batch classifier loss: 0.037024; batch adversarial loss: 0.022490\n",
      "epoch 216; iter: 10; batch classifier loss: 0.037664; batch adversarial loss: 0.026340\n",
      "epoch 216; iter: 20; batch classifier loss: 0.034845; batch adversarial loss: 0.022361\n",
      "epoch 216; iter: 30; batch classifier loss: 0.041015; batch adversarial loss: 0.021145\n",
      "epoch 216; iter: 40; batch classifier loss: 0.037718; batch adversarial loss: 0.020837\n",
      "epoch 216; iter: 50; batch classifier loss: 0.037148; batch adversarial loss: 0.025986\n",
      "[217/500] Running epoch\n",
      "epoch 217; iter: 0; batch classifier loss: 0.038101; batch adversarial loss: 0.024043\n",
      "epoch 217; iter: 10; batch classifier loss: 0.038681; batch adversarial loss: 0.023387\n",
      "epoch 217; iter: 20; batch classifier loss: 0.039096; batch adversarial loss: 0.019042\n",
      "epoch 217; iter: 30; batch classifier loss: 0.037895; batch adversarial loss: 0.023147\n",
      "epoch 217; iter: 40; batch classifier loss: 0.035692; batch adversarial loss: 0.023930\n",
      "epoch 217; iter: 50; batch classifier loss: 0.037884; batch adversarial loss: 0.023272\n",
      "[218/500] Running epoch\n",
      "epoch 218; iter: 0; batch classifier loss: 0.037528; batch adversarial loss: 0.024451\n",
      "epoch 218; iter: 10; batch classifier loss: 0.036953; batch adversarial loss: 0.018710\n",
      "epoch 218; iter: 20; batch classifier loss: 0.037038; batch adversarial loss: 0.022371\n",
      "epoch 218; iter: 30; batch classifier loss: 0.035581; batch adversarial loss: 0.020568\n",
      "epoch 218; iter: 40; batch classifier loss: 0.037986; batch adversarial loss: 0.021043\n",
      "epoch 218; iter: 50; batch classifier loss: 0.038070; batch adversarial loss: 0.023685\n",
      "[219/500] Running epoch\n",
      "epoch 219; iter: 0; batch classifier loss: 0.036976; batch adversarial loss: 0.020525\n",
      "epoch 219; iter: 10; batch classifier loss: 0.038035; batch adversarial loss: 0.027041\n",
      "epoch 219; iter: 20; batch classifier loss: 0.037848; batch adversarial loss: 0.024603\n",
      "epoch 219; iter: 30; batch classifier loss: 0.036478; batch adversarial loss: 0.021569\n",
      "epoch 219; iter: 40; batch classifier loss: 0.038769; batch adversarial loss: 0.022616\n",
      "epoch 219; iter: 50; batch classifier loss: 0.038550; batch adversarial loss: 0.025040\n",
      "[220/500] Running epoch\n",
      "epoch 220; iter: 0; batch classifier loss: 0.038495; batch adversarial loss: 0.020793\n",
      "epoch 220; iter: 10; batch classifier loss: 0.038268; batch adversarial loss: 0.025649\n",
      "epoch 220; iter: 20; batch classifier loss: 0.038728; batch adversarial loss: 0.024788\n",
      "epoch 220; iter: 30; batch classifier loss: 0.036796; batch adversarial loss: 0.020241\n",
      "epoch 220; iter: 40; batch classifier loss: 0.039750; batch adversarial loss: 0.029124\n",
      "epoch 220; iter: 50; batch classifier loss: 0.038682; batch adversarial loss: 0.024114\n",
      "||w||: 1.2981605529785156\n",
      "||w2||: 0.5990511775016785\n",
      "w.T g: [[0.30159954]]\n",
      "[221/500] Running epoch\n",
      "epoch 221; iter: 0; batch classifier loss: 0.038154; batch adversarial loss: 0.022357\n",
      "epoch 221; iter: 10; batch classifier loss: 0.039238; batch adversarial loss: 0.019888\n",
      "epoch 221; iter: 20; batch classifier loss: 0.035629; batch adversarial loss: 0.021846\n",
      "epoch 221; iter: 30; batch classifier loss: 0.036562; batch adversarial loss: 0.023173\n",
      "epoch 221; iter: 40; batch classifier loss: 0.037154; batch adversarial loss: 0.025075\n",
      "epoch 221; iter: 50; batch classifier loss: 0.037070; batch adversarial loss: 0.025029\n",
      "[222/500] Running epoch\n",
      "epoch 222; iter: 0; batch classifier loss: 0.037671; batch adversarial loss: 0.021658\n",
      "epoch 222; iter: 10; batch classifier loss: 0.036991; batch adversarial loss: 0.019508\n",
      "epoch 222; iter: 20; batch classifier loss: 0.036849; batch adversarial loss: 0.020085\n",
      "epoch 222; iter: 30; batch classifier loss: 0.038274; batch adversarial loss: 0.021757\n",
      "epoch 222; iter: 40; batch classifier loss: 0.037518; batch adversarial loss: 0.019493\n",
      "epoch 222; iter: 50; batch classifier loss: 0.037319; batch adversarial loss: 0.020054\n",
      "[223/500] Running epoch\n",
      "epoch 223; iter: 0; batch classifier loss: 0.035977; batch adversarial loss: 0.023934\n",
      "epoch 223; iter: 10; batch classifier loss: 0.037484; batch adversarial loss: 0.024361\n",
      "epoch 223; iter: 20; batch classifier loss: 0.038289; batch adversarial loss: 0.026539\n",
      "epoch 223; iter: 30; batch classifier loss: 0.039507; batch adversarial loss: 0.025949\n",
      "epoch 223; iter: 40; batch classifier loss: 0.037020; batch adversarial loss: 0.026220\n",
      "epoch 223; iter: 50; batch classifier loss: 0.037336; batch adversarial loss: 0.023564\n",
      "[224/500] Running epoch\n",
      "epoch 224; iter: 0; batch classifier loss: 0.035764; batch adversarial loss: 0.017969\n",
      "epoch 224; iter: 10; batch classifier loss: 0.038884; batch adversarial loss: 0.023024\n",
      "epoch 224; iter: 20; batch classifier loss: 0.038288; batch adversarial loss: 0.025758\n",
      "epoch 224; iter: 30; batch classifier loss: 0.037904; batch adversarial loss: 0.025180\n",
      "epoch 224; iter: 40; batch classifier loss: 0.040132; batch adversarial loss: 0.028700\n",
      "epoch 224; iter: 50; batch classifier loss: 0.039353; batch adversarial loss: 0.022407\n",
      "[225/500] Running epoch\n",
      "epoch 225; iter: 0; batch classifier loss: 0.039132; batch adversarial loss: 0.022820\n",
      "epoch 225; iter: 10; batch classifier loss: 0.039349; batch adversarial loss: 0.023055\n",
      "epoch 225; iter: 20; batch classifier loss: 0.037648; batch adversarial loss: 0.021883\n",
      "epoch 225; iter: 30; batch classifier loss: 0.038070; batch adversarial loss: 0.022045\n",
      "epoch 225; iter: 40; batch classifier loss: 0.036779; batch adversarial loss: 0.024379\n",
      "epoch 225; iter: 50; batch classifier loss: 0.038578; batch adversarial loss: 0.021206\n",
      "[226/500] Running epoch\n",
      "epoch 226; iter: 0; batch classifier loss: 0.036518; batch adversarial loss: 0.020176\n",
      "epoch 226; iter: 10; batch classifier loss: 0.035903; batch adversarial loss: 0.024965\n",
      "epoch 226; iter: 20; batch classifier loss: 0.037763; batch adversarial loss: 0.020857\n",
      "epoch 226; iter: 30; batch classifier loss: 0.038500; batch adversarial loss: 0.022450\n",
      "epoch 226; iter: 40; batch classifier loss: 0.038840; batch adversarial loss: 0.024835\n",
      "epoch 226; iter: 50; batch classifier loss: 0.038835; batch adversarial loss: 0.024489\n",
      "[227/500] Running epoch\n",
      "epoch 227; iter: 0; batch classifier loss: 0.039428; batch adversarial loss: 0.022732\n",
      "epoch 227; iter: 10; batch classifier loss: 0.037301; batch adversarial loss: 0.023651\n",
      "epoch 227; iter: 20; batch classifier loss: 0.037678; batch adversarial loss: 0.023612\n",
      "epoch 227; iter: 30; batch classifier loss: 0.036559; batch adversarial loss: 0.022696\n",
      "epoch 227; iter: 40; batch classifier loss: 0.036938; batch adversarial loss: 0.025230\n",
      "epoch 227; iter: 50; batch classifier loss: 0.037715; batch adversarial loss: 0.024837\n",
      "[228/500] Running epoch\n",
      "epoch 228; iter: 0; batch classifier loss: 0.038751; batch adversarial loss: 0.024323\n",
      "epoch 228; iter: 10; batch classifier loss: 0.037161; batch adversarial loss: 0.021450\n",
      "epoch 228; iter: 20; batch classifier loss: 0.037892; batch adversarial loss: 0.023207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 228; iter: 30; batch classifier loss: 0.037645; batch adversarial loss: 0.024762\n",
      "epoch 228; iter: 40; batch classifier loss: 0.036033; batch adversarial loss: 0.022578\n",
      "epoch 228; iter: 50; batch classifier loss: 0.036437; batch adversarial loss: 0.023923\n",
      "[229/500] Running epoch\n",
      "epoch 229; iter: 0; batch classifier loss: 0.036795; batch adversarial loss: 0.023711\n",
      "epoch 229; iter: 10; batch classifier loss: 0.037240; batch adversarial loss: 0.024109\n",
      "epoch 229; iter: 20; batch classifier loss: 0.040190; batch adversarial loss: 0.026104\n",
      "epoch 229; iter: 30; batch classifier loss: 0.037616; batch adversarial loss: 0.020535\n",
      "epoch 229; iter: 40; batch classifier loss: 0.036347; batch adversarial loss: 0.020957\n",
      "epoch 229; iter: 50; batch classifier loss: 0.037854; batch adversarial loss: 0.024092\n",
      "[230/500] Running epoch\n",
      "epoch 230; iter: 0; batch classifier loss: 0.037897; batch adversarial loss: 0.022861\n",
      "epoch 230; iter: 10; batch classifier loss: 0.036598; batch adversarial loss: 0.024567\n",
      "epoch 230; iter: 20; batch classifier loss: 0.037258; batch adversarial loss: 0.023091\n",
      "epoch 230; iter: 30; batch classifier loss: 0.038538; batch adversarial loss: 0.028902\n",
      "epoch 230; iter: 40; batch classifier loss: 0.038068; batch adversarial loss: 0.026177\n",
      "epoch 230; iter: 50; batch classifier loss: 0.036117; batch adversarial loss: 0.022235\n",
      "||w||: 1.2980141639709473\n",
      "||w2||: 0.5982481837272644\n",
      "w.T g: [[0.30241965]]\n",
      "[231/500] Running epoch\n",
      "epoch 231; iter: 0; batch classifier loss: 0.036928; batch adversarial loss: 0.022573\n",
      "epoch 231; iter: 10; batch classifier loss: 0.038344; batch adversarial loss: 0.022770\n",
      "epoch 231; iter: 20; batch classifier loss: 0.037298; batch adversarial loss: 0.024020\n",
      "epoch 231; iter: 30; batch classifier loss: 0.037133; batch adversarial loss: 0.026722\n",
      "epoch 231; iter: 40; batch classifier loss: 0.036063; batch adversarial loss: 0.022181\n",
      "epoch 231; iter: 50; batch classifier loss: 0.038340; batch adversarial loss: 0.024806\n",
      "[232/500] Running epoch\n",
      "epoch 232; iter: 0; batch classifier loss: 0.038124; batch adversarial loss: 0.022141\n",
      "epoch 232; iter: 10; batch classifier loss: 0.036636; batch adversarial loss: 0.020235\n",
      "epoch 232; iter: 20; batch classifier loss: 0.039155; batch adversarial loss: 0.026133\n",
      "epoch 232; iter: 30; batch classifier loss: 0.037288; batch adversarial loss: 0.020910\n",
      "epoch 232; iter: 40; batch classifier loss: 0.036053; batch adversarial loss: 0.022993\n",
      "epoch 232; iter: 50; batch classifier loss: 0.039017; batch adversarial loss: 0.024005\n",
      "[233/500] Running epoch\n",
      "epoch 233; iter: 0; batch classifier loss: 0.038536; batch adversarial loss: 0.024306\n",
      "epoch 233; iter: 10; batch classifier loss: 0.037716; batch adversarial loss: 0.022175\n",
      "epoch 233; iter: 20; batch classifier loss: 0.036156; batch adversarial loss: 0.022365\n",
      "epoch 233; iter: 30; batch classifier loss: 0.039900; batch adversarial loss: 0.022318\n",
      "epoch 233; iter: 40; batch classifier loss: 0.036401; batch adversarial loss: 0.023766\n",
      "epoch 233; iter: 50; batch classifier loss: 0.037150; batch adversarial loss: 0.023190\n",
      "[234/500] Running epoch\n",
      "epoch 234; iter: 0; batch classifier loss: 0.037189; batch adversarial loss: 0.021688\n",
      "epoch 234; iter: 10; batch classifier loss: 0.038164; batch adversarial loss: 0.026343\n",
      "epoch 234; iter: 20; batch classifier loss: 0.037610; batch adversarial loss: 0.024540\n",
      "epoch 234; iter: 30; batch classifier loss: 0.034046; batch adversarial loss: 0.023354\n",
      "epoch 234; iter: 40; batch classifier loss: 0.036737; batch adversarial loss: 0.021792\n",
      "epoch 234; iter: 50; batch classifier loss: 0.039368; batch adversarial loss: 0.024000\n",
      "[235/500] Running epoch\n",
      "epoch 235; iter: 0; batch classifier loss: 0.038026; batch adversarial loss: 0.023470\n",
      "epoch 235; iter: 10; batch classifier loss: 0.036645; batch adversarial loss: 0.022121\n",
      "epoch 235; iter: 20; batch classifier loss: 0.035264; batch adversarial loss: 0.021353\n",
      "epoch 235; iter: 30; batch classifier loss: 0.037379; batch adversarial loss: 0.022093\n",
      "epoch 235; iter: 40; batch classifier loss: 0.037763; batch adversarial loss: 0.021307\n",
      "epoch 235; iter: 50; batch classifier loss: 0.036902; batch adversarial loss: 0.020296\n",
      "[236/500] Running epoch\n",
      "epoch 236; iter: 0; batch classifier loss: 0.037797; batch adversarial loss: 0.021050\n",
      "epoch 236; iter: 10; batch classifier loss: 0.037229; batch adversarial loss: 0.019686\n",
      "epoch 236; iter: 20; batch classifier loss: 0.036186; batch adversarial loss: 0.023107\n",
      "epoch 236; iter: 30; batch classifier loss: 0.037818; batch adversarial loss: 0.023574\n",
      "epoch 236; iter: 40; batch classifier loss: 0.037168; batch adversarial loss: 0.022452\n",
      "epoch 236; iter: 50; batch classifier loss: 0.038513; batch adversarial loss: 0.022296\n",
      "[237/500] Running epoch\n",
      "epoch 237; iter: 0; batch classifier loss: 0.036749; batch adversarial loss: 0.020838\n",
      "epoch 237; iter: 10; batch classifier loss: 0.037106; batch adversarial loss: 0.023663\n",
      "epoch 237; iter: 20; batch classifier loss: 0.037157; batch adversarial loss: 0.023406\n",
      "epoch 237; iter: 30; batch classifier loss: 0.038298; batch adversarial loss: 0.020844\n",
      "epoch 237; iter: 40; batch classifier loss: 0.035377; batch adversarial loss: 0.020793\n",
      "epoch 237; iter: 50; batch classifier loss: 0.037867; batch adversarial loss: 0.018893\n",
      "[238/500] Running epoch\n",
      "epoch 238; iter: 0; batch classifier loss: 0.040885; batch adversarial loss: 0.026714\n",
      "epoch 238; iter: 10; batch classifier loss: 0.038894; batch adversarial loss: 0.020380\n",
      "epoch 238; iter: 20; batch classifier loss: 0.040139; batch adversarial loss: 0.027994\n",
      "epoch 238; iter: 30; batch classifier loss: 0.037908; batch adversarial loss: 0.023208\n",
      "epoch 238; iter: 40; batch classifier loss: 0.037640; batch adversarial loss: 0.023811\n",
      "epoch 238; iter: 50; batch classifier loss: 0.039902; batch adversarial loss: 0.023857\n",
      "[239/500] Running epoch\n",
      "epoch 239; iter: 0; batch classifier loss: 0.037421; batch adversarial loss: 0.020771\n",
      "epoch 239; iter: 10; batch classifier loss: 0.039709; batch adversarial loss: 0.025233\n",
      "epoch 239; iter: 20; batch classifier loss: 0.038713; batch adversarial loss: 0.022273\n",
      "epoch 239; iter: 30; batch classifier loss: 0.037646; batch adversarial loss: 0.028535\n",
      "epoch 239; iter: 40; batch classifier loss: 0.036089; batch adversarial loss: 0.025210\n",
      "epoch 239; iter: 50; batch classifier loss: 0.034945; batch adversarial loss: 0.024469\n",
      "[240/500] Running epoch\n",
      "epoch 240; iter: 0; batch classifier loss: 0.036636; batch adversarial loss: 0.022716\n",
      "epoch 240; iter: 10; batch classifier loss: 0.040067; batch adversarial loss: 0.023551\n",
      "epoch 240; iter: 20; batch classifier loss: 0.034849; batch adversarial loss: 0.023831\n",
      "epoch 240; iter: 30; batch classifier loss: 0.036293; batch adversarial loss: 0.022423\n",
      "epoch 240; iter: 40; batch classifier loss: 0.037763; batch adversarial loss: 0.021917\n",
      "epoch 240; iter: 50; batch classifier loss: 0.037007; batch adversarial loss: 0.020498\n",
      "||w||: 1.2979453802108765\n",
      "||w2||: 0.5976928472518921\n",
      "w.T g: [[0.30298508]]\n",
      "[241/500] Running epoch\n",
      "epoch 241; iter: 0; batch classifier loss: 0.037618; batch adversarial loss: 0.026406\n",
      "epoch 241; iter: 10; batch classifier loss: 0.037146; batch adversarial loss: 0.023891\n",
      "epoch 241; iter: 20; batch classifier loss: 0.038030; batch adversarial loss: 0.022823\n",
      "epoch 241; iter: 30; batch classifier loss: 0.038648; batch adversarial loss: 0.024329\n",
      "epoch 241; iter: 40; batch classifier loss: 0.037217; batch adversarial loss: 0.022352\n",
      "epoch 241; iter: 50; batch classifier loss: 0.037948; batch adversarial loss: 0.018179\n",
      "[242/500] Running epoch\n",
      "epoch 242; iter: 0; batch classifier loss: 0.036039; batch adversarial loss: 0.021234\n",
      "epoch 242; iter: 10; batch classifier loss: 0.039383; batch adversarial loss: 0.023013\n",
      "epoch 242; iter: 20; batch classifier loss: 0.038236; batch adversarial loss: 0.022430\n",
      "epoch 242; iter: 30; batch classifier loss: 0.036279; batch adversarial loss: 0.022312\n",
      "epoch 242; iter: 40; batch classifier loss: 0.038421; batch adversarial loss: 0.024063\n",
      "epoch 242; iter: 50; batch classifier loss: 0.036852; batch adversarial loss: 0.024464\n",
      "[243/500] Running epoch\n",
      "epoch 243; iter: 0; batch classifier loss: 0.036468; batch adversarial loss: 0.025211\n",
      "epoch 243; iter: 10; batch classifier loss: 0.036020; batch adversarial loss: 0.027798\n",
      "epoch 243; iter: 20; batch classifier loss: 0.037744; batch adversarial loss: 0.028055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 243; iter: 30; batch classifier loss: 0.038310; batch adversarial loss: 0.021124\n",
      "epoch 243; iter: 40; batch classifier loss: 0.038316; batch adversarial loss: 0.021352\n",
      "epoch 243; iter: 50; batch classifier loss: 0.037745; batch adversarial loss: 0.024335\n",
      "[244/500] Running epoch\n",
      "epoch 244; iter: 0; batch classifier loss: 0.036883; batch adversarial loss: 0.027525\n",
      "epoch 244; iter: 10; batch classifier loss: 0.036008; batch adversarial loss: 0.023535\n",
      "epoch 244; iter: 20; batch classifier loss: 0.038028; batch adversarial loss: 0.024498\n",
      "epoch 244; iter: 30; batch classifier loss: 0.038065; batch adversarial loss: 0.025614\n",
      "epoch 244; iter: 40; batch classifier loss: 0.037214; batch adversarial loss: 0.022240\n",
      "epoch 244; iter: 50; batch classifier loss: 0.036136; batch adversarial loss: 0.019943\n",
      "[245/500] Running epoch\n",
      "epoch 245; iter: 0; batch classifier loss: 0.037759; batch adversarial loss: 0.024893\n",
      "epoch 245; iter: 10; batch classifier loss: 0.038082; batch adversarial loss: 0.023388\n",
      "epoch 245; iter: 20; batch classifier loss: 0.038374; batch adversarial loss: 0.023329\n",
      "epoch 245; iter: 30; batch classifier loss: 0.038105; batch adversarial loss: 0.024633\n",
      "epoch 245; iter: 40; batch classifier loss: 0.037289; batch adversarial loss: 0.024048\n",
      "epoch 245; iter: 50; batch classifier loss: 0.037300; batch adversarial loss: 0.023634\n",
      "[246/500] Running epoch\n",
      "epoch 246; iter: 0; batch classifier loss: 0.037996; batch adversarial loss: 0.023322\n",
      "epoch 246; iter: 10; batch classifier loss: 0.039363; batch adversarial loss: 0.027281\n",
      "epoch 246; iter: 20; batch classifier loss: 0.037900; batch adversarial loss: 0.022773\n",
      "epoch 246; iter: 30; batch classifier loss: 0.036212; batch adversarial loss: 0.019963\n",
      "epoch 246; iter: 40; batch classifier loss: 0.037681; batch adversarial loss: 0.029040\n",
      "epoch 246; iter: 50; batch classifier loss: 0.037144; batch adversarial loss: 0.023700\n",
      "[247/500] Running epoch\n",
      "epoch 247; iter: 0; batch classifier loss: 0.037461; batch adversarial loss: 0.024713\n",
      "epoch 247; iter: 10; batch classifier loss: 0.037124; batch adversarial loss: 0.024068\n",
      "epoch 247; iter: 20; batch classifier loss: 0.038520; batch adversarial loss: 0.025267\n",
      "epoch 247; iter: 30; batch classifier loss: 0.037420; batch adversarial loss: 0.026618\n",
      "epoch 247; iter: 40; batch classifier loss: 0.038102; batch adversarial loss: 0.025978\n",
      "epoch 247; iter: 50; batch classifier loss: 0.039489; batch adversarial loss: 0.023165\n",
      "[248/500] Running epoch\n",
      "epoch 248; iter: 0; batch classifier loss: 0.038145; batch adversarial loss: 0.021849\n",
      "epoch 248; iter: 10; batch classifier loss: 0.037749; batch adversarial loss: 0.020587\n",
      "epoch 248; iter: 20; batch classifier loss: 0.036348; batch adversarial loss: 0.023149\n",
      "epoch 248; iter: 30; batch classifier loss: 0.036870; batch adversarial loss: 0.026999\n",
      "epoch 248; iter: 40; batch classifier loss: 0.037495; batch adversarial loss: 0.024886\n",
      "epoch 248; iter: 50; batch classifier loss: 0.037582; batch adversarial loss: 0.021292\n",
      "[249/500] Running epoch\n",
      "epoch 249; iter: 0; batch classifier loss: 0.038260; batch adversarial loss: 0.024240\n",
      "epoch 249; iter: 10; batch classifier loss: 0.038357; batch adversarial loss: 0.021461\n",
      "epoch 249; iter: 20; batch classifier loss: 0.038091; batch adversarial loss: 0.028214\n",
      "epoch 249; iter: 30; batch classifier loss: 0.035962; batch adversarial loss: 0.023750\n",
      "epoch 249; iter: 40; batch classifier loss: 0.038325; batch adversarial loss: 0.022153\n",
      "epoch 249; iter: 50; batch classifier loss: 0.036731; batch adversarial loss: 0.020310\n",
      "[250/500] Running epoch\n",
      "epoch 250; iter: 0; batch classifier loss: 0.037689; batch adversarial loss: 0.023315\n",
      "epoch 250; iter: 10; batch classifier loss: 0.038223; batch adversarial loss: 0.020227\n",
      "epoch 250; iter: 20; batch classifier loss: 0.036494; batch adversarial loss: 0.021352\n",
      "epoch 250; iter: 30; batch classifier loss: 0.037508; batch adversarial loss: 0.028339\n",
      "epoch 250; iter: 40; batch classifier loss: 0.036208; batch adversarial loss: 0.022025\n",
      "epoch 250; iter: 50; batch classifier loss: 0.037571; batch adversarial loss: 0.023257\n",
      "||w||: 1.2979085445404053\n",
      "||w2||: 0.5973256826400757\n",
      "w.T g: [[0.3034008]]\n",
      "[251/500] Running epoch\n",
      "epoch 251; iter: 0; batch classifier loss: 0.038322; batch adversarial loss: 0.023067\n",
      "epoch 251; iter: 10; batch classifier loss: 0.038448; batch adversarial loss: 0.023434\n",
      "epoch 251; iter: 20; batch classifier loss: 0.038951; batch adversarial loss: 0.021265\n",
      "epoch 251; iter: 30; batch classifier loss: 0.037186; batch adversarial loss: 0.023156\n",
      "epoch 251; iter: 40; batch classifier loss: 0.036716; batch adversarial loss: 0.021519\n",
      "epoch 251; iter: 50; batch classifier loss: 0.038518; batch adversarial loss: 0.024328\n",
      "[252/500] Running epoch\n",
      "epoch 252; iter: 0; batch classifier loss: 0.038379; batch adversarial loss: 0.020633\n",
      "epoch 252; iter: 10; batch classifier loss: 0.036334; batch adversarial loss: 0.022618\n",
      "epoch 252; iter: 20; batch classifier loss: 0.037303; batch adversarial loss: 0.021405\n",
      "epoch 252; iter: 30; batch classifier loss: 0.037040; batch adversarial loss: 0.024635\n",
      "epoch 252; iter: 40; batch classifier loss: 0.037472; batch adversarial loss: 0.024927\n",
      "epoch 252; iter: 50; batch classifier loss: 0.040681; batch adversarial loss: 0.024909\n",
      "[253/500] Running epoch\n",
      "epoch 253; iter: 0; batch classifier loss: 0.035466; batch adversarial loss: 0.019578\n",
      "epoch 253; iter: 10; batch classifier loss: 0.036622; batch adversarial loss: 0.018993\n",
      "epoch 253; iter: 20; batch classifier loss: 0.038366; batch adversarial loss: 0.022164\n",
      "epoch 253; iter: 30; batch classifier loss: 0.038107; batch adversarial loss: 0.023718\n",
      "epoch 253; iter: 40; batch classifier loss: 0.037046; batch adversarial loss: 0.020742\n",
      "epoch 253; iter: 50; batch classifier loss: 0.038630; batch adversarial loss: 0.029940\n",
      "[254/500] Running epoch\n",
      "epoch 254; iter: 0; batch classifier loss: 0.035815; batch adversarial loss: 0.018729\n",
      "epoch 254; iter: 10; batch classifier loss: 0.037227; batch adversarial loss: 0.028197\n",
      "epoch 254; iter: 20; batch classifier loss: 0.037127; batch adversarial loss: 0.023702\n",
      "epoch 254; iter: 30; batch classifier loss: 0.036888; batch adversarial loss: 0.018816\n",
      "epoch 254; iter: 40; batch classifier loss: 0.035978; batch adversarial loss: 0.020058\n",
      "epoch 254; iter: 50; batch classifier loss: 0.039946; batch adversarial loss: 0.023680\n",
      "[255/500] Running epoch\n",
      "epoch 255; iter: 0; batch classifier loss: 0.039230; batch adversarial loss: 0.024231\n",
      "epoch 255; iter: 10; batch classifier loss: 0.038723; batch adversarial loss: 0.025155\n",
      "epoch 255; iter: 20; batch classifier loss: 0.036495; batch adversarial loss: 0.020922\n",
      "epoch 255; iter: 30; batch classifier loss: 0.036047; batch adversarial loss: 0.020817\n",
      "epoch 255; iter: 40; batch classifier loss: 0.038440; batch adversarial loss: 0.022557\n",
      "epoch 255; iter: 50; batch classifier loss: 0.037029; batch adversarial loss: 0.020499\n",
      "[256/500] Running epoch\n",
      "epoch 256; iter: 0; batch classifier loss: 0.038300; batch adversarial loss: 0.023280\n",
      "epoch 256; iter: 10; batch classifier loss: 0.036225; batch adversarial loss: 0.020528\n",
      "epoch 256; iter: 20; batch classifier loss: 0.037249; batch adversarial loss: 0.020589\n",
      "epoch 256; iter: 30; batch classifier loss: 0.036655; batch adversarial loss: 0.027323\n",
      "epoch 256; iter: 40; batch classifier loss: 0.039538; batch adversarial loss: 0.026696\n",
      "epoch 256; iter: 50; batch classifier loss: 0.036655; batch adversarial loss: 0.022593\n",
      "[257/500] Running epoch\n",
      "epoch 257; iter: 0; batch classifier loss: 0.036627; batch adversarial loss: 0.021112\n",
      "epoch 257; iter: 10; batch classifier loss: 0.038341; batch adversarial loss: 0.025613\n",
      "epoch 257; iter: 20; batch classifier loss: 0.035888; batch adversarial loss: 0.026965\n",
      "epoch 257; iter: 30; batch classifier loss: 0.037541; batch adversarial loss: 0.022743\n",
      "epoch 257; iter: 40; batch classifier loss: 0.036861; batch adversarial loss: 0.023232\n",
      "epoch 257; iter: 50; batch classifier loss: 0.037193; batch adversarial loss: 0.021217\n",
      "[258/500] Running epoch\n",
      "epoch 258; iter: 0; batch classifier loss: 0.037092; batch adversarial loss: 0.023835\n",
      "epoch 258; iter: 10; batch classifier loss: 0.036629; batch adversarial loss: 0.025155\n",
      "epoch 258; iter: 20; batch classifier loss: 0.038551; batch adversarial loss: 0.021246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 258; iter: 30; batch classifier loss: 0.038144; batch adversarial loss: 0.022839\n",
      "epoch 258; iter: 40; batch classifier loss: 0.037734; batch adversarial loss: 0.026112\n",
      "epoch 258; iter: 50; batch classifier loss: 0.037983; batch adversarial loss: 0.022467\n",
      "[259/500] Running epoch\n",
      "epoch 259; iter: 0; batch classifier loss: 0.038942; batch adversarial loss: 0.025297\n",
      "epoch 259; iter: 10; batch classifier loss: 0.037767; batch adversarial loss: 0.021903\n",
      "epoch 259; iter: 20; batch classifier loss: 0.037749; batch adversarial loss: 0.021365\n",
      "epoch 259; iter: 30; batch classifier loss: 0.037534; batch adversarial loss: 0.022928\n",
      "epoch 259; iter: 40; batch classifier loss: 0.038323; batch adversarial loss: 0.020662\n",
      "epoch 259; iter: 50; batch classifier loss: 0.038987; batch adversarial loss: 0.024395\n",
      "[260/500] Running epoch\n",
      "epoch 260; iter: 0; batch classifier loss: 0.038028; batch adversarial loss: 0.028161\n",
      "epoch 260; iter: 10; batch classifier loss: 0.038024; batch adversarial loss: 0.028031\n",
      "epoch 260; iter: 20; batch classifier loss: 0.036699; batch adversarial loss: 0.023073\n",
      "epoch 260; iter: 30; batch classifier loss: 0.037670; batch adversarial loss: 0.025002\n",
      "epoch 260; iter: 40; batch classifier loss: 0.037300; batch adversarial loss: 0.020540\n",
      "epoch 260; iter: 50; batch classifier loss: 0.035640; batch adversarial loss: 0.018962\n",
      "||w||: 1.297874927520752\n",
      "||w2||: 0.5970490574836731\n",
      "w.T g: [[0.30366423]]\n",
      "[261/500] Running epoch\n",
      "epoch 261; iter: 0; batch classifier loss: 0.038697; batch adversarial loss: 0.022786\n",
      "epoch 261; iter: 10; batch classifier loss: 0.037288; batch adversarial loss: 0.020907\n",
      "epoch 261; iter: 20; batch classifier loss: 0.039660; batch adversarial loss: 0.024220\n",
      "epoch 261; iter: 30; batch classifier loss: 0.037778; batch adversarial loss: 0.024086\n",
      "epoch 261; iter: 40; batch classifier loss: 0.037714; batch adversarial loss: 0.021327\n",
      "epoch 261; iter: 50; batch classifier loss: 0.040394; batch adversarial loss: 0.021160\n",
      "[262/500] Running epoch\n",
      "epoch 262; iter: 0; batch classifier loss: 0.039447; batch adversarial loss: 0.029165\n",
      "epoch 262; iter: 10; batch classifier loss: 0.039215; batch adversarial loss: 0.025170\n",
      "epoch 262; iter: 20; batch classifier loss: 0.038311; batch adversarial loss: 0.023775\n",
      "epoch 262; iter: 30; batch classifier loss: 0.036272; batch adversarial loss: 0.019306\n",
      "epoch 262; iter: 40; batch classifier loss: 0.038751; batch adversarial loss: 0.020879\n",
      "epoch 262; iter: 50; batch classifier loss: 0.037037; batch adversarial loss: 0.025202\n",
      "[263/500] Running epoch\n",
      "epoch 263; iter: 0; batch classifier loss: 0.036501; batch adversarial loss: 0.020175\n",
      "epoch 263; iter: 10; batch classifier loss: 0.038224; batch adversarial loss: 0.023987\n",
      "epoch 263; iter: 20; batch classifier loss: 0.037333; batch adversarial loss: 0.024763\n",
      "epoch 263; iter: 30; batch classifier loss: 0.038059; batch adversarial loss: 0.023834\n",
      "epoch 263; iter: 40; batch classifier loss: 0.035929; batch adversarial loss: 0.021827\n",
      "epoch 263; iter: 50; batch classifier loss: 0.038932; batch adversarial loss: 0.020470\n",
      "[264/500] Running epoch\n",
      "epoch 264; iter: 0; batch classifier loss: 0.037388; batch adversarial loss: 0.024338\n",
      "epoch 264; iter: 10; batch classifier loss: 0.038874; batch adversarial loss: 0.021005\n",
      "epoch 264; iter: 20; batch classifier loss: 0.034862; batch adversarial loss: 0.019415\n",
      "epoch 264; iter: 30; batch classifier loss: 0.037625; batch adversarial loss: 0.026307\n",
      "epoch 264; iter: 40; batch classifier loss: 0.035926; batch adversarial loss: 0.026706\n",
      "epoch 264; iter: 50; batch classifier loss: 0.037068; batch adversarial loss: 0.020758\n",
      "[265/500] Running epoch\n",
      "epoch 265; iter: 0; batch classifier loss: 0.036547; batch adversarial loss: 0.022478\n",
      "epoch 265; iter: 10; batch classifier loss: 0.039008; batch adversarial loss: 0.025604\n",
      "epoch 265; iter: 20; batch classifier loss: 0.037609; batch adversarial loss: 0.020577\n",
      "epoch 265; iter: 30; batch classifier loss: 0.037932; batch adversarial loss: 0.022008\n",
      "epoch 265; iter: 40; batch classifier loss: 0.036768; batch adversarial loss: 0.026338\n",
      "epoch 265; iter: 50; batch classifier loss: 0.037584; batch adversarial loss: 0.025920\n",
      "[266/500] Running epoch\n",
      "epoch 266; iter: 0; batch classifier loss: 0.041110; batch adversarial loss: 0.028591\n",
      "epoch 266; iter: 10; batch classifier loss: 0.037901; batch adversarial loss: 0.026561\n",
      "epoch 266; iter: 20; batch classifier loss: 0.037995; batch adversarial loss: 0.024712\n",
      "epoch 266; iter: 30; batch classifier loss: 0.036952; batch adversarial loss: 0.024557\n",
      "epoch 266; iter: 40; batch classifier loss: 0.035984; batch adversarial loss: 0.022224\n",
      "epoch 266; iter: 50; batch classifier loss: 0.039963; batch adversarial loss: 0.028307\n",
      "[267/500] Running epoch\n",
      "epoch 267; iter: 0; batch classifier loss: 0.038751; batch adversarial loss: 0.020678\n",
      "epoch 267; iter: 10; batch classifier loss: 0.038887; batch adversarial loss: 0.024646\n",
      "epoch 267; iter: 20; batch classifier loss: 0.038723; batch adversarial loss: 0.027177\n",
      "epoch 267; iter: 30; batch classifier loss: 0.039103; batch adversarial loss: 0.024401\n",
      "epoch 267; iter: 40; batch classifier loss: 0.037590; batch adversarial loss: 0.023683\n",
      "epoch 267; iter: 50; batch classifier loss: 0.038061; batch adversarial loss: 0.025206\n",
      "[268/500] Running epoch\n",
      "epoch 268; iter: 0; batch classifier loss: 0.036830; batch adversarial loss: 0.022868\n",
      "epoch 268; iter: 10; batch classifier loss: 0.039676; batch adversarial loss: 0.022718\n",
      "epoch 268; iter: 20; batch classifier loss: 0.039096; batch adversarial loss: 0.024158\n",
      "epoch 268; iter: 30; batch classifier loss: 0.037889; batch adversarial loss: 0.022586\n",
      "epoch 268; iter: 40; batch classifier loss: 0.038755; batch adversarial loss: 0.024859\n",
      "epoch 268; iter: 50; batch classifier loss: 0.038776; batch adversarial loss: 0.023056\n",
      "[269/500] Running epoch\n",
      "epoch 269; iter: 0; batch classifier loss: 0.037986; batch adversarial loss: 0.025850\n",
      "epoch 269; iter: 10; batch classifier loss: 0.038539; batch adversarial loss: 0.024244\n",
      "epoch 269; iter: 20; batch classifier loss: 0.038367; batch adversarial loss: 0.023550\n",
      "epoch 269; iter: 30; batch classifier loss: 0.036355; batch adversarial loss: 0.024873\n",
      "epoch 269; iter: 40; batch classifier loss: 0.038702; batch adversarial loss: 0.025442\n",
      "epoch 269; iter: 50; batch classifier loss: 0.034975; batch adversarial loss: 0.021289\n",
      "[270/500] Running epoch\n",
      "epoch 270; iter: 0; batch classifier loss: 0.037490; batch adversarial loss: 0.022682\n",
      "epoch 270; iter: 10; batch classifier loss: 0.039360; batch adversarial loss: 0.022551\n",
      "epoch 270; iter: 20; batch classifier loss: 0.038577; batch adversarial loss: 0.020435\n",
      "epoch 270; iter: 30; batch classifier loss: 0.040847; batch adversarial loss: 0.025260\n",
      "epoch 270; iter: 40; batch classifier loss: 0.037731; batch adversarial loss: 0.022812\n",
      "epoch 270; iter: 50; batch classifier loss: 0.037545; batch adversarial loss: 0.020374\n",
      "||w||: 1.2978639602661133\n",
      "||w2||: 0.5968804955482483\n",
      "w.T g: [[0.30385826]]\n",
      "[271/500] Running epoch\n",
      "epoch 271; iter: 0; batch classifier loss: 0.036509; batch adversarial loss: 0.019517\n",
      "epoch 271; iter: 10; batch classifier loss: 0.036039; batch adversarial loss: 0.020875\n",
      "epoch 271; iter: 20; batch classifier loss: 0.037917; batch adversarial loss: 0.019522\n",
      "epoch 271; iter: 30; batch classifier loss: 0.038882; batch adversarial loss: 0.021455\n",
      "epoch 271; iter: 40; batch classifier loss: 0.037280; batch adversarial loss: 0.020035\n",
      "epoch 271; iter: 50; batch classifier loss: 0.036201; batch adversarial loss: 0.024969\n",
      "[272/500] Running epoch\n",
      "epoch 272; iter: 0; batch classifier loss: 0.037054; batch adversarial loss: 0.021673\n",
      "epoch 272; iter: 10; batch classifier loss: 0.037873; batch adversarial loss: 0.025719\n",
      "epoch 272; iter: 20; batch classifier loss: 0.036332; batch adversarial loss: 0.023855\n",
      "epoch 272; iter: 30; batch classifier loss: 0.037540; batch adversarial loss: 0.020665\n",
      "epoch 272; iter: 40; batch classifier loss: 0.038709; batch adversarial loss: 0.021218\n",
      "epoch 272; iter: 50; batch classifier loss: 0.038645; batch adversarial loss: 0.021879\n",
      "[273/500] Running epoch\n",
      "epoch 273; iter: 0; batch classifier loss: 0.037945; batch adversarial loss: 0.027168\n",
      "epoch 273; iter: 10; batch classifier loss: 0.036843; batch adversarial loss: 0.021941\n",
      "epoch 273; iter: 20; batch classifier loss: 0.037725; batch adversarial loss: 0.022364\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 273; iter: 30; batch classifier loss: 0.037479; batch adversarial loss: 0.023295\n",
      "epoch 273; iter: 40; batch classifier loss: 0.033849; batch adversarial loss: 0.022354\n",
      "epoch 273; iter: 50; batch classifier loss: 0.037103; batch adversarial loss: 0.022384\n",
      "[274/500] Running epoch\n",
      "epoch 274; iter: 0; batch classifier loss: 0.036061; batch adversarial loss: 0.025763\n",
      "epoch 274; iter: 10; batch classifier loss: 0.038912; batch adversarial loss: 0.022245\n",
      "epoch 274; iter: 20; batch classifier loss: 0.034494; batch adversarial loss: 0.022509\n",
      "epoch 274; iter: 30; batch classifier loss: 0.036775; batch adversarial loss: 0.020749\n",
      "epoch 274; iter: 40; batch classifier loss: 0.039843; batch adversarial loss: 0.024619\n",
      "epoch 274; iter: 50; batch classifier loss: 0.036657; batch adversarial loss: 0.023271\n",
      "[275/500] Running epoch\n",
      "epoch 275; iter: 0; batch classifier loss: 0.036600; batch adversarial loss: 0.023686\n",
      "epoch 275; iter: 10; batch classifier loss: 0.036714; batch adversarial loss: 0.027541\n",
      "epoch 275; iter: 20; batch classifier loss: 0.039027; batch adversarial loss: 0.024310\n",
      "epoch 275; iter: 30; batch classifier loss: 0.036871; batch adversarial loss: 0.020424\n",
      "epoch 275; iter: 40; batch classifier loss: 0.035866; batch adversarial loss: 0.019740\n",
      "epoch 275; iter: 50; batch classifier loss: 0.034557; batch adversarial loss: 0.022689\n",
      "[276/500] Running epoch\n",
      "epoch 276; iter: 0; batch classifier loss: 0.039065; batch adversarial loss: 0.023952\n",
      "epoch 276; iter: 10; batch classifier loss: 0.037966; batch adversarial loss: 0.023904\n",
      "epoch 276; iter: 20; batch classifier loss: 0.037129; batch adversarial loss: 0.022029\n",
      "epoch 276; iter: 30; batch classifier loss: 0.038083; batch adversarial loss: 0.023066\n",
      "epoch 276; iter: 40; batch classifier loss: 0.038182; batch adversarial loss: 0.022646\n",
      "epoch 276; iter: 50; batch classifier loss: 0.038837; batch adversarial loss: 0.026193\n",
      "[277/500] Running epoch\n",
      "epoch 277; iter: 0; batch classifier loss: 0.036172; batch adversarial loss: 0.023180\n",
      "epoch 277; iter: 10; batch classifier loss: 0.036681; batch adversarial loss: 0.020579\n",
      "epoch 277; iter: 20; batch classifier loss: 0.037073; batch adversarial loss: 0.024194\n",
      "epoch 277; iter: 30; batch classifier loss: 0.035721; batch adversarial loss: 0.024344\n",
      "epoch 277; iter: 40; batch classifier loss: 0.037167; batch adversarial loss: 0.024512\n",
      "epoch 277; iter: 50; batch classifier loss: 0.037283; batch adversarial loss: 0.024134\n",
      "[278/500] Running epoch\n",
      "epoch 278; iter: 0; batch classifier loss: 0.036163; batch adversarial loss: 0.021078\n",
      "epoch 278; iter: 10; batch classifier loss: 0.038701; batch adversarial loss: 0.024893\n",
      "epoch 278; iter: 20; batch classifier loss: 0.038421; batch adversarial loss: 0.024251\n",
      "epoch 278; iter: 30; batch classifier loss: 0.035685; batch adversarial loss: 0.022339\n",
      "epoch 278; iter: 40; batch classifier loss: 0.039502; batch adversarial loss: 0.027724\n",
      "epoch 278; iter: 50; batch classifier loss: 0.037986; batch adversarial loss: 0.025161\n",
      "[279/500] Running epoch\n",
      "epoch 279; iter: 0; batch classifier loss: 0.038738; batch adversarial loss: 0.024937\n",
      "epoch 279; iter: 10; batch classifier loss: 0.038257; batch adversarial loss: 0.024225\n",
      "epoch 279; iter: 20; batch classifier loss: 0.036397; batch adversarial loss: 0.023634\n",
      "epoch 279; iter: 30; batch classifier loss: 0.038578; batch adversarial loss: 0.022302\n",
      "epoch 279; iter: 40; batch classifier loss: 0.038891; batch adversarial loss: 0.029995\n",
      "epoch 279; iter: 50; batch classifier loss: 0.038323; batch adversarial loss: 0.021060\n",
      "[280/500] Running epoch\n",
      "epoch 280; iter: 0; batch classifier loss: 0.037382; batch adversarial loss: 0.023233\n",
      "epoch 280; iter: 10; batch classifier loss: 0.036021; batch adversarial loss: 0.020980\n",
      "epoch 280; iter: 20; batch classifier loss: 0.038869; batch adversarial loss: 0.025936\n",
      "epoch 280; iter: 30; batch classifier loss: 0.036647; batch adversarial loss: 0.024068\n",
      "epoch 280; iter: 40; batch classifier loss: 0.037888; batch adversarial loss: 0.022247\n",
      "epoch 280; iter: 50; batch classifier loss: 0.038446; batch adversarial loss: 0.024868\n",
      "||w||: 1.2978564500808716\n",
      "||w2||: 0.5967646837234497\n",
      "w.T g: [[0.30398125]]\n",
      "[281/500] Running epoch\n",
      "epoch 281; iter: 0; batch classifier loss: 0.039784; batch adversarial loss: 0.022074\n",
      "epoch 281; iter: 10; batch classifier loss: 0.039359; batch adversarial loss: 0.024590\n",
      "epoch 281; iter: 20; batch classifier loss: 0.036923; batch adversarial loss: 0.027505\n",
      "epoch 281; iter: 30; batch classifier loss: 0.038707; batch adversarial loss: 0.023702\n",
      "epoch 281; iter: 40; batch classifier loss: 0.038888; batch adversarial loss: 0.024388\n",
      "epoch 281; iter: 50; batch classifier loss: 0.038397; batch adversarial loss: 0.021650\n",
      "[282/500] Running epoch\n",
      "epoch 282; iter: 0; batch classifier loss: 0.037138; batch adversarial loss: 0.024593\n",
      "epoch 282; iter: 10; batch classifier loss: 0.036417; batch adversarial loss: 0.021463\n",
      "epoch 282; iter: 20; batch classifier loss: 0.036856; batch adversarial loss: 0.021156\n",
      "epoch 282; iter: 30; batch classifier loss: 0.036304; batch adversarial loss: 0.024030\n",
      "epoch 282; iter: 40; batch classifier loss: 0.037185; batch adversarial loss: 0.022450\n",
      "epoch 282; iter: 50; batch classifier loss: 0.036570; batch adversarial loss: 0.023311\n",
      "[283/500] Running epoch\n",
      "epoch 283; iter: 0; batch classifier loss: 0.036199; batch adversarial loss: 0.021019\n",
      "epoch 283; iter: 10; batch classifier loss: 0.040731; batch adversarial loss: 0.028466\n",
      "epoch 283; iter: 20; batch classifier loss: 0.037162; batch adversarial loss: 0.022685\n",
      "epoch 283; iter: 30; batch classifier loss: 0.034791; batch adversarial loss: 0.020983\n",
      "epoch 283; iter: 40; batch classifier loss: 0.036552; batch adversarial loss: 0.020604\n",
      "epoch 283; iter: 50; batch classifier loss: 0.040682; batch adversarial loss: 0.026103\n",
      "[284/500] Running epoch\n",
      "epoch 284; iter: 0; batch classifier loss: 0.037682; batch adversarial loss: 0.021773\n",
      "epoch 284; iter: 10; batch classifier loss: 0.037963; batch adversarial loss: 0.022113\n",
      "epoch 284; iter: 20; batch classifier loss: 0.034570; batch adversarial loss: 0.021977\n",
      "epoch 284; iter: 30; batch classifier loss: 0.039003; batch adversarial loss: 0.022519\n",
      "epoch 284; iter: 40; batch classifier loss: 0.037507; batch adversarial loss: 0.019764\n",
      "epoch 284; iter: 50; batch classifier loss: 0.038258; batch adversarial loss: 0.023639\n",
      "[285/500] Running epoch\n",
      "epoch 285; iter: 0; batch classifier loss: 0.037991; batch adversarial loss: 0.025169\n",
      "epoch 285; iter: 10; batch classifier loss: 0.037165; batch adversarial loss: 0.027131\n",
      "epoch 285; iter: 20; batch classifier loss: 0.037510; batch adversarial loss: 0.025642\n",
      "epoch 285; iter: 30; batch classifier loss: 0.037008; batch adversarial loss: 0.025897\n",
      "epoch 285; iter: 40; batch classifier loss: 0.037560; batch adversarial loss: 0.027375\n",
      "epoch 285; iter: 50; batch classifier loss: 0.036483; batch adversarial loss: 0.022871\n",
      "[286/500] Running epoch\n",
      "epoch 286; iter: 0; batch classifier loss: 0.037410; batch adversarial loss: 0.022837\n",
      "epoch 286; iter: 10; batch classifier loss: 0.037357; batch adversarial loss: 0.022146\n",
      "epoch 286; iter: 20; batch classifier loss: 0.038543; batch adversarial loss: 0.023964\n",
      "epoch 286; iter: 30; batch classifier loss: 0.040994; batch adversarial loss: 0.026115\n",
      "epoch 286; iter: 40; batch classifier loss: 0.035118; batch adversarial loss: 0.025398\n",
      "epoch 286; iter: 50; batch classifier loss: 0.036786; batch adversarial loss: 0.021819\n",
      "[287/500] Running epoch\n",
      "epoch 287; iter: 0; batch classifier loss: 0.037948; batch adversarial loss: 0.025478\n",
      "epoch 287; iter: 10; batch classifier loss: 0.036298; batch adversarial loss: 0.022047\n",
      "epoch 287; iter: 20; batch classifier loss: 0.037951; batch adversarial loss: 0.023724\n",
      "epoch 287; iter: 30; batch classifier loss: 0.035411; batch adversarial loss: 0.022665\n",
      "epoch 287; iter: 40; batch classifier loss: 0.037598; batch adversarial loss: 0.020281\n",
      "epoch 287; iter: 50; batch classifier loss: 0.039208; batch adversarial loss: 0.022539\n",
      "[288/500] Running epoch\n",
      "epoch 288; iter: 0; batch classifier loss: 0.035676; batch adversarial loss: 0.019039\n",
      "epoch 288; iter: 10; batch classifier loss: 0.037308; batch adversarial loss: 0.024017\n",
      "epoch 288; iter: 20; batch classifier loss: 0.036291; batch adversarial loss: 0.021463\n",
      "epoch 288; iter: 30; batch classifier loss: 0.036309; batch adversarial loss: 0.022775\n",
      "epoch 288; iter: 40; batch classifier loss: 0.038305; batch adversarial loss: 0.024693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 288; iter: 50; batch classifier loss: 0.037862; batch adversarial loss: 0.029230\n",
      "[289/500] Running epoch\n",
      "epoch 289; iter: 0; batch classifier loss: 0.037843; batch adversarial loss: 0.021867\n",
      "epoch 289; iter: 10; batch classifier loss: 0.038389; batch adversarial loss: 0.019434\n",
      "epoch 289; iter: 20; batch classifier loss: 0.039053; batch adversarial loss: 0.026215\n",
      "epoch 289; iter: 30; batch classifier loss: 0.037061; batch adversarial loss: 0.020426\n",
      "epoch 289; iter: 40; batch classifier loss: 0.038083; batch adversarial loss: 0.023307\n",
      "epoch 289; iter: 50; batch classifier loss: 0.038167; batch adversarial loss: 0.022866\n",
      "[290/500] Running epoch\n",
      "epoch 290; iter: 0; batch classifier loss: 0.036656; batch adversarial loss: 0.024473\n",
      "epoch 290; iter: 10; batch classifier loss: 0.037969; batch adversarial loss: 0.024056\n",
      "epoch 290; iter: 20; batch classifier loss: 0.037014; batch adversarial loss: 0.024513\n",
      "epoch 290; iter: 30; batch classifier loss: 0.036276; batch adversarial loss: 0.025126\n",
      "epoch 290; iter: 40; batch classifier loss: 0.040318; batch adversarial loss: 0.020962\n",
      "epoch 290; iter: 50; batch classifier loss: 0.039361; batch adversarial loss: 0.026033\n",
      "||w||: 1.2978545427322388\n",
      "||w2||: 0.5966813564300537\n",
      "w.T g: [[0.30406171]]\n",
      "[291/500] Running epoch\n",
      "epoch 291; iter: 0; batch classifier loss: 0.037580; batch adversarial loss: 0.024425\n",
      "epoch 291; iter: 10; batch classifier loss: 0.037140; batch adversarial loss: 0.027122\n",
      "epoch 291; iter: 20; batch classifier loss: 0.038119; batch adversarial loss: 0.020558\n",
      "epoch 291; iter: 30; batch classifier loss: 0.035356; batch adversarial loss: 0.023997\n",
      "epoch 291; iter: 40; batch classifier loss: 0.038916; batch adversarial loss: 0.027582\n",
      "epoch 291; iter: 50; batch classifier loss: 0.038123; batch adversarial loss: 0.020536\n",
      "[292/500] Running epoch\n",
      "epoch 292; iter: 0; batch classifier loss: 0.036710; batch adversarial loss: 0.023278\n",
      "epoch 292; iter: 10; batch classifier loss: 0.038029; batch adversarial loss: 0.025072\n",
      "epoch 292; iter: 20; batch classifier loss: 0.035419; batch adversarial loss: 0.021599\n",
      "epoch 292; iter: 30; batch classifier loss: 0.036011; batch adversarial loss: 0.022696\n",
      "epoch 292; iter: 40; batch classifier loss: 0.039616; batch adversarial loss: 0.024794\n",
      "epoch 292; iter: 50; batch classifier loss: 0.036455; batch adversarial loss: 0.020663\n",
      "[293/500] Running epoch\n",
      "epoch 293; iter: 0; batch classifier loss: 0.038316; batch adversarial loss: 0.020174\n",
      "epoch 293; iter: 10; batch classifier loss: 0.039534; batch adversarial loss: 0.023750\n",
      "epoch 293; iter: 20; batch classifier loss: 0.037565; batch adversarial loss: 0.021319\n",
      "epoch 293; iter: 30; batch classifier loss: 0.038949; batch adversarial loss: 0.020009\n",
      "epoch 293; iter: 40; batch classifier loss: 0.038506; batch adversarial loss: 0.022132\n",
      "epoch 293; iter: 50; batch classifier loss: 0.040179; batch adversarial loss: 0.022376\n",
      "[294/500] Running epoch\n",
      "epoch 294; iter: 0; batch classifier loss: 0.035416; batch adversarial loss: 0.020127\n",
      "epoch 294; iter: 10; batch classifier loss: 0.038480; batch adversarial loss: 0.028565\n",
      "epoch 294; iter: 20; batch classifier loss: 0.037446; batch adversarial loss: 0.023966\n",
      "epoch 294; iter: 30; batch classifier loss: 0.037680; batch adversarial loss: 0.020830\n",
      "epoch 294; iter: 40; batch classifier loss: 0.038466; batch adversarial loss: 0.020539\n",
      "epoch 294; iter: 50; batch classifier loss: 0.036917; batch adversarial loss: 0.020148\n",
      "[295/500] Running epoch\n",
      "epoch 295; iter: 0; batch classifier loss: 0.039006; batch adversarial loss: 0.023889\n",
      "epoch 295; iter: 10; batch classifier loss: 0.040069; batch adversarial loss: 0.024505\n",
      "epoch 295; iter: 20; batch classifier loss: 0.036878; batch adversarial loss: 0.021790\n",
      "epoch 295; iter: 30; batch classifier loss: 0.038749; batch adversarial loss: 0.025055\n",
      "epoch 295; iter: 40; batch classifier loss: 0.038003; batch adversarial loss: 0.025754\n",
      "epoch 295; iter: 50; batch classifier loss: 0.037399; batch adversarial loss: 0.022164\n",
      "[296/500] Running epoch\n",
      "epoch 296; iter: 0; batch classifier loss: 0.038966; batch adversarial loss: 0.028174\n",
      "epoch 296; iter: 10; batch classifier loss: 0.036253; batch adversarial loss: 0.025656\n",
      "epoch 296; iter: 20; batch classifier loss: 0.039188; batch adversarial loss: 0.026036\n",
      "epoch 296; iter: 30; batch classifier loss: 0.040341; batch adversarial loss: 0.024349\n",
      "epoch 296; iter: 40; batch classifier loss: 0.037395; batch adversarial loss: 0.025710\n",
      "epoch 296; iter: 50; batch classifier loss: 0.037781; batch adversarial loss: 0.025183\n",
      "[297/500] Running epoch\n",
      "epoch 297; iter: 0; batch classifier loss: 0.038946; batch adversarial loss: 0.023086\n",
      "epoch 297; iter: 10; batch classifier loss: 0.039949; batch adversarial loss: 0.019758\n",
      "epoch 297; iter: 20; batch classifier loss: 0.039691; batch adversarial loss: 0.022685\n",
      "epoch 297; iter: 30; batch classifier loss: 0.036064; batch adversarial loss: 0.027095\n",
      "epoch 297; iter: 40; batch classifier loss: 0.037943; batch adversarial loss: 0.022905\n",
      "epoch 297; iter: 50; batch classifier loss: 0.036318; batch adversarial loss: 0.024807\n",
      "[298/500] Running epoch\n",
      "epoch 298; iter: 0; batch classifier loss: 0.038744; batch adversarial loss: 0.025881\n",
      "epoch 298; iter: 10; batch classifier loss: 0.037993; batch adversarial loss: 0.021288\n",
      "epoch 298; iter: 20; batch classifier loss: 0.036994; batch adversarial loss: 0.021711\n",
      "epoch 298; iter: 30; batch classifier loss: 0.038254; batch adversarial loss: 0.019499\n",
      "epoch 298; iter: 40; batch classifier loss: 0.036667; batch adversarial loss: 0.024520\n",
      "epoch 298; iter: 50; batch classifier loss: 0.036533; batch adversarial loss: 0.023868\n",
      "[299/500] Running epoch\n",
      "epoch 299; iter: 0; batch classifier loss: 0.037442; batch adversarial loss: 0.021551\n",
      "epoch 299; iter: 10; batch classifier loss: 0.037678; batch adversarial loss: 0.022414\n",
      "epoch 299; iter: 20; batch classifier loss: 0.038251; batch adversarial loss: 0.023631\n",
      "epoch 299; iter: 30; batch classifier loss: 0.036268; batch adversarial loss: 0.023426\n",
      "epoch 299; iter: 40; batch classifier loss: 0.037223; batch adversarial loss: 0.022814\n",
      "epoch 299; iter: 50; batch classifier loss: 0.036445; batch adversarial loss: 0.020939\n",
      "[300/500] Running epoch\n",
      "epoch 300; iter: 0; batch classifier loss: 0.034388; batch adversarial loss: 0.020440\n",
      "epoch 300; iter: 10; batch classifier loss: 0.037647; batch adversarial loss: 0.025385\n",
      "epoch 300; iter: 20; batch classifier loss: 0.037765; batch adversarial loss: 0.021113\n",
      "epoch 300; iter: 30; batch classifier loss: 0.036837; batch adversarial loss: 0.023486\n",
      "epoch 300; iter: 40; batch classifier loss: 0.036445; batch adversarial loss: 0.026703\n",
      "epoch 300; iter: 50; batch classifier loss: 0.036680; batch adversarial loss: 0.021735\n",
      "||w||: 1.2978529930114746\n",
      "||w2||: 0.5966309309005737\n",
      "w.T g: [[0.30411467]]\n",
      "[301/500] Running epoch\n",
      "epoch 301; iter: 0; batch classifier loss: 0.039661; batch adversarial loss: 0.027955\n",
      "epoch 301; iter: 10; batch classifier loss: 0.036706; batch adversarial loss: 0.023700\n",
      "epoch 301; iter: 20; batch classifier loss: 0.036324; batch adversarial loss: 0.027081\n",
      "epoch 301; iter: 30; batch classifier loss: 0.037526; batch adversarial loss: 0.026621\n",
      "epoch 301; iter: 40; batch classifier loss: 0.036650; batch adversarial loss: 0.021332\n",
      "epoch 301; iter: 50; batch classifier loss: 0.034540; batch adversarial loss: 0.024011\n",
      "[302/500] Running epoch\n",
      "epoch 302; iter: 0; batch classifier loss: 0.037627; batch adversarial loss: 0.021417\n",
      "epoch 302; iter: 10; batch classifier loss: 0.036652; batch adversarial loss: 0.022737\n",
      "epoch 302; iter: 20; batch classifier loss: 0.038988; batch adversarial loss: 0.025960\n",
      "epoch 302; iter: 30; batch classifier loss: 0.036418; batch adversarial loss: 0.024937\n",
      "epoch 302; iter: 40; batch classifier loss: 0.039404; batch adversarial loss: 0.020238\n",
      "epoch 302; iter: 50; batch classifier loss: 0.036520; batch adversarial loss: 0.023795\n",
      "[303/500] Running epoch\n",
      "epoch 303; iter: 0; batch classifier loss: 0.038099; batch adversarial loss: 0.023387\n",
      "epoch 303; iter: 10; batch classifier loss: 0.038129; batch adversarial loss: 0.019525\n",
      "epoch 303; iter: 20; batch classifier loss: 0.037541; batch adversarial loss: 0.021833\n",
      "epoch 303; iter: 30; batch classifier loss: 0.037611; batch adversarial loss: 0.021411\n",
      "epoch 303; iter: 40; batch classifier loss: 0.037438; batch adversarial loss: 0.021426\n",
      "epoch 303; iter: 50; batch classifier loss: 0.038819; batch adversarial loss: 0.021092\n",
      "[304/500] Running epoch\n",
      "epoch 304; iter: 0; batch classifier loss: 0.039521; batch adversarial loss: 0.023778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 304; iter: 10; batch classifier loss: 0.037839; batch adversarial loss: 0.023094\n",
      "epoch 304; iter: 20; batch classifier loss: 0.037809; batch adversarial loss: 0.022694\n",
      "epoch 304; iter: 30; batch classifier loss: 0.039627; batch adversarial loss: 0.025517\n",
      "epoch 304; iter: 40; batch classifier loss: 0.036683; batch adversarial loss: 0.020663\n",
      "epoch 304; iter: 50; batch classifier loss: 0.037063; batch adversarial loss: 0.018711\n",
      "[305/500] Running epoch\n",
      "epoch 305; iter: 0; batch classifier loss: 0.036109; batch adversarial loss: 0.022039\n",
      "epoch 305; iter: 10; batch classifier loss: 0.038092; batch adversarial loss: 0.021401\n",
      "epoch 305; iter: 20; batch classifier loss: 0.039377; batch adversarial loss: 0.021875\n",
      "epoch 305; iter: 30; batch classifier loss: 0.035964; batch adversarial loss: 0.023053\n",
      "epoch 305; iter: 40; batch classifier loss: 0.037038; batch adversarial loss: 0.023942\n",
      "epoch 305; iter: 50; batch classifier loss: 0.036673; batch adversarial loss: 0.022677\n",
      "[306/500] Running epoch\n",
      "epoch 306; iter: 0; batch classifier loss: 0.037943; batch adversarial loss: 0.020073\n",
      "epoch 306; iter: 10; batch classifier loss: 0.036236; batch adversarial loss: 0.020289\n",
      "epoch 306; iter: 20; batch classifier loss: 0.034650; batch adversarial loss: 0.023466\n",
      "epoch 306; iter: 30; batch classifier loss: 0.035817; batch adversarial loss: 0.023509\n",
      "epoch 306; iter: 40; batch classifier loss: 0.034527; batch adversarial loss: 0.023905\n",
      "epoch 306; iter: 50; batch classifier loss: 0.036694; batch adversarial loss: 0.021734\n",
      "[307/500] Running epoch\n",
      "epoch 307; iter: 0; batch classifier loss: 0.037621; batch adversarial loss: 0.020787\n",
      "epoch 307; iter: 10; batch classifier loss: 0.036434; batch adversarial loss: 0.023799\n",
      "epoch 307; iter: 20; batch classifier loss: 0.036853; batch adversarial loss: 0.024909\n",
      "epoch 307; iter: 30; batch classifier loss: 0.037027; batch adversarial loss: 0.023859\n",
      "epoch 307; iter: 40; batch classifier loss: 0.038103; batch adversarial loss: 0.018945\n",
      "epoch 307; iter: 50; batch classifier loss: 0.036811; batch adversarial loss: 0.021221\n",
      "[308/500] Running epoch\n",
      "epoch 308; iter: 0; batch classifier loss: 0.038766; batch adversarial loss: 0.024548\n",
      "epoch 308; iter: 10; batch classifier loss: 0.038006; batch adversarial loss: 0.020935\n",
      "epoch 308; iter: 20; batch classifier loss: 0.036451; batch adversarial loss: 0.025377\n",
      "epoch 308; iter: 30; batch classifier loss: 0.038144; batch adversarial loss: 0.026186\n",
      "epoch 308; iter: 40; batch classifier loss: 0.036908; batch adversarial loss: 0.025497\n",
      "epoch 308; iter: 50; batch classifier loss: 0.036933; batch adversarial loss: 0.019686\n",
      "[309/500] Running epoch\n",
      "epoch 309; iter: 0; batch classifier loss: 0.037450; batch adversarial loss: 0.023820\n",
      "epoch 309; iter: 10; batch classifier loss: 0.037692; batch adversarial loss: 0.024542\n",
      "epoch 309; iter: 20; batch classifier loss: 0.037144; batch adversarial loss: 0.019367\n",
      "epoch 309; iter: 30; batch classifier loss: 0.039049; batch adversarial loss: 0.021823\n",
      "epoch 309; iter: 40; batch classifier loss: 0.034449; batch adversarial loss: 0.022176\n",
      "epoch 309; iter: 50; batch classifier loss: 0.036312; batch adversarial loss: 0.022776\n",
      "[310/500] Running epoch\n",
      "epoch 310; iter: 0; batch classifier loss: 0.037551; batch adversarial loss: 0.022974\n",
      "epoch 310; iter: 10; batch classifier loss: 0.037770; batch adversarial loss: 0.022686\n",
      "epoch 310; iter: 20; batch classifier loss: 0.036232; batch adversarial loss: 0.026825\n",
      "epoch 310; iter: 30; batch classifier loss: 0.037116; batch adversarial loss: 0.019651\n",
      "epoch 310; iter: 40; batch classifier loss: 0.037897; batch adversarial loss: 0.022088\n",
      "epoch 310; iter: 50; batch classifier loss: 0.039171; batch adversarial loss: 0.020352\n",
      "||w||: 1.2978516817092896\n",
      "||w2||: 0.5965964198112488\n",
      "w.T g: [[0.30415166]]\n",
      "[311/500] Running epoch\n",
      "epoch 311; iter: 0; batch classifier loss: 0.037820; batch adversarial loss: 0.022585\n",
      "epoch 311; iter: 10; batch classifier loss: 0.037692; batch adversarial loss: 0.021663\n",
      "epoch 311; iter: 20; batch classifier loss: 0.037176; batch adversarial loss: 0.023647\n",
      "epoch 311; iter: 30; batch classifier loss: 0.038129; batch adversarial loss: 0.023895\n",
      "epoch 311; iter: 40; batch classifier loss: 0.039110; batch adversarial loss: 0.022235\n",
      "epoch 311; iter: 50; batch classifier loss: 0.037576; batch adversarial loss: 0.023142\n",
      "[312/500] Running epoch\n",
      "epoch 312; iter: 0; batch classifier loss: 0.037068; batch adversarial loss: 0.020859\n",
      "epoch 312; iter: 10; batch classifier loss: 0.037719; batch adversarial loss: 0.023129\n",
      "epoch 312; iter: 20; batch classifier loss: 0.037441; batch adversarial loss: 0.020630\n",
      "epoch 312; iter: 30; batch classifier loss: 0.036379; batch adversarial loss: 0.022435\n",
      "epoch 312; iter: 40; batch classifier loss: 0.037303; batch adversarial loss: 0.025550\n",
      "epoch 312; iter: 50; batch classifier loss: 0.037438; batch adversarial loss: 0.025129\n",
      "[313/500] Running epoch\n",
      "epoch 313; iter: 0; batch classifier loss: 0.037274; batch adversarial loss: 0.019508\n",
      "epoch 313; iter: 10; batch classifier loss: 0.039446; batch adversarial loss: 0.025433\n",
      "epoch 313; iter: 20; batch classifier loss: 0.037064; batch adversarial loss: 0.024792\n",
      "epoch 313; iter: 30; batch classifier loss: 0.037978; batch adversarial loss: 0.028060\n",
      "epoch 313; iter: 40; batch classifier loss: 0.039290; batch adversarial loss: 0.026980\n",
      "epoch 313; iter: 50; batch classifier loss: 0.036258; batch adversarial loss: 0.018579\n",
      "[314/500] Running epoch\n",
      "epoch 314; iter: 0; batch classifier loss: 0.037914; batch adversarial loss: 0.024777\n",
      "epoch 314; iter: 10; batch classifier loss: 0.039638; batch adversarial loss: 0.022438\n",
      "epoch 314; iter: 20; batch classifier loss: 0.039996; batch adversarial loss: 0.026613\n",
      "epoch 314; iter: 30; batch classifier loss: 0.039863; batch adversarial loss: 0.024134\n",
      "epoch 314; iter: 40; batch classifier loss: 0.037498; batch adversarial loss: 0.024173\n",
      "epoch 314; iter: 50; batch classifier loss: 0.036979; batch adversarial loss: 0.018819\n",
      "[315/500] Running epoch\n",
      "epoch 315; iter: 0; batch classifier loss: 0.038674; batch adversarial loss: 0.022844\n",
      "epoch 315; iter: 10; batch classifier loss: 0.036132; batch adversarial loss: 0.021206\n",
      "epoch 315; iter: 20; batch classifier loss: 0.035581; batch adversarial loss: 0.022046\n",
      "epoch 315; iter: 30; batch classifier loss: 0.038356; batch adversarial loss: 0.022153\n",
      "epoch 315; iter: 40; batch classifier loss: 0.037256; batch adversarial loss: 0.025475\n",
      "epoch 315; iter: 50; batch classifier loss: 0.035639; batch adversarial loss: 0.024124\n",
      "[316/500] Running epoch\n",
      "epoch 316; iter: 0; batch classifier loss: 0.038157; batch adversarial loss: 0.020523\n",
      "epoch 316; iter: 10; batch classifier loss: 0.036221; batch adversarial loss: 0.026211\n",
      "epoch 316; iter: 20; batch classifier loss: 0.038571; batch adversarial loss: 0.023143\n",
      "epoch 316; iter: 30; batch classifier loss: 0.037708; batch adversarial loss: 0.018348\n",
      "epoch 316; iter: 40; batch classifier loss: 0.037923; batch adversarial loss: 0.021820\n",
      "epoch 316; iter: 50; batch classifier loss: 0.036477; batch adversarial loss: 0.021277\n",
      "[317/500] Running epoch\n",
      "epoch 317; iter: 0; batch classifier loss: 0.039107; batch adversarial loss: 0.025149\n",
      "epoch 317; iter: 10; batch classifier loss: 0.037877; batch adversarial loss: 0.023176\n",
      "epoch 317; iter: 20; batch classifier loss: 0.037105; batch adversarial loss: 0.018550\n",
      "epoch 317; iter: 30; batch classifier loss: 0.038883; batch adversarial loss: 0.022156\n",
      "epoch 317; iter: 40; batch classifier loss: 0.035135; batch adversarial loss: 0.022019\n",
      "epoch 317; iter: 50; batch classifier loss: 0.038874; batch adversarial loss: 0.024629\n",
      "[318/500] Running epoch\n",
      "epoch 318; iter: 0; batch classifier loss: 0.037179; batch adversarial loss: 0.020777\n",
      "epoch 318; iter: 10; batch classifier loss: 0.035862; batch adversarial loss: 0.019152\n",
      "epoch 318; iter: 20; batch classifier loss: 0.039364; batch adversarial loss: 0.025965\n",
      "epoch 318; iter: 30; batch classifier loss: 0.040067; batch adversarial loss: 0.022843\n",
      "epoch 318; iter: 40; batch classifier loss: 0.039069; batch adversarial loss: 0.020982\n",
      "epoch 318; iter: 50; batch classifier loss: 0.039127; batch adversarial loss: 0.025909\n",
      "[319/500] Running epoch\n",
      "epoch 319; iter: 0; batch classifier loss: 0.038178; batch adversarial loss: 0.020950\n",
      "epoch 319; iter: 10; batch classifier loss: 0.036650; batch adversarial loss: 0.023330\n",
      "epoch 319; iter: 20; batch classifier loss: 0.037379; batch adversarial loss: 0.020679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 319; iter: 30; batch classifier loss: 0.036858; batch adversarial loss: 0.019039\n",
      "epoch 319; iter: 40; batch classifier loss: 0.037853; batch adversarial loss: 0.024076\n",
      "epoch 319; iter: 50; batch classifier loss: 0.038790; batch adversarial loss: 0.023315\n",
      "[320/500] Running epoch\n",
      "epoch 320; iter: 0; batch classifier loss: 0.037402; batch adversarial loss: 0.022972\n",
      "epoch 320; iter: 10; batch classifier loss: 0.037157; batch adversarial loss: 0.022470\n",
      "epoch 320; iter: 20; batch classifier loss: 0.037258; batch adversarial loss: 0.020331\n",
      "epoch 320; iter: 30; batch classifier loss: 0.036103; batch adversarial loss: 0.024119\n",
      "epoch 320; iter: 40; batch classifier loss: 0.037039; batch adversarial loss: 0.023350\n",
      "epoch 320; iter: 50; batch classifier loss: 0.038276; batch adversarial loss: 0.025336\n",
      "||w||: 1.2978516817092896\n",
      "||w2||: 0.596573531627655\n",
      "w.T g: [[0.3041761]]\n",
      "[321/500] Running epoch\n",
      "epoch 321; iter: 0; batch classifier loss: 0.038002; batch adversarial loss: 0.022544\n",
      "epoch 321; iter: 10; batch classifier loss: 0.038052; batch adversarial loss: 0.021976\n",
      "epoch 321; iter: 20; batch classifier loss: 0.038457; batch adversarial loss: 0.020783\n",
      "epoch 321; iter: 30; batch classifier loss: 0.038047; batch adversarial loss: 0.023333\n",
      "epoch 321; iter: 40; batch classifier loss: 0.036163; batch adversarial loss: 0.021092\n",
      "epoch 321; iter: 50; batch classifier loss: 0.037556; batch adversarial loss: 0.020022\n",
      "[322/500] Running epoch\n",
      "epoch 322; iter: 0; batch classifier loss: 0.037209; batch adversarial loss: 0.019731\n",
      "epoch 322; iter: 10; batch classifier loss: 0.038610; batch adversarial loss: 0.023412\n",
      "epoch 322; iter: 20; batch classifier loss: 0.036114; batch adversarial loss: 0.022616\n",
      "epoch 322; iter: 30; batch classifier loss: 0.037221; batch adversarial loss: 0.024214\n",
      "epoch 322; iter: 40; batch classifier loss: 0.036298; batch adversarial loss: 0.020397\n",
      "epoch 322; iter: 50; batch classifier loss: 0.037677; batch adversarial loss: 0.030166\n",
      "[323/500] Running epoch\n",
      "epoch 323; iter: 0; batch classifier loss: 0.037081; batch adversarial loss: 0.023396\n",
      "epoch 323; iter: 10; batch classifier loss: 0.037144; batch adversarial loss: 0.022510\n",
      "epoch 323; iter: 20; batch classifier loss: 0.037847; batch adversarial loss: 0.023871\n",
      "epoch 323; iter: 30; batch classifier loss: 0.037465; batch adversarial loss: 0.019548\n",
      "epoch 323; iter: 40; batch classifier loss: 0.038557; batch adversarial loss: 0.024927\n",
      "epoch 323; iter: 50; batch classifier loss: 0.037193; batch adversarial loss: 0.029204\n",
      "[324/500] Running epoch\n",
      "epoch 324; iter: 0; batch classifier loss: 0.035518; batch adversarial loss: 0.021242\n",
      "epoch 324; iter: 10; batch classifier loss: 0.038552; batch adversarial loss: 0.030964\n",
      "epoch 324; iter: 20; batch classifier loss: 0.039673; batch adversarial loss: 0.027737\n",
      "epoch 324; iter: 30; batch classifier loss: 0.039594; batch adversarial loss: 0.026479\n",
      "epoch 324; iter: 40; batch classifier loss: 0.039039; batch adversarial loss: 0.024227\n",
      "epoch 324; iter: 50; batch classifier loss: 0.038548; batch adversarial loss: 0.023686\n",
      "[325/500] Running epoch\n",
      "epoch 325; iter: 0; batch classifier loss: 0.037241; batch adversarial loss: 0.022038\n",
      "epoch 325; iter: 10; batch classifier loss: 0.039810; batch adversarial loss: 0.024003\n",
      "epoch 325; iter: 20; batch classifier loss: 0.039232; batch adversarial loss: 0.023795\n",
      "epoch 325; iter: 30; batch classifier loss: 0.035431; batch adversarial loss: 0.026424\n",
      "epoch 325; iter: 40; batch classifier loss: 0.035398; batch adversarial loss: 0.023900\n",
      "epoch 325; iter: 50; batch classifier loss: 0.038057; batch adversarial loss: 0.023524\n",
      "[326/500] Running epoch\n",
      "epoch 326; iter: 0; batch classifier loss: 0.037987; batch adversarial loss: 0.023363\n",
      "epoch 326; iter: 10; batch classifier loss: 0.036776; batch adversarial loss: 0.025886\n",
      "epoch 326; iter: 20; batch classifier loss: 0.039131; batch adversarial loss: 0.022201\n",
      "epoch 326; iter: 30; batch classifier loss: 0.037058; batch adversarial loss: 0.020980\n",
      "epoch 326; iter: 40; batch classifier loss: 0.036315; batch adversarial loss: 0.025656\n",
      "epoch 326; iter: 50; batch classifier loss: 0.036826; batch adversarial loss: 0.023520\n",
      "[327/500] Running epoch\n",
      "epoch 327; iter: 0; batch classifier loss: 0.039191; batch adversarial loss: 0.021644\n",
      "epoch 327; iter: 10; batch classifier loss: 0.036348; batch adversarial loss: 0.023961\n",
      "epoch 327; iter: 20; batch classifier loss: 0.038170; batch adversarial loss: 0.021885\n",
      "epoch 327; iter: 30; batch classifier loss: 0.037588; batch adversarial loss: 0.023465\n",
      "epoch 327; iter: 40; batch classifier loss: 0.039063; batch adversarial loss: 0.024400\n",
      "epoch 327; iter: 50; batch classifier loss: 0.040125; batch adversarial loss: 0.024667\n",
      "[328/500] Running epoch\n",
      "epoch 328; iter: 0; batch classifier loss: 0.037004; batch adversarial loss: 0.021339\n",
      "epoch 328; iter: 10; batch classifier loss: 0.036701; batch adversarial loss: 0.023074\n",
      "epoch 328; iter: 20; batch classifier loss: 0.038632; batch adversarial loss: 0.022911\n",
      "epoch 328; iter: 30; batch classifier loss: 0.036342; batch adversarial loss: 0.021698\n",
      "epoch 328; iter: 40; batch classifier loss: 0.037458; batch adversarial loss: 0.022250\n",
      "epoch 328; iter: 50; batch classifier loss: 0.038127; batch adversarial loss: 0.023869\n",
      "[329/500] Running epoch\n",
      "epoch 329; iter: 0; batch classifier loss: 0.035964; batch adversarial loss: 0.019680\n",
      "epoch 329; iter: 10; batch classifier loss: 0.036781; batch adversarial loss: 0.023965\n",
      "epoch 329; iter: 20; batch classifier loss: 0.037526; batch adversarial loss: 0.023145\n",
      "epoch 329; iter: 30; batch classifier loss: 0.036518; batch adversarial loss: 0.023400\n",
      "epoch 329; iter: 40; batch classifier loss: 0.037992; batch adversarial loss: 0.024339\n",
      "epoch 329; iter: 50; batch classifier loss: 0.036453; batch adversarial loss: 0.024504\n",
      "[330/500] Running epoch\n",
      "epoch 330; iter: 0; batch classifier loss: 0.037208; batch adversarial loss: 0.023369\n",
      "epoch 330; iter: 10; batch classifier loss: 0.036995; batch adversarial loss: 0.022795\n",
      "epoch 330; iter: 20; batch classifier loss: 0.036924; batch adversarial loss: 0.024268\n",
      "epoch 330; iter: 30; batch classifier loss: 0.037632; batch adversarial loss: 0.026246\n",
      "epoch 330; iter: 40; batch classifier loss: 0.040405; batch adversarial loss: 0.025830\n",
      "epoch 330; iter: 50; batch classifier loss: 0.035295; batch adversarial loss: 0.022321\n",
      "||w||: 1.2978508472442627\n",
      "||w2||: 0.596558153629303\n",
      "w.T g: [[0.30419223]]\n",
      "[331/500] Running epoch\n",
      "epoch 331; iter: 0; batch classifier loss: 0.036952; batch adversarial loss: 0.023616\n",
      "epoch 331; iter: 10; batch classifier loss: 0.038033; batch adversarial loss: 0.023411\n",
      "epoch 331; iter: 20; batch classifier loss: 0.034960; batch adversarial loss: 0.023647\n",
      "epoch 331; iter: 30; batch classifier loss: 0.038549; batch adversarial loss: 0.022462\n",
      "epoch 331; iter: 40; batch classifier loss: 0.037903; batch adversarial loss: 0.022617\n",
      "epoch 331; iter: 50; batch classifier loss: 0.037622; batch adversarial loss: 0.020813\n",
      "[332/500] Running epoch\n",
      "epoch 332; iter: 0; batch classifier loss: 0.036669; batch adversarial loss: 0.020242\n",
      "epoch 332; iter: 10; batch classifier loss: 0.036458; batch adversarial loss: 0.024159\n",
      "epoch 332; iter: 20; batch classifier loss: 0.037604; batch adversarial loss: 0.022178\n",
      "epoch 332; iter: 30; batch classifier loss: 0.037690; batch adversarial loss: 0.021492\n",
      "epoch 332; iter: 40; batch classifier loss: 0.037268; batch adversarial loss: 0.021446\n",
      "epoch 332; iter: 50; batch classifier loss: 0.035722; batch adversarial loss: 0.021864\n",
      "[333/500] Running epoch\n",
      "epoch 333; iter: 0; batch classifier loss: 0.036575; batch adversarial loss: 0.022071\n",
      "epoch 333; iter: 10; batch classifier loss: 0.037210; batch adversarial loss: 0.021260\n",
      "epoch 333; iter: 20; batch classifier loss: 0.038898; batch adversarial loss: 0.019609\n",
      "epoch 333; iter: 30; batch classifier loss: 0.035411; batch adversarial loss: 0.021284\n",
      "epoch 333; iter: 40; batch classifier loss: 0.036471; batch adversarial loss: 0.024641\n",
      "epoch 333; iter: 50; batch classifier loss: 0.036893; batch adversarial loss: 0.023153\n",
      "[334/500] Running epoch\n",
      "epoch 334; iter: 0; batch classifier loss: 0.038082; batch adversarial loss: 0.020391\n",
      "epoch 334; iter: 10; batch classifier loss: 0.037801; batch adversarial loss: 0.024546\n",
      "epoch 334; iter: 20; batch classifier loss: 0.038903; batch adversarial loss: 0.022276\n",
      "epoch 334; iter: 30; batch classifier loss: 0.037981; batch adversarial loss: 0.019896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 334; iter: 40; batch classifier loss: 0.037223; batch adversarial loss: 0.025263\n",
      "epoch 334; iter: 50; batch classifier loss: 0.037802; batch adversarial loss: 0.024065\n",
      "[335/500] Running epoch\n",
      "epoch 335; iter: 0; batch classifier loss: 0.037665; batch adversarial loss: 0.026105\n",
      "epoch 335; iter: 10; batch classifier loss: 0.036827; batch adversarial loss: 0.021144\n",
      "epoch 335; iter: 20; batch classifier loss: 0.038634; batch adversarial loss: 0.020561\n",
      "epoch 335; iter: 30; batch classifier loss: 0.036708; batch adversarial loss: 0.021010\n",
      "epoch 335; iter: 40; batch classifier loss: 0.036372; batch adversarial loss: 0.023508\n",
      "epoch 335; iter: 50; batch classifier loss: 0.037469; batch adversarial loss: 0.022509\n",
      "[336/500] Running epoch\n",
      "epoch 336; iter: 0; batch classifier loss: 0.034507; batch adversarial loss: 0.021687\n",
      "epoch 336; iter: 10; batch classifier loss: 0.039250; batch adversarial loss: 0.022431\n",
      "epoch 336; iter: 20; batch classifier loss: 0.038459; batch adversarial loss: 0.021891\n",
      "epoch 336; iter: 30; batch classifier loss: 0.040033; batch adversarial loss: 0.027245\n",
      "epoch 336; iter: 40; batch classifier loss: 0.038942; batch adversarial loss: 0.021053\n",
      "epoch 336; iter: 50; batch classifier loss: 0.037680; batch adversarial loss: 0.023461\n",
      "[337/500] Running epoch\n",
      "epoch 337; iter: 0; batch classifier loss: 0.038410; batch adversarial loss: 0.022463\n",
      "epoch 337; iter: 10; batch classifier loss: 0.036939; batch adversarial loss: 0.022332\n",
      "epoch 337; iter: 20; batch classifier loss: 0.036699; batch adversarial loss: 0.023169\n",
      "epoch 337; iter: 30; batch classifier loss: 0.037427; batch adversarial loss: 0.025565\n",
      "epoch 337; iter: 40; batch classifier loss: 0.037049; batch adversarial loss: 0.024997\n",
      "epoch 337; iter: 50; batch classifier loss: 0.038464; batch adversarial loss: 0.024146\n",
      "[338/500] Running epoch\n",
      "epoch 338; iter: 0; batch classifier loss: 0.037827; batch adversarial loss: 0.022986\n",
      "epoch 338; iter: 10; batch classifier loss: 0.038741; batch adversarial loss: 0.024863\n",
      "epoch 338; iter: 20; batch classifier loss: 0.038086; batch adversarial loss: 0.023407\n",
      "epoch 338; iter: 30; batch classifier loss: 0.037636; batch adversarial loss: 0.024784\n",
      "epoch 338; iter: 40; batch classifier loss: 0.036952; batch adversarial loss: 0.024419\n",
      "epoch 338; iter: 50; batch classifier loss: 0.036500; batch adversarial loss: 0.026474\n",
      "[339/500] Running epoch\n",
      "epoch 339; iter: 0; batch classifier loss: 0.038802; batch adversarial loss: 0.026227\n",
      "epoch 339; iter: 10; batch classifier loss: 0.038891; batch adversarial loss: 0.026096\n",
      "epoch 339; iter: 20; batch classifier loss: 0.036728; batch adversarial loss: 0.027059\n",
      "epoch 339; iter: 30; batch classifier loss: 0.037275; batch adversarial loss: 0.024029\n",
      "epoch 339; iter: 40; batch classifier loss: 0.038987; batch adversarial loss: 0.023010\n",
      "epoch 339; iter: 50; batch classifier loss: 0.040689; batch adversarial loss: 0.021741\n",
      "[340/500] Running epoch\n",
      "epoch 340; iter: 0; batch classifier loss: 0.039222; batch adversarial loss: 0.027863\n",
      "epoch 340; iter: 10; batch classifier loss: 0.040453; batch adversarial loss: 0.023190\n",
      "epoch 340; iter: 20; batch classifier loss: 0.038952; batch adversarial loss: 0.025757\n",
      "epoch 340; iter: 30; batch classifier loss: 0.038237; batch adversarial loss: 0.025413\n",
      "epoch 340; iter: 40; batch classifier loss: 0.038410; batch adversarial loss: 0.023696\n",
      "epoch 340; iter: 50; batch classifier loss: 0.035094; batch adversarial loss: 0.019903\n",
      "||w||: 1.297850251197815\n",
      "||w2||: 0.5965480208396912\n",
      "w.T g: [[0.30420265]]\n",
      "[341/500] Running epoch\n",
      "epoch 341; iter: 0; batch classifier loss: 0.037199; batch adversarial loss: 0.023189\n",
      "epoch 341; iter: 10; batch classifier loss: 0.037072; batch adversarial loss: 0.023393\n",
      "epoch 341; iter: 20; batch classifier loss: 0.038878; batch adversarial loss: 0.024488\n",
      "epoch 341; iter: 30; batch classifier loss: 0.035765; batch adversarial loss: 0.025368\n",
      "epoch 341; iter: 40; batch classifier loss: 0.037761; batch adversarial loss: 0.024696\n",
      "epoch 341; iter: 50; batch classifier loss: 0.039211; batch adversarial loss: 0.021876\n",
      "[342/500] Running epoch\n",
      "epoch 342; iter: 0; batch classifier loss: 0.036863; batch adversarial loss: 0.022851\n",
      "epoch 342; iter: 10; batch classifier loss: 0.038734; batch adversarial loss: 0.026277\n",
      "epoch 342; iter: 20; batch classifier loss: 0.039684; batch adversarial loss: 0.023389\n",
      "epoch 342; iter: 30; batch classifier loss: 0.038878; batch adversarial loss: 0.028513\n",
      "epoch 342; iter: 40; batch classifier loss: 0.039732; batch adversarial loss: 0.025147\n",
      "epoch 342; iter: 50; batch classifier loss: 0.039159; batch adversarial loss: 0.022483\n",
      "[343/500] Running epoch\n",
      "epoch 343; iter: 0; batch classifier loss: 0.039484; batch adversarial loss: 0.025870\n",
      "epoch 343; iter: 10; batch classifier loss: 0.038329; batch adversarial loss: 0.023883\n",
      "epoch 343; iter: 20; batch classifier loss: 0.036104; batch adversarial loss: 0.020422\n",
      "epoch 343; iter: 30; batch classifier loss: 0.035515; batch adversarial loss: 0.021746\n",
      "epoch 343; iter: 40; batch classifier loss: 0.037867; batch adversarial loss: 0.020030\n",
      "epoch 343; iter: 50; batch classifier loss: 0.039270; batch adversarial loss: 0.027041\n",
      "[344/500] Running epoch\n",
      "epoch 344; iter: 0; batch classifier loss: 0.036782; batch adversarial loss: 0.023245\n",
      "epoch 344; iter: 10; batch classifier loss: 0.037995; batch adversarial loss: 0.025491\n",
      "epoch 344; iter: 20; batch classifier loss: 0.036839; batch adversarial loss: 0.023204\n",
      "epoch 344; iter: 30; batch classifier loss: 0.037961; batch adversarial loss: 0.024660\n",
      "epoch 344; iter: 40; batch classifier loss: 0.038176; batch adversarial loss: 0.025379\n",
      "epoch 344; iter: 50; batch classifier loss: 0.038243; batch adversarial loss: 0.025559\n",
      "[345/500] Running epoch\n",
      "epoch 345; iter: 0; batch classifier loss: 0.037328; batch adversarial loss: 0.021724\n",
      "epoch 345; iter: 10; batch classifier loss: 0.038513; batch adversarial loss: 0.023099\n",
      "epoch 345; iter: 20; batch classifier loss: 0.037564; batch adversarial loss: 0.025115\n",
      "epoch 345; iter: 30; batch classifier loss: 0.035924; batch adversarial loss: 0.023563\n",
      "epoch 345; iter: 40; batch classifier loss: 0.036231; batch adversarial loss: 0.019164\n",
      "epoch 345; iter: 50; batch classifier loss: 0.037916; batch adversarial loss: 0.020451\n",
      "[346/500] Running epoch\n",
      "epoch 346; iter: 0; batch classifier loss: 0.039766; batch adversarial loss: 0.025418\n",
      "epoch 346; iter: 10; batch classifier loss: 0.035507; batch adversarial loss: 0.023522\n",
      "epoch 346; iter: 20; batch classifier loss: 0.038301; batch adversarial loss: 0.019709\n",
      "epoch 346; iter: 30; batch classifier loss: 0.037155; batch adversarial loss: 0.025460\n",
      "epoch 346; iter: 40; batch classifier loss: 0.039381; batch adversarial loss: 0.023918\n",
      "epoch 346; iter: 50; batch classifier loss: 0.036964; batch adversarial loss: 0.024092\n",
      "[347/500] Running epoch\n",
      "epoch 347; iter: 0; batch classifier loss: 0.038721; batch adversarial loss: 0.028724\n",
      "epoch 347; iter: 10; batch classifier loss: 0.036471; batch adversarial loss: 0.022620\n",
      "epoch 347; iter: 20; batch classifier loss: 0.038869; batch adversarial loss: 0.030581\n",
      "epoch 347; iter: 30; batch classifier loss: 0.036980; batch adversarial loss: 0.023374\n",
      "epoch 347; iter: 40; batch classifier loss: 0.037131; batch adversarial loss: 0.020909\n",
      "epoch 347; iter: 50; batch classifier loss: 0.039432; batch adversarial loss: 0.027219\n",
      "[348/500] Running epoch\n",
      "epoch 348; iter: 0; batch classifier loss: 0.038237; batch adversarial loss: 0.023843\n",
      "epoch 348; iter: 10; batch classifier loss: 0.035689; batch adversarial loss: 0.021919\n",
      "epoch 348; iter: 20; batch classifier loss: 0.036951; batch adversarial loss: 0.023761\n",
      "epoch 348; iter: 30; batch classifier loss: 0.037532; batch adversarial loss: 0.019472\n",
      "epoch 348; iter: 40; batch classifier loss: 0.037798; batch adversarial loss: 0.024914\n",
      "epoch 348; iter: 50; batch classifier loss: 0.036624; batch adversarial loss: 0.023434\n",
      "[349/500] Running epoch\n",
      "epoch 349; iter: 0; batch classifier loss: 0.038462; batch adversarial loss: 0.020541\n",
      "epoch 349; iter: 10; batch classifier loss: 0.037219; batch adversarial loss: 0.024320\n",
      "epoch 349; iter: 20; batch classifier loss: 0.038739; batch adversarial loss: 0.027276\n",
      "epoch 349; iter: 30; batch classifier loss: 0.038195; batch adversarial loss: 0.021448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 349; iter: 40; batch classifier loss: 0.037639; batch adversarial loss: 0.020580\n",
      "epoch 349; iter: 50; batch classifier loss: 0.038387; batch adversarial loss: 0.021132\n",
      "[350/500] Running epoch\n",
      "epoch 350; iter: 0; batch classifier loss: 0.037714; batch adversarial loss: 0.028648\n",
      "epoch 350; iter: 10; batch classifier loss: 0.038856; batch adversarial loss: 0.025374\n",
      "epoch 350; iter: 20; batch classifier loss: 0.038653; batch adversarial loss: 0.022554\n",
      "epoch 350; iter: 30; batch classifier loss: 0.039253; batch adversarial loss: 0.025542\n",
      "epoch 350; iter: 40; batch classifier loss: 0.035291; batch adversarial loss: 0.024385\n",
      "epoch 350; iter: 50; batch classifier loss: 0.039314; batch adversarial loss: 0.025000\n",
      "||w||: 1.2978501319885254\n",
      "||w2||: 0.5965412259101868\n",
      "w.T g: [[0.30421065]]\n",
      "[351/500] Running epoch\n",
      "epoch 351; iter: 0; batch classifier loss: 0.037335; batch adversarial loss: 0.024997\n",
      "epoch 351; iter: 10; batch classifier loss: 0.035582; batch adversarial loss: 0.024796\n",
      "epoch 351; iter: 20; batch classifier loss: 0.037317; batch adversarial loss: 0.018923\n",
      "epoch 351; iter: 30; batch classifier loss: 0.036844; batch adversarial loss: 0.021797\n",
      "epoch 351; iter: 40; batch classifier loss: 0.039136; batch adversarial loss: 0.021703\n",
      "epoch 351; iter: 50; batch classifier loss: 0.038861; batch adversarial loss: 0.021310\n",
      "[352/500] Running epoch\n",
      "epoch 352; iter: 0; batch classifier loss: 0.038314; batch adversarial loss: 0.020814\n",
      "epoch 352; iter: 10; batch classifier loss: 0.035969; batch adversarial loss: 0.023616\n",
      "epoch 352; iter: 20; batch classifier loss: 0.037194; batch adversarial loss: 0.024567\n",
      "epoch 352; iter: 30; batch classifier loss: 0.038307; batch adversarial loss: 0.023838\n",
      "epoch 352; iter: 40; batch classifier loss: 0.038106; batch adversarial loss: 0.026112\n",
      "epoch 352; iter: 50; batch classifier loss: 0.036261; batch adversarial loss: 0.021895\n",
      "[353/500] Running epoch\n",
      "epoch 353; iter: 0; batch classifier loss: 0.038740; batch adversarial loss: 0.028413\n",
      "epoch 353; iter: 10; batch classifier loss: 0.037797; batch adversarial loss: 0.024805\n",
      "epoch 353; iter: 20; batch classifier loss: 0.035677; batch adversarial loss: 0.024100\n",
      "epoch 353; iter: 30; batch classifier loss: 0.036456; batch adversarial loss: 0.024044\n",
      "epoch 353; iter: 40; batch classifier loss: 0.037073; batch adversarial loss: 0.022963\n",
      "epoch 353; iter: 50; batch classifier loss: 0.036890; batch adversarial loss: 0.027347\n",
      "[354/500] Running epoch\n",
      "epoch 354; iter: 0; batch classifier loss: 0.036909; batch adversarial loss: 0.023161\n",
      "epoch 354; iter: 10; batch classifier loss: 0.039037; batch adversarial loss: 0.025065\n",
      "epoch 354; iter: 20; batch classifier loss: 0.038940; batch adversarial loss: 0.025742\n",
      "epoch 354; iter: 30; batch classifier loss: 0.040687; batch adversarial loss: 0.025963\n",
      "epoch 354; iter: 40; batch classifier loss: 0.038862; batch adversarial loss: 0.021701\n",
      "epoch 354; iter: 50; batch classifier loss: 0.038248; batch adversarial loss: 0.022273\n",
      "[355/500] Running epoch\n",
      "epoch 355; iter: 0; batch classifier loss: 0.036753; batch adversarial loss: 0.020570\n",
      "epoch 355; iter: 10; batch classifier loss: 0.039652; batch adversarial loss: 0.019097\n",
      "epoch 355; iter: 20; batch classifier loss: 0.038534; batch adversarial loss: 0.022846\n",
      "epoch 355; iter: 30; batch classifier loss: 0.038744; batch adversarial loss: 0.025484\n",
      "epoch 355; iter: 40; batch classifier loss: 0.038304; batch adversarial loss: 0.024243\n",
      "epoch 355; iter: 50; batch classifier loss: 0.038801; batch adversarial loss: 0.025800\n",
      "[356/500] Running epoch\n",
      "epoch 356; iter: 0; batch classifier loss: 0.037546; batch adversarial loss: 0.027325\n",
      "epoch 356; iter: 10; batch classifier loss: 0.039371; batch adversarial loss: 0.025365\n",
      "epoch 356; iter: 20; batch classifier loss: 0.037212; batch adversarial loss: 0.024171\n",
      "epoch 356; iter: 30; batch classifier loss: 0.037412; batch adversarial loss: 0.020770\n",
      "epoch 356; iter: 40; batch classifier loss: 0.037993; batch adversarial loss: 0.022183\n",
      "epoch 356; iter: 50; batch classifier loss: 0.038945; batch adversarial loss: 0.025717\n",
      "[357/500] Running epoch\n",
      "epoch 357; iter: 0; batch classifier loss: 0.038459; batch adversarial loss: 0.026066\n",
      "epoch 357; iter: 10; batch classifier loss: 0.036250; batch adversarial loss: 0.025660\n",
      "epoch 357; iter: 20; batch classifier loss: 0.036220; batch adversarial loss: 0.025742\n",
      "epoch 357; iter: 30; batch classifier loss: 0.037567; batch adversarial loss: 0.024257\n",
      "epoch 357; iter: 40; batch classifier loss: 0.038763; batch adversarial loss: 0.024473\n",
      "epoch 357; iter: 50; batch classifier loss: 0.037330; batch adversarial loss: 0.022525\n",
      "[358/500] Running epoch\n",
      "epoch 358; iter: 0; batch classifier loss: 0.037537; batch adversarial loss: 0.022242\n",
      "epoch 358; iter: 10; batch classifier loss: 0.039038; batch adversarial loss: 0.023412\n",
      "epoch 358; iter: 20; batch classifier loss: 0.036908; batch adversarial loss: 0.022079\n",
      "epoch 358; iter: 30; batch classifier loss: 0.036848; batch adversarial loss: 0.023729\n",
      "epoch 358; iter: 40; batch classifier loss: 0.036122; batch adversarial loss: 0.024060\n",
      "epoch 358; iter: 50; batch classifier loss: 0.037020; batch adversarial loss: 0.022034\n",
      "[359/500] Running epoch\n",
      "epoch 359; iter: 0; batch classifier loss: 0.037895; batch adversarial loss: 0.023698\n",
      "epoch 359; iter: 10; batch classifier loss: 0.038335; batch adversarial loss: 0.022494\n",
      "epoch 359; iter: 20; batch classifier loss: 0.037507; batch adversarial loss: 0.024591\n",
      "epoch 359; iter: 30; batch classifier loss: 0.038581; batch adversarial loss: 0.018661\n",
      "epoch 359; iter: 40; batch classifier loss: 0.038283; batch adversarial loss: 0.022719\n",
      "epoch 359; iter: 50; batch classifier loss: 0.033503; batch adversarial loss: 0.022790\n",
      "[360/500] Running epoch\n",
      "epoch 360; iter: 0; batch classifier loss: 0.036413; batch adversarial loss: 0.022772\n",
      "epoch 360; iter: 10; batch classifier loss: 0.037426; batch adversarial loss: 0.020121\n",
      "epoch 360; iter: 20; batch classifier loss: 0.037473; batch adversarial loss: 0.022927\n",
      "epoch 360; iter: 30; batch classifier loss: 0.037035; batch adversarial loss: 0.021802\n",
      "epoch 360; iter: 40; batch classifier loss: 0.036366; batch adversarial loss: 0.022493\n",
      "epoch 360; iter: 50; batch classifier loss: 0.036491; batch adversarial loss: 0.022330\n",
      "||w||: 1.297851324081421\n",
      "||w2||: 0.596537172794342\n",
      "w.T g: [[0.30421515]]\n",
      "[361/500] Running epoch\n",
      "epoch 361; iter: 0; batch classifier loss: 0.038573; batch adversarial loss: 0.020819\n",
      "epoch 361; iter: 10; batch classifier loss: 0.039389; batch adversarial loss: 0.028935\n",
      "epoch 361; iter: 20; batch classifier loss: 0.036348; batch adversarial loss: 0.023645\n",
      "epoch 361; iter: 30; batch classifier loss: 0.037240; batch adversarial loss: 0.021659\n",
      "epoch 361; iter: 40; batch classifier loss: 0.037859; batch adversarial loss: 0.024932\n",
      "epoch 361; iter: 50; batch classifier loss: 0.036268; batch adversarial loss: 0.021599\n",
      "[362/500] Running epoch\n",
      "epoch 362; iter: 0; batch classifier loss: 0.036656; batch adversarial loss: 0.026654\n",
      "epoch 362; iter: 10; batch classifier loss: 0.037103; batch adversarial loss: 0.022152\n",
      "epoch 362; iter: 20; batch classifier loss: 0.038531; batch adversarial loss: 0.028086\n",
      "epoch 362; iter: 30; batch classifier loss: 0.035881; batch adversarial loss: 0.024397\n",
      "epoch 362; iter: 40; batch classifier loss: 0.038434; batch adversarial loss: 0.023105\n",
      "epoch 362; iter: 50; batch classifier loss: 0.035927; batch adversarial loss: 0.023802\n",
      "[363/500] Running epoch\n",
      "epoch 363; iter: 0; batch classifier loss: 0.039664; batch adversarial loss: 0.028170\n",
      "epoch 363; iter: 10; batch classifier loss: 0.038663; batch adversarial loss: 0.026609\n",
      "epoch 363; iter: 20; batch classifier loss: 0.034813; batch adversarial loss: 0.020917\n",
      "epoch 363; iter: 30; batch classifier loss: 0.039196; batch adversarial loss: 0.023356\n",
      "epoch 363; iter: 40; batch classifier loss: 0.039868; batch adversarial loss: 0.022788\n",
      "epoch 363; iter: 50; batch classifier loss: 0.037551; batch adversarial loss: 0.020812\n",
      "[364/500] Running epoch\n",
      "epoch 364; iter: 0; batch classifier loss: 0.037640; batch adversarial loss: 0.020364\n",
      "epoch 364; iter: 10; batch classifier loss: 0.037083; batch adversarial loss: 0.024186\n",
      "epoch 364; iter: 20; batch classifier loss: 0.036857; batch adversarial loss: 0.020962\n",
      "epoch 364; iter: 30; batch classifier loss: 0.037056; batch adversarial loss: 0.022625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 364; iter: 40; batch classifier loss: 0.039003; batch adversarial loss: 0.022172\n",
      "epoch 364; iter: 50; batch classifier loss: 0.039302; batch adversarial loss: 0.023595\n",
      "[365/500] Running epoch\n",
      "epoch 365; iter: 0; batch classifier loss: 0.036230; batch adversarial loss: 0.023172\n",
      "epoch 365; iter: 10; batch classifier loss: 0.037933; batch adversarial loss: 0.024090\n",
      "epoch 365; iter: 20; batch classifier loss: 0.036469; batch adversarial loss: 0.022446\n",
      "epoch 365; iter: 30; batch classifier loss: 0.036283; batch adversarial loss: 0.030586\n",
      "epoch 365; iter: 40; batch classifier loss: 0.038405; batch adversarial loss: 0.019253\n",
      "epoch 365; iter: 50; batch classifier loss: 0.036434; batch adversarial loss: 0.024981\n",
      "[366/500] Running epoch\n",
      "epoch 366; iter: 0; batch classifier loss: 0.038914; batch adversarial loss: 0.026335\n",
      "epoch 366; iter: 10; batch classifier loss: 0.038248; batch adversarial loss: 0.018821\n",
      "epoch 366; iter: 20; batch classifier loss: 0.037756; batch adversarial loss: 0.023648\n",
      "epoch 366; iter: 30; batch classifier loss: 0.039481; batch adversarial loss: 0.022140\n",
      "epoch 366; iter: 40; batch classifier loss: 0.038285; batch adversarial loss: 0.025050\n",
      "epoch 366; iter: 50; batch classifier loss: 0.037597; batch adversarial loss: 0.022497\n",
      "[367/500] Running epoch\n",
      "epoch 367; iter: 0; batch classifier loss: 0.036371; batch adversarial loss: 0.020021\n",
      "epoch 367; iter: 10; batch classifier loss: 0.037922; batch adversarial loss: 0.019436\n",
      "epoch 367; iter: 20; batch classifier loss: 0.037741; batch adversarial loss: 0.022214\n",
      "epoch 367; iter: 30; batch classifier loss: 0.037712; batch adversarial loss: 0.022437\n",
      "epoch 367; iter: 40; batch classifier loss: 0.039285; batch adversarial loss: 0.023784\n",
      "epoch 367; iter: 50; batch classifier loss: 0.039560; batch adversarial loss: 0.026275\n",
      "[368/500] Running epoch\n",
      "epoch 368; iter: 0; batch classifier loss: 0.037949; batch adversarial loss: 0.027009\n",
      "epoch 368; iter: 10; batch classifier loss: 0.037283; batch adversarial loss: 0.022128\n",
      "epoch 368; iter: 20; batch classifier loss: 0.036980; batch adversarial loss: 0.026406\n",
      "epoch 368; iter: 30; batch classifier loss: 0.036760; batch adversarial loss: 0.023243\n",
      "epoch 368; iter: 40; batch classifier loss: 0.038837; batch adversarial loss: 0.023959\n",
      "epoch 368; iter: 50; batch classifier loss: 0.037358; batch adversarial loss: 0.021348\n",
      "[369/500] Running epoch\n",
      "epoch 369; iter: 0; batch classifier loss: 0.035645; batch adversarial loss: 0.023000\n",
      "epoch 369; iter: 10; batch classifier loss: 0.039251; batch adversarial loss: 0.025384\n",
      "epoch 369; iter: 20; batch classifier loss: 0.037994; batch adversarial loss: 0.023210\n",
      "epoch 369; iter: 30; batch classifier loss: 0.039572; batch adversarial loss: 0.022523\n",
      "epoch 369; iter: 40; batch classifier loss: 0.037220; batch adversarial loss: 0.023878\n",
      "epoch 369; iter: 50; batch classifier loss: 0.036776; batch adversarial loss: 0.024497\n",
      "[370/500] Running epoch\n",
      "epoch 370; iter: 0; batch classifier loss: 0.038730; batch adversarial loss: 0.026428\n",
      "epoch 370; iter: 10; batch classifier loss: 0.038674; batch adversarial loss: 0.025553\n",
      "epoch 370; iter: 20; batch classifier loss: 0.037387; batch adversarial loss: 0.027588\n",
      "epoch 370; iter: 30; batch classifier loss: 0.037600; batch adversarial loss: 0.021170\n",
      "epoch 370; iter: 40; batch classifier loss: 0.036346; batch adversarial loss: 0.017450\n",
      "epoch 370; iter: 50; batch classifier loss: 0.038871; batch adversarial loss: 0.019558\n",
      "||w||: 1.2978533506393433\n",
      "||w2||: 0.5965346097946167\n",
      "w.T g: [[0.30421747]]\n",
      "[371/500] Running epoch\n",
      "epoch 371; iter: 0; batch classifier loss: 0.038666; batch adversarial loss: 0.020119\n",
      "epoch 371; iter: 10; batch classifier loss: 0.038847; batch adversarial loss: 0.025683\n",
      "epoch 371; iter: 20; batch classifier loss: 0.035949; batch adversarial loss: 0.024758\n",
      "epoch 371; iter: 30; batch classifier loss: 0.035709; batch adversarial loss: 0.023588\n",
      "epoch 371; iter: 40; batch classifier loss: 0.038063; batch adversarial loss: 0.021064\n",
      "epoch 371; iter: 50; batch classifier loss: 0.035330; batch adversarial loss: 0.023201\n",
      "[372/500] Running epoch\n",
      "epoch 372; iter: 0; batch classifier loss: 0.037971; batch adversarial loss: 0.022536\n",
      "epoch 372; iter: 10; batch classifier loss: 0.037704; batch adversarial loss: 0.021811\n",
      "epoch 372; iter: 20; batch classifier loss: 0.036399; batch adversarial loss: 0.020174\n",
      "epoch 372; iter: 30; batch classifier loss: 0.036756; batch adversarial loss: 0.024371\n",
      "epoch 372; iter: 40; batch classifier loss: 0.036322; batch adversarial loss: 0.024970\n",
      "epoch 372; iter: 50; batch classifier loss: 0.038462; batch adversarial loss: 0.023463\n",
      "[373/500] Running epoch\n",
      "epoch 373; iter: 0; batch classifier loss: 0.035988; batch adversarial loss: 0.023464\n",
      "epoch 373; iter: 10; batch classifier loss: 0.038195; batch adversarial loss: 0.023478\n",
      "epoch 373; iter: 20; batch classifier loss: 0.039012; batch adversarial loss: 0.021685\n",
      "epoch 373; iter: 30; batch classifier loss: 0.037505; batch adversarial loss: 0.022862\n",
      "epoch 373; iter: 40; batch classifier loss: 0.037372; batch adversarial loss: 0.022562\n",
      "epoch 373; iter: 50; batch classifier loss: 0.037713; batch adversarial loss: 0.026747\n",
      "[374/500] Running epoch\n",
      "epoch 374; iter: 0; batch classifier loss: 0.035676; batch adversarial loss: 0.022754\n",
      "epoch 374; iter: 10; batch classifier loss: 0.037998; batch adversarial loss: 0.019847\n",
      "epoch 374; iter: 20; batch classifier loss: 0.038602; batch adversarial loss: 0.028145\n",
      "epoch 374; iter: 30; batch classifier loss: 0.037732; batch adversarial loss: 0.021628\n",
      "epoch 374; iter: 40; batch classifier loss: 0.037786; batch adversarial loss: 0.027843\n",
      "epoch 374; iter: 50; batch classifier loss: 0.036618; batch adversarial loss: 0.023359\n",
      "[375/500] Running epoch\n",
      "epoch 375; iter: 0; batch classifier loss: 0.037545; batch adversarial loss: 0.020299\n",
      "epoch 375; iter: 10; batch classifier loss: 0.035071; batch adversarial loss: 0.021726\n",
      "epoch 375; iter: 20; batch classifier loss: 0.038681; batch adversarial loss: 0.023214\n",
      "epoch 375; iter: 30; batch classifier loss: 0.037976; batch adversarial loss: 0.024799\n",
      "epoch 375; iter: 40; batch classifier loss: 0.036786; batch adversarial loss: 0.023392\n",
      "epoch 375; iter: 50; batch classifier loss: 0.039537; batch adversarial loss: 0.021733\n",
      "[376/500] Running epoch\n",
      "epoch 376; iter: 0; batch classifier loss: 0.039278; batch adversarial loss: 0.023896\n",
      "epoch 376; iter: 10; batch classifier loss: 0.037633; batch adversarial loss: 0.022987\n",
      "epoch 376; iter: 20; batch classifier loss: 0.037581; batch adversarial loss: 0.029225\n",
      "epoch 376; iter: 30; batch classifier loss: 0.035450; batch adversarial loss: 0.023256\n",
      "epoch 376; iter: 40; batch classifier loss: 0.036004; batch adversarial loss: 0.021417\n",
      "epoch 376; iter: 50; batch classifier loss: 0.035350; batch adversarial loss: 0.022546\n",
      "[377/500] Running epoch\n",
      "epoch 377; iter: 0; batch classifier loss: 0.037100; batch adversarial loss: 0.022294\n",
      "epoch 377; iter: 10; batch classifier loss: 0.036654; batch adversarial loss: 0.024470\n",
      "epoch 377; iter: 20; batch classifier loss: 0.037847; batch adversarial loss: 0.026524\n",
      "epoch 377; iter: 30; batch classifier loss: 0.034189; batch adversarial loss: 0.023245\n",
      "epoch 377; iter: 40; batch classifier loss: 0.038362; batch adversarial loss: 0.027149\n",
      "epoch 377; iter: 50; batch classifier loss: 0.036003; batch adversarial loss: 0.022637\n",
      "[378/500] Running epoch\n",
      "epoch 378; iter: 0; batch classifier loss: 0.036602; batch adversarial loss: 0.025162\n",
      "epoch 378; iter: 10; batch classifier loss: 0.036884; batch adversarial loss: 0.021677\n",
      "epoch 378; iter: 20; batch classifier loss: 0.037089; batch adversarial loss: 0.023895\n",
      "epoch 378; iter: 30; batch classifier loss: 0.037565; batch adversarial loss: 0.021757\n",
      "epoch 378; iter: 40; batch classifier loss: 0.037140; batch adversarial loss: 0.023686\n",
      "epoch 378; iter: 50; batch classifier loss: 0.037483; batch adversarial loss: 0.022716\n",
      "[379/500] Running epoch\n",
      "epoch 379; iter: 0; batch classifier loss: 0.037710; batch adversarial loss: 0.021137\n",
      "epoch 379; iter: 10; batch classifier loss: 0.038590; batch adversarial loss: 0.027255\n",
      "epoch 379; iter: 20; batch classifier loss: 0.036395; batch adversarial loss: 0.023766\n",
      "epoch 379; iter: 30; batch classifier loss: 0.037630; batch adversarial loss: 0.020828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 379; iter: 40; batch classifier loss: 0.037643; batch adversarial loss: 0.027953\n",
      "epoch 379; iter: 50; batch classifier loss: 0.037500; batch adversarial loss: 0.022773\n",
      "[380/500] Running epoch\n",
      "epoch 380; iter: 0; batch classifier loss: 0.040113; batch adversarial loss: 0.024318\n",
      "epoch 380; iter: 10; batch classifier loss: 0.040217; batch adversarial loss: 0.026017\n",
      "epoch 380; iter: 20; batch classifier loss: 0.039121; batch adversarial loss: 0.018760\n",
      "epoch 380; iter: 30; batch classifier loss: 0.035053; batch adversarial loss: 0.026646\n",
      "epoch 380; iter: 40; batch classifier loss: 0.037524; batch adversarial loss: 0.027710\n",
      "epoch 380; iter: 50; batch classifier loss: 0.039804; batch adversarial loss: 0.022842\n",
      "||w||: 1.2978535890579224\n",
      "||w2||: 0.5965333580970764\n",
      "w.T g: [[0.30421944]]\n",
      "[381/500] Running epoch\n",
      "epoch 381; iter: 0; batch classifier loss: 0.037732; batch adversarial loss: 0.021303\n",
      "epoch 381; iter: 10; batch classifier loss: 0.037312; batch adversarial loss: 0.025621\n",
      "epoch 381; iter: 20; batch classifier loss: 0.037276; batch adversarial loss: 0.023673\n",
      "epoch 381; iter: 30; batch classifier loss: 0.037756; batch adversarial loss: 0.028715\n",
      "epoch 381; iter: 40; batch classifier loss: 0.039436; batch adversarial loss: 0.023848\n",
      "epoch 381; iter: 50; batch classifier loss: 0.035039; batch adversarial loss: 0.023548\n",
      "[382/500] Running epoch\n",
      "epoch 382; iter: 0; batch classifier loss: 0.037294; batch adversarial loss: 0.021943\n",
      "epoch 382; iter: 10; batch classifier loss: 0.037376; batch adversarial loss: 0.024368\n",
      "epoch 382; iter: 20; batch classifier loss: 0.038233; batch adversarial loss: 0.026334\n",
      "epoch 382; iter: 30; batch classifier loss: 0.037554; batch adversarial loss: 0.026716\n",
      "epoch 382; iter: 40; batch classifier loss: 0.038208; batch adversarial loss: 0.021645\n",
      "epoch 382; iter: 50; batch classifier loss: 0.039543; batch adversarial loss: 0.026805\n",
      "[383/500] Running epoch\n",
      "epoch 383; iter: 0; batch classifier loss: 0.037091; batch adversarial loss: 0.024097\n",
      "epoch 383; iter: 10; batch classifier loss: 0.036242; batch adversarial loss: 0.021941\n",
      "epoch 383; iter: 20; batch classifier loss: 0.035265; batch adversarial loss: 0.023264\n",
      "epoch 383; iter: 30; batch classifier loss: 0.038230; batch adversarial loss: 0.024158\n",
      "epoch 383; iter: 40; batch classifier loss: 0.037897; batch adversarial loss: 0.021207\n",
      "epoch 383; iter: 50; batch classifier loss: 0.035760; batch adversarial loss: 0.021355\n",
      "[384/500] Running epoch\n",
      "epoch 384; iter: 0; batch classifier loss: 0.039135; batch adversarial loss: 0.022965\n",
      "epoch 384; iter: 10; batch classifier loss: 0.035617; batch adversarial loss: 0.020973\n",
      "epoch 384; iter: 20; batch classifier loss: 0.039277; batch adversarial loss: 0.024586\n",
      "epoch 384; iter: 30; batch classifier loss: 0.037935; batch adversarial loss: 0.028704\n",
      "epoch 384; iter: 40; batch classifier loss: 0.038205; batch adversarial loss: 0.021273\n",
      "epoch 384; iter: 50; batch classifier loss: 0.037442; batch adversarial loss: 0.022035\n",
      "[385/500] Running epoch\n",
      "epoch 385; iter: 0; batch classifier loss: 0.037741; batch adversarial loss: 0.024376\n",
      "epoch 385; iter: 10; batch classifier loss: 0.038463; batch adversarial loss: 0.026706\n",
      "epoch 385; iter: 20; batch classifier loss: 0.037855; batch adversarial loss: 0.024514\n",
      "epoch 385; iter: 30; batch classifier loss: 0.038099; batch adversarial loss: 0.020939\n",
      "epoch 385; iter: 40; batch classifier loss: 0.037924; batch adversarial loss: 0.022034\n",
      "epoch 385; iter: 50; batch classifier loss: 0.038820; batch adversarial loss: 0.024077\n",
      "[386/500] Running epoch\n",
      "epoch 386; iter: 0; batch classifier loss: 0.036239; batch adversarial loss: 0.021183\n",
      "epoch 386; iter: 10; batch classifier loss: 0.037193; batch adversarial loss: 0.024527\n",
      "epoch 386; iter: 20; batch classifier loss: 0.040111; batch adversarial loss: 0.028551\n",
      "epoch 386; iter: 30; batch classifier loss: 0.038502; batch adversarial loss: 0.021314\n",
      "epoch 386; iter: 40; batch classifier loss: 0.038380; batch adversarial loss: 0.021617\n",
      "epoch 386; iter: 50; batch classifier loss: 0.038828; batch adversarial loss: 0.022336\n",
      "[387/500] Running epoch\n",
      "epoch 387; iter: 0; batch classifier loss: 0.038023; batch adversarial loss: 0.025247\n",
      "epoch 387; iter: 10; batch classifier loss: 0.039253; batch adversarial loss: 0.023713\n",
      "epoch 387; iter: 20; batch classifier loss: 0.040599; batch adversarial loss: 0.026666\n",
      "epoch 387; iter: 30; batch classifier loss: 0.039457; batch adversarial loss: 0.017835\n",
      "epoch 387; iter: 40; batch classifier loss: 0.037806; batch adversarial loss: 0.022353\n",
      "epoch 387; iter: 50; batch classifier loss: 0.037945; batch adversarial loss: 0.023595\n",
      "[388/500] Running epoch\n",
      "epoch 388; iter: 0; batch classifier loss: 0.037956; batch adversarial loss: 0.024191\n",
      "epoch 388; iter: 10; batch classifier loss: 0.036918; batch adversarial loss: 0.021257\n",
      "epoch 388; iter: 20; batch classifier loss: 0.038105; batch adversarial loss: 0.022567\n",
      "epoch 388; iter: 30; batch classifier loss: 0.037298; batch adversarial loss: 0.022915\n",
      "epoch 388; iter: 40; batch classifier loss: 0.039492; batch adversarial loss: 0.025645\n",
      "epoch 388; iter: 50; batch classifier loss: 0.037169; batch adversarial loss: 0.020589\n",
      "[389/500] Running epoch\n",
      "epoch 389; iter: 0; batch classifier loss: 0.038170; batch adversarial loss: 0.022693\n",
      "epoch 389; iter: 10; batch classifier loss: 0.039942; batch adversarial loss: 0.025295\n",
      "epoch 389; iter: 20; batch classifier loss: 0.038573; batch adversarial loss: 0.024464\n",
      "epoch 389; iter: 30; batch classifier loss: 0.037968; batch adversarial loss: 0.025037\n",
      "epoch 389; iter: 40; batch classifier loss: 0.036399; batch adversarial loss: 0.024241\n",
      "epoch 389; iter: 50; batch classifier loss: 0.035887; batch adversarial loss: 0.022598\n",
      "[390/500] Running epoch\n",
      "epoch 390; iter: 0; batch classifier loss: 0.035706; batch adversarial loss: 0.021467\n",
      "epoch 390; iter: 10; batch classifier loss: 0.038388; batch adversarial loss: 0.024615\n",
      "epoch 390; iter: 20; batch classifier loss: 0.037837; batch adversarial loss: 0.020051\n",
      "epoch 390; iter: 30; batch classifier loss: 0.039272; batch adversarial loss: 0.023742\n",
      "epoch 390; iter: 40; batch classifier loss: 0.038426; batch adversarial loss: 0.024972\n",
      "epoch 390; iter: 50; batch classifier loss: 0.036917; batch adversarial loss: 0.022728\n",
      "||w||: 1.2978538274765015\n",
      "||w2||: 0.5965330600738525\n",
      "w.T g: [[0.30422113]]\n",
      "[391/500] Running epoch\n",
      "epoch 391; iter: 0; batch classifier loss: 0.037970; batch adversarial loss: 0.029359\n",
      "epoch 391; iter: 10; batch classifier loss: 0.036242; batch adversarial loss: 0.018919\n",
      "epoch 391; iter: 20; batch classifier loss: 0.035805; batch adversarial loss: 0.023690\n",
      "epoch 391; iter: 30; batch classifier loss: 0.040561; batch adversarial loss: 0.023290\n",
      "epoch 391; iter: 40; batch classifier loss: 0.038266; batch adversarial loss: 0.022351\n",
      "epoch 391; iter: 50; batch classifier loss: 0.036432; batch adversarial loss: 0.021886\n",
      "[392/500] Running epoch\n",
      "epoch 392; iter: 0; batch classifier loss: 0.036403; batch adversarial loss: 0.024148\n",
      "epoch 392; iter: 10; batch classifier loss: 0.037723; batch adversarial loss: 0.020407\n",
      "epoch 392; iter: 20; batch classifier loss: 0.035008; batch adversarial loss: 0.019886\n",
      "epoch 392; iter: 30; batch classifier loss: 0.037950; batch adversarial loss: 0.023796\n",
      "epoch 392; iter: 40; batch classifier loss: 0.035405; batch adversarial loss: 0.023792\n",
      "epoch 392; iter: 50; batch classifier loss: 0.036403; batch adversarial loss: 0.022843\n",
      "[393/500] Running epoch\n",
      "epoch 393; iter: 0; batch classifier loss: 0.036875; batch adversarial loss: 0.022924\n",
      "epoch 393; iter: 10; batch classifier loss: 0.037969; batch adversarial loss: 0.023138\n",
      "epoch 393; iter: 20; batch classifier loss: 0.037899; batch adversarial loss: 0.018409\n",
      "epoch 393; iter: 30; batch classifier loss: 0.037328; batch adversarial loss: 0.021193\n",
      "epoch 393; iter: 40; batch classifier loss: 0.038947; batch adversarial loss: 0.023463\n",
      "epoch 393; iter: 50; batch classifier loss: 0.038786; batch adversarial loss: 0.022524\n",
      "[394/500] Running epoch\n",
      "epoch 394; iter: 0; batch classifier loss: 0.036943; batch adversarial loss: 0.020856\n",
      "epoch 394; iter: 10; batch classifier loss: 0.037733; batch adversarial loss: 0.023101\n",
      "epoch 394; iter: 20; batch classifier loss: 0.038554; batch adversarial loss: 0.026101\n",
      "epoch 394; iter: 30; batch classifier loss: 0.038780; batch adversarial loss: 0.028128\n",
      "epoch 394; iter: 40; batch classifier loss: 0.038215; batch adversarial loss: 0.023058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 394; iter: 50; batch classifier loss: 0.039234; batch adversarial loss: 0.026084\n",
      "[395/500] Running epoch\n",
      "epoch 395; iter: 0; batch classifier loss: 0.036603; batch adversarial loss: 0.021887\n",
      "epoch 395; iter: 10; batch classifier loss: 0.037369; batch adversarial loss: 0.024233\n",
      "epoch 395; iter: 20; batch classifier loss: 0.037252; batch adversarial loss: 0.022643\n",
      "epoch 395; iter: 30; batch classifier loss: 0.037400; batch adversarial loss: 0.021027\n",
      "epoch 395; iter: 40; batch classifier loss: 0.037711; batch adversarial loss: 0.023787\n",
      "epoch 395; iter: 50; batch classifier loss: 0.037864; batch adversarial loss: 0.024773\n",
      "[396/500] Running epoch\n",
      "epoch 396; iter: 0; batch classifier loss: 0.037633; batch adversarial loss: 0.022376\n",
      "epoch 396; iter: 10; batch classifier loss: 0.038829; batch adversarial loss: 0.019913\n",
      "epoch 396; iter: 20; batch classifier loss: 0.036095; batch adversarial loss: 0.020559\n",
      "epoch 396; iter: 30; batch classifier loss: 0.040570; batch adversarial loss: 0.027415\n",
      "epoch 396; iter: 40; batch classifier loss: 0.037114; batch adversarial loss: 0.023952\n",
      "epoch 396; iter: 50; batch classifier loss: 0.037266; batch adversarial loss: 0.023447\n",
      "[397/500] Running epoch\n",
      "epoch 397; iter: 0; batch classifier loss: 0.037169; batch adversarial loss: 0.024022\n",
      "epoch 397; iter: 10; batch classifier loss: 0.035620; batch adversarial loss: 0.021890\n",
      "epoch 397; iter: 20; batch classifier loss: 0.038124; batch adversarial loss: 0.025583\n",
      "epoch 397; iter: 30; batch classifier loss: 0.037334; batch adversarial loss: 0.024464\n",
      "epoch 397; iter: 40; batch classifier loss: 0.038199; batch adversarial loss: 0.022340\n",
      "epoch 397; iter: 50; batch classifier loss: 0.037961; batch adversarial loss: 0.023919\n",
      "[398/500] Running epoch\n",
      "epoch 398; iter: 0; batch classifier loss: 0.036947; batch adversarial loss: 0.021690\n",
      "epoch 398; iter: 10; batch classifier loss: 0.037326; batch adversarial loss: 0.025205\n",
      "epoch 398; iter: 20; batch classifier loss: 0.037404; batch adversarial loss: 0.025816\n",
      "epoch 398; iter: 30; batch classifier loss: 0.034226; batch adversarial loss: 0.023169\n",
      "epoch 398; iter: 40; batch classifier loss: 0.039444; batch adversarial loss: 0.027089\n",
      "epoch 398; iter: 50; batch classifier loss: 0.039468; batch adversarial loss: 0.022032\n",
      "[399/500] Running epoch\n",
      "epoch 399; iter: 0; batch classifier loss: 0.036680; batch adversarial loss: 0.025867\n",
      "epoch 399; iter: 10; batch classifier loss: 0.036906; batch adversarial loss: 0.023126\n",
      "epoch 399; iter: 20; batch classifier loss: 0.036583; batch adversarial loss: 0.024624\n",
      "epoch 399; iter: 30; batch classifier loss: 0.038891; batch adversarial loss: 0.020754\n",
      "epoch 399; iter: 40; batch classifier loss: 0.038291; batch adversarial loss: 0.024002\n",
      "epoch 399; iter: 50; batch classifier loss: 0.035761; batch adversarial loss: 0.019794\n",
      "[400/500] Running epoch\n",
      "epoch 400; iter: 0; batch classifier loss: 0.037734; batch adversarial loss: 0.023178\n",
      "epoch 400; iter: 10; batch classifier loss: 0.037712; batch adversarial loss: 0.025743\n",
      "epoch 400; iter: 20; batch classifier loss: 0.038918; batch adversarial loss: 0.023025\n",
      "epoch 400; iter: 30; batch classifier loss: 0.038500; batch adversarial loss: 0.027023\n",
      "epoch 400; iter: 40; batch classifier loss: 0.037886; batch adversarial loss: 0.023267\n",
      "epoch 400; iter: 50; batch classifier loss: 0.037169; batch adversarial loss: 0.021659\n",
      "||w||: 1.297853708267212\n",
      "||w2||: 0.5965330004692078\n",
      "w.T g: [[0.30422188]]\n",
      "[401/500] Running epoch\n",
      "epoch 401; iter: 0; batch classifier loss: 0.033601; batch adversarial loss: 0.019302\n",
      "epoch 401; iter: 10; batch classifier loss: 0.037444; batch adversarial loss: 0.020502\n",
      "epoch 401; iter: 20; batch classifier loss: 0.036852; batch adversarial loss: 0.026329\n",
      "epoch 401; iter: 30; batch classifier loss: 0.037587; batch adversarial loss: 0.025711\n",
      "epoch 401; iter: 40; batch classifier loss: 0.037469; batch adversarial loss: 0.018802\n",
      "epoch 401; iter: 50; batch classifier loss: 0.037299; batch adversarial loss: 0.022340\n",
      "[402/500] Running epoch\n",
      "epoch 402; iter: 0; batch classifier loss: 0.038765; batch adversarial loss: 0.018474\n",
      "epoch 402; iter: 10; batch classifier loss: 0.038959; batch adversarial loss: 0.031379\n",
      "epoch 402; iter: 20; batch classifier loss: 0.037599; batch adversarial loss: 0.022320\n",
      "epoch 402; iter: 30; batch classifier loss: 0.037633; batch adversarial loss: 0.020191\n",
      "epoch 402; iter: 40; batch classifier loss: 0.038816; batch adversarial loss: 0.023634\n",
      "epoch 402; iter: 50; batch classifier loss: 0.038385; batch adversarial loss: 0.024314\n",
      "[403/500] Running epoch\n",
      "epoch 403; iter: 0; batch classifier loss: 0.036807; batch adversarial loss: 0.021325\n",
      "epoch 403; iter: 10; batch classifier loss: 0.037683; batch adversarial loss: 0.028214\n",
      "epoch 403; iter: 20; batch classifier loss: 0.038264; batch adversarial loss: 0.022160\n",
      "epoch 403; iter: 30; batch classifier loss: 0.038019; batch adversarial loss: 0.021425\n",
      "epoch 403; iter: 40; batch classifier loss: 0.038186; batch adversarial loss: 0.025867\n",
      "epoch 403; iter: 50; batch classifier loss: 0.038218; batch adversarial loss: 0.024122\n",
      "[404/500] Running epoch\n",
      "epoch 404; iter: 0; batch classifier loss: 0.037055; batch adversarial loss: 0.020849\n",
      "epoch 404; iter: 10; batch classifier loss: 0.036605; batch adversarial loss: 0.025022\n",
      "epoch 404; iter: 20; batch classifier loss: 0.035674; batch adversarial loss: 0.021550\n",
      "epoch 404; iter: 30; batch classifier loss: 0.039323; batch adversarial loss: 0.025879\n",
      "epoch 404; iter: 40; batch classifier loss: 0.037548; batch adversarial loss: 0.023542\n",
      "epoch 404; iter: 50; batch classifier loss: 0.037447; batch adversarial loss: 0.021400\n",
      "[405/500] Running epoch\n",
      "epoch 405; iter: 0; batch classifier loss: 0.037262; batch adversarial loss: 0.027421\n",
      "epoch 405; iter: 10; batch classifier loss: 0.037316; batch adversarial loss: 0.026259\n",
      "epoch 405; iter: 20; batch classifier loss: 0.035679; batch adversarial loss: 0.025968\n",
      "epoch 405; iter: 30; batch classifier loss: 0.037676; batch adversarial loss: 0.021981\n",
      "epoch 405; iter: 40; batch classifier loss: 0.038683; batch adversarial loss: 0.019297\n",
      "epoch 405; iter: 50; batch classifier loss: 0.038586; batch adversarial loss: 0.024163\n",
      "[406/500] Running epoch\n",
      "epoch 406; iter: 0; batch classifier loss: 0.038462; batch adversarial loss: 0.023701\n",
      "epoch 406; iter: 10; batch classifier loss: 0.038071; batch adversarial loss: 0.020419\n",
      "epoch 406; iter: 20; batch classifier loss: 0.038274; batch adversarial loss: 0.024890\n",
      "epoch 406; iter: 30; batch classifier loss: 0.039320; batch adversarial loss: 0.023442\n",
      "epoch 406; iter: 40; batch classifier loss: 0.037188; batch adversarial loss: 0.022244\n",
      "epoch 406; iter: 50; batch classifier loss: 0.039628; batch adversarial loss: 0.022930\n",
      "[407/500] Running epoch\n",
      "epoch 407; iter: 0; batch classifier loss: 0.037979; batch adversarial loss: 0.023754\n",
      "epoch 407; iter: 10; batch classifier loss: 0.038036; batch adversarial loss: 0.024130\n",
      "epoch 407; iter: 20; batch classifier loss: 0.036345; batch adversarial loss: 0.024953\n",
      "epoch 407; iter: 30; batch classifier loss: 0.037442; batch adversarial loss: 0.024904\n",
      "epoch 407; iter: 40; batch classifier loss: 0.037433; batch adversarial loss: 0.025288\n",
      "epoch 407; iter: 50; batch classifier loss: 0.036880; batch adversarial loss: 0.023285\n",
      "[408/500] Running epoch\n",
      "epoch 408; iter: 0; batch classifier loss: 0.038800; batch adversarial loss: 0.023598\n",
      "epoch 408; iter: 10; batch classifier loss: 0.039583; batch adversarial loss: 0.024563\n",
      "epoch 408; iter: 20; batch classifier loss: 0.035494; batch adversarial loss: 0.022366\n",
      "epoch 408; iter: 30; batch classifier loss: 0.038279; batch adversarial loss: 0.024646\n",
      "epoch 408; iter: 40; batch classifier loss: 0.037363; batch adversarial loss: 0.021313\n",
      "epoch 408; iter: 50; batch classifier loss: 0.037739; batch adversarial loss: 0.020379\n",
      "[409/500] Running epoch\n",
      "epoch 409; iter: 0; batch classifier loss: 0.037492; batch adversarial loss: 0.026467\n",
      "epoch 409; iter: 10; batch classifier loss: 0.038476; batch adversarial loss: 0.026131\n",
      "epoch 409; iter: 20; batch classifier loss: 0.037450; batch adversarial loss: 0.026944\n",
      "epoch 409; iter: 30; batch classifier loss: 0.037369; batch adversarial loss: 0.025740\n",
      "epoch 409; iter: 40; batch classifier loss: 0.037345; batch adversarial loss: 0.023622\n",
      "epoch 409; iter: 50; batch classifier loss: 0.036272; batch adversarial loss: 0.022967\n",
      "[410/500] Running epoch\n",
      "epoch 410; iter: 0; batch classifier loss: 0.036660; batch adversarial loss: 0.022777\n",
      "epoch 410; iter: 10; batch classifier loss: 0.037545; batch adversarial loss: 0.024959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 410; iter: 20; batch classifier loss: 0.037939; batch adversarial loss: 0.022155\n",
      "epoch 410; iter: 30; batch classifier loss: 0.036564; batch adversarial loss: 0.022617\n",
      "epoch 410; iter: 40; batch classifier loss: 0.037795; batch adversarial loss: 0.024967\n",
      "epoch 410; iter: 50; batch classifier loss: 0.035199; batch adversarial loss: 0.026612\n",
      "||w||: 1.2978535890579224\n",
      "||w2||: 0.596532940864563\n",
      "w.T g: [[0.30422235]]\n",
      "[411/500] Running epoch\n",
      "epoch 411; iter: 0; batch classifier loss: 0.038402; batch adversarial loss: 0.026268\n",
      "epoch 411; iter: 10; batch classifier loss: 0.036268; batch adversarial loss: 0.022312\n",
      "epoch 411; iter: 20; batch classifier loss: 0.038277; batch adversarial loss: 0.024930\n",
      "epoch 411; iter: 30; batch classifier loss: 0.038080; batch adversarial loss: 0.024765\n",
      "epoch 411; iter: 40; batch classifier loss: 0.038830; batch adversarial loss: 0.022027\n",
      "epoch 411; iter: 50; batch classifier loss: 0.036518; batch adversarial loss: 0.023941\n",
      "[412/500] Running epoch\n",
      "epoch 412; iter: 0; batch classifier loss: 0.039619; batch adversarial loss: 0.022594\n",
      "epoch 412; iter: 10; batch classifier loss: 0.038194; batch adversarial loss: 0.023112\n",
      "epoch 412; iter: 20; batch classifier loss: 0.036659; batch adversarial loss: 0.026669\n",
      "epoch 412; iter: 30; batch classifier loss: 0.036104; batch adversarial loss: 0.020404\n",
      "epoch 412; iter: 40; batch classifier loss: 0.037842; batch adversarial loss: 0.022014\n",
      "epoch 412; iter: 50; batch classifier loss: 0.036831; batch adversarial loss: 0.019428\n",
      "[413/500] Running epoch\n",
      "epoch 413; iter: 0; batch classifier loss: 0.040565; batch adversarial loss: 0.028702\n",
      "epoch 413; iter: 10; batch classifier loss: 0.037069; batch adversarial loss: 0.022410\n",
      "epoch 413; iter: 20; batch classifier loss: 0.037384; batch adversarial loss: 0.019925\n",
      "epoch 413; iter: 30; batch classifier loss: 0.038295; batch adversarial loss: 0.022174\n",
      "epoch 413; iter: 40; batch classifier loss: 0.036844; batch adversarial loss: 0.024707\n",
      "epoch 413; iter: 50; batch classifier loss: 0.036775; batch adversarial loss: 0.023166\n",
      "[414/500] Running epoch\n",
      "epoch 414; iter: 0; batch classifier loss: 0.038009; batch adversarial loss: 0.026282\n",
      "epoch 414; iter: 10; batch classifier loss: 0.036540; batch adversarial loss: 0.019827\n",
      "epoch 414; iter: 20; batch classifier loss: 0.040254; batch adversarial loss: 0.024990\n",
      "epoch 414; iter: 30; batch classifier loss: 0.038141; batch adversarial loss: 0.022853\n",
      "epoch 414; iter: 40; batch classifier loss: 0.037489; batch adversarial loss: 0.026210\n",
      "epoch 414; iter: 50; batch classifier loss: 0.040378; batch adversarial loss: 0.023836\n",
      "[415/500] Running epoch\n",
      "epoch 415; iter: 0; batch classifier loss: 0.037652; batch adversarial loss: 0.022539\n",
      "epoch 415; iter: 10; batch classifier loss: 0.037454; batch adversarial loss: 0.025605\n",
      "epoch 415; iter: 20; batch classifier loss: 0.038760; batch adversarial loss: 0.023499\n",
      "epoch 415; iter: 30; batch classifier loss: 0.035829; batch adversarial loss: 0.024585\n",
      "epoch 415; iter: 40; batch classifier loss: 0.037170; batch adversarial loss: 0.021422\n",
      "epoch 415; iter: 50; batch classifier loss: 0.038448; batch adversarial loss: 0.023185\n",
      "[416/500] Running epoch\n",
      "epoch 416; iter: 0; batch classifier loss: 0.035284; batch adversarial loss: 0.021679\n",
      "epoch 416; iter: 10; batch classifier loss: 0.038811; batch adversarial loss: 0.019536\n",
      "epoch 416; iter: 20; batch classifier loss: 0.036883; batch adversarial loss: 0.022649\n",
      "epoch 416; iter: 30; batch classifier loss: 0.036759; batch adversarial loss: 0.021728\n",
      "epoch 416; iter: 40; batch classifier loss: 0.038890; batch adversarial loss: 0.024415\n",
      "epoch 416; iter: 50; batch classifier loss: 0.037186; batch adversarial loss: 0.021593\n",
      "[417/500] Running epoch\n",
      "epoch 417; iter: 0; batch classifier loss: 0.036335; batch adversarial loss: 0.023847\n",
      "epoch 417; iter: 10; batch classifier loss: 0.038840; batch adversarial loss: 0.028217\n",
      "epoch 417; iter: 20; batch classifier loss: 0.039695; batch adversarial loss: 0.027934\n",
      "epoch 417; iter: 30; batch classifier loss: 0.037187; batch adversarial loss: 0.017459\n",
      "epoch 417; iter: 40; batch classifier loss: 0.036016; batch adversarial loss: 0.025715\n",
      "epoch 417; iter: 50; batch classifier loss: 0.037481; batch adversarial loss: 0.026426\n",
      "[418/500] Running epoch\n",
      "epoch 418; iter: 0; batch classifier loss: 0.038688; batch adversarial loss: 0.026218\n",
      "epoch 418; iter: 10; batch classifier loss: 0.035762; batch adversarial loss: 0.022851\n",
      "epoch 418; iter: 20; batch classifier loss: 0.038543; batch adversarial loss: 0.020491\n",
      "epoch 418; iter: 30; batch classifier loss: 0.038571; batch adversarial loss: 0.024881\n",
      "epoch 418; iter: 40; batch classifier loss: 0.035801; batch adversarial loss: 0.022916\n",
      "epoch 418; iter: 50; batch classifier loss: 0.038624; batch adversarial loss: 0.025210\n",
      "[419/500] Running epoch\n",
      "epoch 419; iter: 0; batch classifier loss: 0.037675; batch adversarial loss: 0.025429\n",
      "epoch 419; iter: 10; batch classifier loss: 0.038936; batch adversarial loss: 0.020561\n",
      "epoch 419; iter: 20; batch classifier loss: 0.036350; batch adversarial loss: 0.022014\n",
      "epoch 419; iter: 30; batch classifier loss: 0.038784; batch adversarial loss: 0.023824\n",
      "epoch 419; iter: 40; batch classifier loss: 0.037844; batch adversarial loss: 0.022849\n",
      "epoch 419; iter: 50; batch classifier loss: 0.036254; batch adversarial loss: 0.017486\n",
      "[420/500] Running epoch\n",
      "epoch 420; iter: 0; batch classifier loss: 0.037999; batch adversarial loss: 0.023604\n",
      "epoch 420; iter: 10; batch classifier loss: 0.036780; batch adversarial loss: 0.018801\n",
      "epoch 420; iter: 20; batch classifier loss: 0.038167; batch adversarial loss: 0.023174\n",
      "epoch 420; iter: 30; batch classifier loss: 0.038259; batch adversarial loss: 0.026276\n",
      "epoch 420; iter: 40; batch classifier loss: 0.037861; batch adversarial loss: 0.025480\n",
      "epoch 420; iter: 50; batch classifier loss: 0.038449; batch adversarial loss: 0.021739\n",
      "||w||: 1.2978535890579224\n",
      "||w2||: 0.5965328812599182\n",
      "w.T g: [[0.30422233]]\n",
      "[421/500] Running epoch\n",
      "epoch 421; iter: 0; batch classifier loss: 0.036396; batch adversarial loss: 0.021905\n",
      "epoch 421; iter: 10; batch classifier loss: 0.038202; batch adversarial loss: 0.023237\n",
      "epoch 421; iter: 20; batch classifier loss: 0.037212; batch adversarial loss: 0.022907\n",
      "epoch 421; iter: 30; batch classifier loss: 0.039402; batch adversarial loss: 0.022638\n",
      "epoch 421; iter: 40; batch classifier loss: 0.036069; batch adversarial loss: 0.024922\n",
      "epoch 421; iter: 50; batch classifier loss: 0.035564; batch adversarial loss: 0.021528\n",
      "[422/500] Running epoch\n",
      "epoch 422; iter: 0; batch classifier loss: 0.039282; batch adversarial loss: 0.026744\n",
      "epoch 422; iter: 10; batch classifier loss: 0.037057; batch adversarial loss: 0.019158\n",
      "epoch 422; iter: 20; batch classifier loss: 0.037816; batch adversarial loss: 0.023532\n",
      "epoch 422; iter: 30; batch classifier loss: 0.037063; batch adversarial loss: 0.026555\n",
      "epoch 422; iter: 40; batch classifier loss: 0.036982; batch adversarial loss: 0.018828\n",
      "epoch 422; iter: 50; batch classifier loss: 0.035778; batch adversarial loss: 0.022502\n",
      "[423/500] Running epoch\n",
      "epoch 423; iter: 0; batch classifier loss: 0.035279; batch adversarial loss: 0.024679\n",
      "epoch 423; iter: 10; batch classifier loss: 0.039735; batch adversarial loss: 0.026343\n",
      "epoch 423; iter: 20; batch classifier loss: 0.037005; batch adversarial loss: 0.025511\n",
      "epoch 423; iter: 30; batch classifier loss: 0.038104; batch adversarial loss: 0.024748\n",
      "epoch 423; iter: 40; batch classifier loss: 0.036801; batch adversarial loss: 0.022615\n",
      "epoch 423; iter: 50; batch classifier loss: 0.036355; batch adversarial loss: 0.022511\n",
      "[424/500] Running epoch\n",
      "epoch 424; iter: 0; batch classifier loss: 0.036054; batch adversarial loss: 0.021275\n",
      "epoch 424; iter: 10; batch classifier loss: 0.038154; batch adversarial loss: 0.023372\n",
      "epoch 424; iter: 20; batch classifier loss: 0.039512; batch adversarial loss: 0.024644\n",
      "epoch 424; iter: 30; batch classifier loss: 0.036037; batch adversarial loss: 0.020281\n",
      "epoch 424; iter: 40; batch classifier loss: 0.037655; batch adversarial loss: 0.024864\n",
      "epoch 424; iter: 50; batch classifier loss: 0.037678; batch adversarial loss: 0.021446\n",
      "[425/500] Running epoch\n",
      "epoch 425; iter: 0; batch classifier loss: 0.036871; batch adversarial loss: 0.024622\n",
      "epoch 425; iter: 10; batch classifier loss: 0.040975; batch adversarial loss: 0.026883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 425; iter: 20; batch classifier loss: 0.038568; batch adversarial loss: 0.026110\n",
      "epoch 425; iter: 30; batch classifier loss: 0.037874; batch adversarial loss: 0.022140\n",
      "epoch 425; iter: 40; batch classifier loss: 0.038017; batch adversarial loss: 0.026420\n",
      "epoch 425; iter: 50; batch classifier loss: 0.037659; batch adversarial loss: 0.024347\n",
      "[426/500] Running epoch\n",
      "epoch 426; iter: 0; batch classifier loss: 0.036841; batch adversarial loss: 0.023020\n",
      "epoch 426; iter: 10; batch classifier loss: 0.036660; batch adversarial loss: 0.024381\n",
      "epoch 426; iter: 20; batch classifier loss: 0.038064; batch adversarial loss: 0.025227\n",
      "epoch 426; iter: 30; batch classifier loss: 0.035793; batch adversarial loss: 0.022195\n",
      "epoch 426; iter: 40; batch classifier loss: 0.038122; batch adversarial loss: 0.025595\n",
      "epoch 426; iter: 50; batch classifier loss: 0.036148; batch adversarial loss: 0.019879\n",
      "[427/500] Running epoch\n",
      "epoch 427; iter: 0; batch classifier loss: 0.037354; batch adversarial loss: 0.024081\n",
      "epoch 427; iter: 10; batch classifier loss: 0.036196; batch adversarial loss: 0.021103\n",
      "epoch 427; iter: 20; batch classifier loss: 0.037890; batch adversarial loss: 0.025974\n",
      "epoch 427; iter: 30; batch classifier loss: 0.036403; batch adversarial loss: 0.019624\n",
      "epoch 427; iter: 40; batch classifier loss: 0.039084; batch adversarial loss: 0.026813\n",
      "epoch 427; iter: 50; batch classifier loss: 0.037309; batch adversarial loss: 0.024081\n",
      "[428/500] Running epoch\n",
      "epoch 428; iter: 0; batch classifier loss: 0.038194; batch adversarial loss: 0.026499\n",
      "epoch 428; iter: 10; batch classifier loss: 0.038200; batch adversarial loss: 0.024091\n",
      "epoch 428; iter: 20; batch classifier loss: 0.036989; batch adversarial loss: 0.021709\n",
      "epoch 428; iter: 30; batch classifier loss: 0.040419; batch adversarial loss: 0.031694\n",
      "epoch 428; iter: 40; batch classifier loss: 0.037432; batch adversarial loss: 0.027025\n",
      "epoch 428; iter: 50; batch classifier loss: 0.036374; batch adversarial loss: 0.020019\n",
      "[429/500] Running epoch\n",
      "epoch 429; iter: 0; batch classifier loss: 0.037748; batch adversarial loss: 0.027643\n",
      "epoch 429; iter: 10; batch classifier loss: 0.038000; batch adversarial loss: 0.020285\n",
      "epoch 429; iter: 20; batch classifier loss: 0.036582; batch adversarial loss: 0.020411\n",
      "epoch 429; iter: 30; batch classifier loss: 0.039850; batch adversarial loss: 0.027698\n",
      "epoch 429; iter: 40; batch classifier loss: 0.037392; batch adversarial loss: 0.020743\n",
      "epoch 429; iter: 50; batch classifier loss: 0.034759; batch adversarial loss: 0.020131\n",
      "[430/500] Running epoch\n",
      "epoch 430; iter: 0; batch classifier loss: 0.036422; batch adversarial loss: 0.023722\n",
      "epoch 430; iter: 10; batch classifier loss: 0.037961; batch adversarial loss: 0.025388\n",
      "epoch 430; iter: 20; batch classifier loss: 0.038638; batch adversarial loss: 0.022616\n",
      "epoch 430; iter: 30; batch classifier loss: 0.036524; batch adversarial loss: 0.020284\n",
      "epoch 430; iter: 40; batch classifier loss: 0.037682; batch adversarial loss: 0.022734\n",
      "epoch 430; iter: 50; batch classifier loss: 0.036207; batch adversarial loss: 0.019397\n",
      "||w||: 1.2978535890579224\n",
      "||w2||: 0.5965328812599182\n",
      "w.T g: [[0.30422235]]\n",
      "[431/500] Running epoch\n",
      "epoch 431; iter: 0; batch classifier loss: 0.036036; batch adversarial loss: 0.024038\n",
      "epoch 431; iter: 10; batch classifier loss: 0.038289; batch adversarial loss: 0.022257\n",
      "epoch 431; iter: 20; batch classifier loss: 0.036607; batch adversarial loss: 0.020528\n",
      "epoch 431; iter: 30; batch classifier loss: 0.038760; batch adversarial loss: 0.026920\n",
      "epoch 431; iter: 40; batch classifier loss: 0.038841; batch adversarial loss: 0.020498\n",
      "epoch 431; iter: 50; batch classifier loss: 0.037851; batch adversarial loss: 0.023840\n",
      "[432/500] Running epoch\n",
      "epoch 432; iter: 0; batch classifier loss: 0.038955; batch adversarial loss: 0.026239\n",
      "epoch 432; iter: 10; batch classifier loss: 0.037517; batch adversarial loss: 0.027265\n",
      "epoch 432; iter: 20; batch classifier loss: 0.036420; batch adversarial loss: 0.020263\n",
      "epoch 432; iter: 30; batch classifier loss: 0.035817; batch adversarial loss: 0.019338\n",
      "epoch 432; iter: 40; batch classifier loss: 0.036288; batch adversarial loss: 0.023273\n",
      "epoch 432; iter: 50; batch classifier loss: 0.038833; batch adversarial loss: 0.022133\n",
      "[433/500] Running epoch\n",
      "epoch 433; iter: 0; batch classifier loss: 0.038664; batch adversarial loss: 0.018783\n",
      "epoch 433; iter: 10; batch classifier loss: 0.036435; batch adversarial loss: 0.021582\n",
      "epoch 433; iter: 20; batch classifier loss: 0.034641; batch adversarial loss: 0.019479\n",
      "epoch 433; iter: 30; batch classifier loss: 0.038618; batch adversarial loss: 0.026344\n",
      "epoch 433; iter: 40; batch classifier loss: 0.037408; batch adversarial loss: 0.024439\n",
      "epoch 433; iter: 50; batch classifier loss: 0.034350; batch adversarial loss: 0.023264\n",
      "[434/500] Running epoch\n",
      "epoch 434; iter: 0; batch classifier loss: 0.036558; batch adversarial loss: 0.019278\n",
      "epoch 434; iter: 10; batch classifier loss: 0.038911; batch adversarial loss: 0.019105\n",
      "epoch 434; iter: 20; batch classifier loss: 0.037046; batch adversarial loss: 0.022601\n",
      "epoch 434; iter: 30; batch classifier loss: 0.036205; batch adversarial loss: 0.020067\n",
      "epoch 434; iter: 40; batch classifier loss: 0.036995; batch adversarial loss: 0.026888\n",
      "epoch 434; iter: 50; batch classifier loss: 0.037575; batch adversarial loss: 0.024868\n",
      "[435/500] Running epoch\n",
      "epoch 435; iter: 0; batch classifier loss: 0.037180; batch adversarial loss: 0.022336\n",
      "epoch 435; iter: 10; batch classifier loss: 0.037467; batch adversarial loss: 0.024001\n",
      "epoch 435; iter: 20; batch classifier loss: 0.037385; batch adversarial loss: 0.029001\n",
      "epoch 435; iter: 30; batch classifier loss: 0.036590; batch adversarial loss: 0.025810\n",
      "epoch 435; iter: 40; batch classifier loss: 0.038974; batch adversarial loss: 0.023424\n",
      "epoch 435; iter: 50; batch classifier loss: 0.037716; batch adversarial loss: 0.024891\n",
      "[436/500] Running epoch\n",
      "epoch 436; iter: 0; batch classifier loss: 0.038907; batch adversarial loss: 0.026701\n",
      "epoch 436; iter: 10; batch classifier loss: 0.039950; batch adversarial loss: 0.028008\n",
      "epoch 436; iter: 20; batch classifier loss: 0.039638; batch adversarial loss: 0.024342\n",
      "epoch 436; iter: 30; batch classifier loss: 0.036622; batch adversarial loss: 0.018886\n",
      "epoch 436; iter: 40; batch classifier loss: 0.037759; batch adversarial loss: 0.023037\n",
      "epoch 436; iter: 50; batch classifier loss: 0.037945; batch adversarial loss: 0.023249\n",
      "[437/500] Running epoch\n",
      "epoch 437; iter: 0; batch classifier loss: 0.037846; batch adversarial loss: 0.021209\n",
      "epoch 437; iter: 10; batch classifier loss: 0.039065; batch adversarial loss: 0.024242\n",
      "epoch 437; iter: 20; batch classifier loss: 0.038065; batch adversarial loss: 0.022758\n",
      "epoch 437; iter: 30; batch classifier loss: 0.039189; batch adversarial loss: 0.023269\n",
      "epoch 437; iter: 40; batch classifier loss: 0.035855; batch adversarial loss: 0.019711\n",
      "epoch 437; iter: 50; batch classifier loss: 0.034989; batch adversarial loss: 0.024232\n",
      "[438/500] Running epoch\n",
      "epoch 438; iter: 0; batch classifier loss: 0.038734; batch adversarial loss: 0.021146\n",
      "epoch 438; iter: 10; batch classifier loss: 0.037095; batch adversarial loss: 0.024180\n",
      "epoch 438; iter: 20; batch classifier loss: 0.037151; batch adversarial loss: 0.021384\n",
      "epoch 438; iter: 30; batch classifier loss: 0.039450; batch adversarial loss: 0.027489\n",
      "epoch 438; iter: 40; batch classifier loss: 0.037952; batch adversarial loss: 0.024300\n",
      "epoch 438; iter: 50; batch classifier loss: 0.036329; batch adversarial loss: 0.020465\n",
      "[439/500] Running epoch\n",
      "epoch 439; iter: 0; batch classifier loss: 0.036359; batch adversarial loss: 0.020903\n",
      "epoch 439; iter: 10; batch classifier loss: 0.038076; batch adversarial loss: 0.021137\n",
      "epoch 439; iter: 20; batch classifier loss: 0.037766; batch adversarial loss: 0.028063\n",
      "epoch 439; iter: 30; batch classifier loss: 0.037206; batch adversarial loss: 0.022806\n",
      "epoch 439; iter: 40; batch classifier loss: 0.037376; batch adversarial loss: 0.024754\n",
      "epoch 439; iter: 50; batch classifier loss: 0.036446; batch adversarial loss: 0.023309\n",
      "[440/500] Running epoch\n",
      "epoch 440; iter: 0; batch classifier loss: 0.038311; batch adversarial loss: 0.022065\n",
      "epoch 440; iter: 10; batch classifier loss: 0.037398; batch adversarial loss: 0.029313\n",
      "epoch 440; iter: 20; batch classifier loss: 0.037278; batch adversarial loss: 0.025478\n",
      "epoch 440; iter: 30; batch classifier loss: 0.037785; batch adversarial loss: 0.020534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 440; iter: 40; batch classifier loss: 0.037192; batch adversarial loss: 0.021010\n",
      "epoch 440; iter: 50; batch classifier loss: 0.037452; batch adversarial loss: 0.022748\n",
      "||w||: 1.2978535890579224\n",
      "||w2||: 0.5965328812599182\n",
      "w.T g: [[0.30422238]]\n",
      "[441/500] Running epoch\n",
      "epoch 441; iter: 0; batch classifier loss: 0.037778; batch adversarial loss: 0.025982\n",
      "epoch 441; iter: 10; batch classifier loss: 0.037931; batch adversarial loss: 0.025827\n",
      "epoch 441; iter: 20; batch classifier loss: 0.037546; batch adversarial loss: 0.023812\n",
      "epoch 441; iter: 30; batch classifier loss: 0.037244; batch adversarial loss: 0.022601\n",
      "epoch 441; iter: 40; batch classifier loss: 0.036675; batch adversarial loss: 0.027448\n",
      "epoch 441; iter: 50; batch classifier loss: 0.038624; batch adversarial loss: 0.021556\n",
      "[442/500] Running epoch\n",
      "epoch 442; iter: 0; batch classifier loss: 0.039040; batch adversarial loss: 0.020798\n",
      "epoch 442; iter: 10; batch classifier loss: 0.036873; batch adversarial loss: 0.023568\n",
      "epoch 442; iter: 20; batch classifier loss: 0.037441; batch adversarial loss: 0.023392\n",
      "epoch 442; iter: 30; batch classifier loss: 0.038721; batch adversarial loss: 0.021054\n",
      "epoch 442; iter: 40; batch classifier loss: 0.037198; batch adversarial loss: 0.021050\n",
      "epoch 442; iter: 50; batch classifier loss: 0.035227; batch adversarial loss: 0.021527\n",
      "[443/500] Running epoch\n",
      "epoch 443; iter: 0; batch classifier loss: 0.037040; batch adversarial loss: 0.030236\n",
      "epoch 443; iter: 10; batch classifier loss: 0.037730; batch adversarial loss: 0.025420\n",
      "epoch 443; iter: 20; batch classifier loss: 0.036457; batch adversarial loss: 0.018123\n",
      "epoch 443; iter: 30; batch classifier loss: 0.038214; batch adversarial loss: 0.024505\n",
      "epoch 443; iter: 40; batch classifier loss: 0.037589; batch adversarial loss: 0.019790\n",
      "epoch 443; iter: 50; batch classifier loss: 0.038118; batch adversarial loss: 0.021278\n",
      "[444/500] Running epoch\n",
      "epoch 444; iter: 0; batch classifier loss: 0.038338; batch adversarial loss: 0.023412\n",
      "epoch 444; iter: 10; batch classifier loss: 0.036204; batch adversarial loss: 0.019246\n",
      "epoch 444; iter: 20; batch classifier loss: 0.038103; batch adversarial loss: 0.026131\n",
      "epoch 444; iter: 30; batch classifier loss: 0.036105; batch adversarial loss: 0.021891\n",
      "epoch 444; iter: 40; batch classifier loss: 0.037938; batch adversarial loss: 0.022458\n",
      "epoch 444; iter: 50; batch classifier loss: 0.036349; batch adversarial loss: 0.022362\n",
      "[445/500] Running epoch\n",
      "epoch 445; iter: 0; batch classifier loss: 0.035390; batch adversarial loss: 0.022570\n",
      "epoch 445; iter: 10; batch classifier loss: 0.037152; batch adversarial loss: 0.022207\n",
      "epoch 445; iter: 20; batch classifier loss: 0.038447; batch adversarial loss: 0.020951\n",
      "epoch 445; iter: 30; batch classifier loss: 0.039057; batch adversarial loss: 0.022074\n",
      "epoch 445; iter: 40; batch classifier loss: 0.036830; batch adversarial loss: 0.019116\n",
      "epoch 445; iter: 50; batch classifier loss: 0.037458; batch adversarial loss: 0.021987\n",
      "[446/500] Running epoch\n",
      "epoch 446; iter: 0; batch classifier loss: 0.038616; batch adversarial loss: 0.022943\n",
      "epoch 446; iter: 10; batch classifier loss: 0.036998; batch adversarial loss: 0.023283\n",
      "epoch 446; iter: 20; batch classifier loss: 0.038069; batch adversarial loss: 0.023175\n",
      "epoch 446; iter: 30; batch classifier loss: 0.037242; batch adversarial loss: 0.024738\n",
      "epoch 446; iter: 40; batch classifier loss: 0.038685; batch adversarial loss: 0.019967\n",
      "epoch 446; iter: 50; batch classifier loss: 0.038220; batch adversarial loss: 0.021419\n",
      "[447/500] Running epoch\n",
      "epoch 447; iter: 0; batch classifier loss: 0.040558; batch adversarial loss: 0.022507\n",
      "epoch 447; iter: 10; batch classifier loss: 0.036968; batch adversarial loss: 0.019110\n",
      "epoch 447; iter: 20; batch classifier loss: 0.039138; batch adversarial loss: 0.020183\n",
      "epoch 447; iter: 30; batch classifier loss: 0.038218; batch adversarial loss: 0.025516\n",
      "epoch 447; iter: 40; batch classifier loss: 0.037044; batch adversarial loss: 0.022546\n",
      "epoch 447; iter: 50; batch classifier loss: 0.038177; batch adversarial loss: 0.025022\n",
      "[448/500] Running epoch\n",
      "epoch 448; iter: 0; batch classifier loss: 0.039534; batch adversarial loss: 0.026829\n",
      "epoch 448; iter: 10; batch classifier loss: 0.037591; batch adversarial loss: 0.023899\n",
      "epoch 448; iter: 20; batch classifier loss: 0.040707; batch adversarial loss: 0.022090\n",
      "epoch 448; iter: 30; batch classifier loss: 0.037635; batch adversarial loss: 0.021104\n",
      "epoch 448; iter: 40; batch classifier loss: 0.035281; batch adversarial loss: 0.024830\n",
      "epoch 448; iter: 50; batch classifier loss: 0.037442; batch adversarial loss: 0.022497\n",
      "[449/500] Running epoch\n",
      "epoch 449; iter: 0; batch classifier loss: 0.036502; batch adversarial loss: 0.022276\n",
      "epoch 449; iter: 10; batch classifier loss: 0.036234; batch adversarial loss: 0.021507\n",
      "epoch 449; iter: 20; batch classifier loss: 0.040712; batch adversarial loss: 0.024128\n",
      "epoch 449; iter: 30; batch classifier loss: 0.039731; batch adversarial loss: 0.026424\n",
      "epoch 449; iter: 40; batch classifier loss: 0.038085; batch adversarial loss: 0.021999\n",
      "epoch 449; iter: 50; batch classifier loss: 0.037533; batch adversarial loss: 0.023445\n",
      "[450/500] Running epoch\n",
      "epoch 450; iter: 0; batch classifier loss: 0.038016; batch adversarial loss: 0.020992\n",
      "epoch 450; iter: 10; batch classifier loss: 0.036516; batch adversarial loss: 0.022854\n",
      "epoch 450; iter: 20; batch classifier loss: 0.037330; batch adversarial loss: 0.023850\n",
      "epoch 450; iter: 30; batch classifier loss: 0.037562; batch adversarial loss: 0.023634\n",
      "epoch 450; iter: 40; batch classifier loss: 0.037851; batch adversarial loss: 0.022958\n",
      "epoch 450; iter: 50; batch classifier loss: 0.037905; batch adversarial loss: 0.025098\n",
      "||w||: 1.2978535890579224\n",
      "||w2||: 0.5965328812599182\n",
      "w.T g: [[0.30422239]]\n",
      "[451/500] Running epoch\n",
      "epoch 451; iter: 0; batch classifier loss: 0.036812; batch adversarial loss: 0.025072\n",
      "epoch 451; iter: 10; batch classifier loss: 0.038307; batch adversarial loss: 0.025821\n",
      "epoch 451; iter: 20; batch classifier loss: 0.037146; batch adversarial loss: 0.025725\n",
      "epoch 451; iter: 30; batch classifier loss: 0.039503; batch adversarial loss: 0.029077\n",
      "epoch 451; iter: 40; batch classifier loss: 0.037804; batch adversarial loss: 0.025318\n",
      "epoch 451; iter: 50; batch classifier loss: 0.036984; batch adversarial loss: 0.023799\n",
      "[452/500] Running epoch\n",
      "epoch 452; iter: 0; batch classifier loss: 0.039240; batch adversarial loss: 0.024854\n",
      "epoch 452; iter: 10; batch classifier loss: 0.037422; batch adversarial loss: 0.020464\n",
      "epoch 452; iter: 20; batch classifier loss: 0.036950; batch adversarial loss: 0.021494\n",
      "epoch 452; iter: 30; batch classifier loss: 0.038889; batch adversarial loss: 0.026297\n",
      "epoch 452; iter: 40; batch classifier loss: 0.037385; batch adversarial loss: 0.023771\n",
      "epoch 452; iter: 50; batch classifier loss: 0.036028; batch adversarial loss: 0.022725\n",
      "[453/500] Running epoch\n",
      "epoch 453; iter: 0; batch classifier loss: 0.040156; batch adversarial loss: 0.022695\n",
      "epoch 453; iter: 10; batch classifier loss: 0.035932; batch adversarial loss: 0.019621\n",
      "epoch 453; iter: 20; batch classifier loss: 0.038227; batch adversarial loss: 0.024771\n",
      "epoch 453; iter: 30; batch classifier loss: 0.036489; batch adversarial loss: 0.024683\n",
      "epoch 453; iter: 40; batch classifier loss: 0.037982; batch adversarial loss: 0.024861\n",
      "epoch 453; iter: 50; batch classifier loss: 0.036672; batch adversarial loss: 0.022577\n",
      "[454/500] Running epoch\n",
      "epoch 454; iter: 0; batch classifier loss: 0.036192; batch adversarial loss: 0.025451\n",
      "epoch 454; iter: 10; batch classifier loss: 0.036883; batch adversarial loss: 0.023727\n",
      "epoch 454; iter: 20; batch classifier loss: 0.038936; batch adversarial loss: 0.023316\n",
      "epoch 454; iter: 30; batch classifier loss: 0.036343; batch adversarial loss: 0.022605\n",
      "epoch 454; iter: 40; batch classifier loss: 0.036693; batch adversarial loss: 0.023303\n",
      "epoch 454; iter: 50; batch classifier loss: 0.037682; batch adversarial loss: 0.024002\n",
      "[455/500] Running epoch\n",
      "epoch 455; iter: 0; batch classifier loss: 0.036536; batch adversarial loss: 0.022766\n",
      "epoch 455; iter: 10; batch classifier loss: 0.036818; batch adversarial loss: 0.023608\n",
      "epoch 455; iter: 20; batch classifier loss: 0.038659; batch adversarial loss: 0.020557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 455; iter: 30; batch classifier loss: 0.037232; batch adversarial loss: 0.026588\n",
      "epoch 455; iter: 40; batch classifier loss: 0.036942; batch adversarial loss: 0.023293\n",
      "epoch 455; iter: 50; batch classifier loss: 0.035075; batch adversarial loss: 0.024382\n",
      "[456/500] Running epoch\n",
      "epoch 456; iter: 0; batch classifier loss: 0.037932; batch adversarial loss: 0.020967\n",
      "epoch 456; iter: 10; batch classifier loss: 0.037076; batch adversarial loss: 0.021163\n",
      "epoch 456; iter: 20; batch classifier loss: 0.037351; batch adversarial loss: 0.023059\n",
      "epoch 456; iter: 30; batch classifier loss: 0.037929; batch adversarial loss: 0.024133\n",
      "epoch 456; iter: 40; batch classifier loss: 0.035176; batch adversarial loss: 0.016018\n",
      "epoch 456; iter: 50; batch classifier loss: 0.038174; batch adversarial loss: 0.023803\n",
      "[457/500] Running epoch\n",
      "epoch 457; iter: 0; batch classifier loss: 0.038803; batch adversarial loss: 0.023348\n",
      "epoch 457; iter: 10; batch classifier loss: 0.036867; batch adversarial loss: 0.022148\n",
      "epoch 457; iter: 20; batch classifier loss: 0.037282; batch adversarial loss: 0.020527\n",
      "epoch 457; iter: 30; batch classifier loss: 0.037875; batch adversarial loss: 0.020728\n",
      "epoch 457; iter: 40; batch classifier loss: 0.038012; batch adversarial loss: 0.026836\n",
      "epoch 457; iter: 50; batch classifier loss: 0.038782; batch adversarial loss: 0.023045\n",
      "[458/500] Running epoch\n",
      "epoch 458; iter: 0; batch classifier loss: 0.039246; batch adversarial loss: 0.022214\n",
      "epoch 458; iter: 10; batch classifier loss: 0.040070; batch adversarial loss: 0.021833\n",
      "epoch 458; iter: 20; batch classifier loss: 0.036028; batch adversarial loss: 0.020927\n",
      "epoch 458; iter: 30; batch classifier loss: 0.039289; batch adversarial loss: 0.020853\n",
      "epoch 458; iter: 40; batch classifier loss: 0.037470; batch adversarial loss: 0.025175\n",
      "epoch 458; iter: 50; batch classifier loss: 0.038664; batch adversarial loss: 0.021762\n",
      "[459/500] Running epoch\n",
      "epoch 459; iter: 0; batch classifier loss: 0.038731; batch adversarial loss: 0.023476\n",
      "epoch 459; iter: 10; batch classifier loss: 0.038135; batch adversarial loss: 0.024323\n",
      "epoch 459; iter: 20; batch classifier loss: 0.035836; batch adversarial loss: 0.023440\n",
      "epoch 459; iter: 30; batch classifier loss: 0.038817; batch adversarial loss: 0.020244\n",
      "epoch 459; iter: 40; batch classifier loss: 0.037216; batch adversarial loss: 0.024095\n",
      "epoch 459; iter: 50; batch classifier loss: 0.037465; batch adversarial loss: 0.021692\n",
      "[460/500] Running epoch\n",
      "epoch 460; iter: 0; batch classifier loss: 0.036732; batch adversarial loss: 0.024840\n",
      "epoch 460; iter: 10; batch classifier loss: 0.036524; batch adversarial loss: 0.021102\n",
      "epoch 460; iter: 20; batch classifier loss: 0.036100; batch adversarial loss: 0.021487\n",
      "epoch 460; iter: 30; batch classifier loss: 0.036053; batch adversarial loss: 0.021961\n",
      "epoch 460; iter: 40; batch classifier loss: 0.036302; batch adversarial loss: 0.024402\n",
      "epoch 460; iter: 50; batch classifier loss: 0.038954; batch adversarial loss: 0.027330\n",
      "||w||: 1.2978535890579224\n",
      "||w2||: 0.5965328812599182\n",
      "w.T g: [[0.30422239]]\n",
      "[461/500] Running epoch\n",
      "epoch 461; iter: 0; batch classifier loss: 0.038273; batch adversarial loss: 0.023646\n",
      "epoch 461; iter: 10; batch classifier loss: 0.037808; batch adversarial loss: 0.021697\n",
      "epoch 461; iter: 20; batch classifier loss: 0.038338; batch adversarial loss: 0.025581\n",
      "epoch 461; iter: 30; batch classifier loss: 0.036192; batch adversarial loss: 0.023570\n",
      "epoch 461; iter: 40; batch classifier loss: 0.037666; batch adversarial loss: 0.022681\n",
      "epoch 461; iter: 50; batch classifier loss: 0.037483; batch adversarial loss: 0.020776\n",
      "[462/500] Running epoch\n",
      "epoch 462; iter: 0; batch classifier loss: 0.038164; batch adversarial loss: 0.022260\n",
      "epoch 462; iter: 10; batch classifier loss: 0.038161; batch adversarial loss: 0.024258\n",
      "epoch 462; iter: 20; batch classifier loss: 0.038125; batch adversarial loss: 0.024048\n",
      "epoch 462; iter: 30; batch classifier loss: 0.039321; batch adversarial loss: 0.024412\n",
      "epoch 462; iter: 40; batch classifier loss: 0.037172; batch adversarial loss: 0.022789\n",
      "epoch 462; iter: 50; batch classifier loss: 0.037582; batch adversarial loss: 0.025024\n",
      "[463/500] Running epoch\n",
      "epoch 463; iter: 0; batch classifier loss: 0.038380; batch adversarial loss: 0.021935\n",
      "epoch 463; iter: 10; batch classifier loss: 0.037878; batch adversarial loss: 0.031452\n",
      "epoch 463; iter: 20; batch classifier loss: 0.037867; batch adversarial loss: 0.021792\n",
      "epoch 463; iter: 30; batch classifier loss: 0.037714; batch adversarial loss: 0.021364\n",
      "epoch 463; iter: 40; batch classifier loss: 0.035461; batch adversarial loss: 0.020119\n",
      "epoch 463; iter: 50; batch classifier loss: 0.037871; batch adversarial loss: 0.023857\n",
      "[464/500] Running epoch\n",
      "epoch 464; iter: 0; batch classifier loss: 0.034663; batch adversarial loss: 0.024134\n",
      "epoch 464; iter: 10; batch classifier loss: 0.035633; batch adversarial loss: 0.018459\n",
      "epoch 464; iter: 20; batch classifier loss: 0.037518; batch adversarial loss: 0.025483\n",
      "epoch 464; iter: 30; batch classifier loss: 0.036609; batch adversarial loss: 0.022766\n",
      "epoch 464; iter: 40; batch classifier loss: 0.038909; batch adversarial loss: 0.025004\n",
      "epoch 464; iter: 50; batch classifier loss: 0.037956; batch adversarial loss: 0.022504\n",
      "[465/500] Running epoch\n",
      "epoch 465; iter: 0; batch classifier loss: 0.036349; batch adversarial loss: 0.019620\n",
      "epoch 465; iter: 10; batch classifier loss: 0.038045; batch adversarial loss: 0.024533\n",
      "epoch 465; iter: 20; batch classifier loss: 0.035823; batch adversarial loss: 0.022440\n",
      "epoch 465; iter: 30; batch classifier loss: 0.038862; batch adversarial loss: 0.029512\n",
      "epoch 465; iter: 40; batch classifier loss: 0.039131; batch adversarial loss: 0.023623\n",
      "epoch 465; iter: 50; batch classifier loss: 0.037354; batch adversarial loss: 0.026655\n",
      "[466/500] Running epoch\n",
      "epoch 466; iter: 0; batch classifier loss: 0.036883; batch adversarial loss: 0.020260\n",
      "epoch 466; iter: 10; batch classifier loss: 0.036341; batch adversarial loss: 0.022567\n",
      "epoch 466; iter: 20; batch classifier loss: 0.035319; batch adversarial loss: 0.022800\n",
      "epoch 466; iter: 30; batch classifier loss: 0.035282; batch adversarial loss: 0.026447\n",
      "epoch 466; iter: 40; batch classifier loss: 0.035381; batch adversarial loss: 0.023292\n",
      "epoch 466; iter: 50; batch classifier loss: 0.037528; batch adversarial loss: 0.023669\n",
      "[467/500] Running epoch\n",
      "epoch 467; iter: 0; batch classifier loss: 0.036840; batch adversarial loss: 0.025869\n",
      "epoch 467; iter: 10; batch classifier loss: 0.037214; batch adversarial loss: 0.023979\n",
      "epoch 467; iter: 20; batch classifier loss: 0.039311; batch adversarial loss: 0.022746\n",
      "epoch 467; iter: 30; batch classifier loss: 0.038412; batch adversarial loss: 0.026742\n",
      "epoch 467; iter: 40; batch classifier loss: 0.037818; batch adversarial loss: 0.023996\n",
      "epoch 467; iter: 50; batch classifier loss: 0.035953; batch adversarial loss: 0.024873\n",
      "[468/500] Running epoch\n",
      "epoch 468; iter: 0; batch classifier loss: 0.038251; batch adversarial loss: 0.019497\n",
      "epoch 468; iter: 10; batch classifier loss: 0.037874; batch adversarial loss: 0.020814\n",
      "epoch 468; iter: 20; batch classifier loss: 0.039045; batch adversarial loss: 0.023148\n",
      "epoch 468; iter: 30; batch classifier loss: 0.037688; batch adversarial loss: 0.024850\n",
      "epoch 468; iter: 40; batch classifier loss: 0.037242; batch adversarial loss: 0.022982\n",
      "epoch 468; iter: 50; batch classifier loss: 0.040298; batch adversarial loss: 0.027580\n",
      "[469/500] Running epoch\n",
      "epoch 469; iter: 0; batch classifier loss: 0.038859; batch adversarial loss: 0.025489\n",
      "epoch 469; iter: 10; batch classifier loss: 0.038995; batch adversarial loss: 0.023759\n",
      "epoch 469; iter: 20; batch classifier loss: 0.035566; batch adversarial loss: 0.020272\n",
      "epoch 469; iter: 30; batch classifier loss: 0.038013; batch adversarial loss: 0.025233\n",
      "epoch 469; iter: 40; batch classifier loss: 0.037383; batch adversarial loss: 0.024471\n",
      "epoch 469; iter: 50; batch classifier loss: 0.036075; batch adversarial loss: 0.019389\n",
      "[470/500] Running epoch\n",
      "epoch 470; iter: 0; batch classifier loss: 0.039800; batch adversarial loss: 0.020474\n",
      "epoch 470; iter: 10; batch classifier loss: 0.038102; batch adversarial loss: 0.023820\n",
      "epoch 470; iter: 20; batch classifier loss: 0.037068; batch adversarial loss: 0.020954\n",
      "epoch 470; iter: 30; batch classifier loss: 0.037854; batch adversarial loss: 0.023664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 470; iter: 40; batch classifier loss: 0.037777; batch adversarial loss: 0.022654\n",
      "epoch 470; iter: 50; batch classifier loss: 0.036902; batch adversarial loss: 0.024190\n",
      "||w||: 1.2978535890579224\n",
      "||w2||: 0.5965328812599182\n",
      "w.T g: [[0.3042224]]\n",
      "[471/500] Running epoch\n",
      "epoch 471; iter: 0; batch classifier loss: 0.036333; batch adversarial loss: 0.022666\n",
      "epoch 471; iter: 10; batch classifier loss: 0.038527; batch adversarial loss: 0.019739\n",
      "epoch 471; iter: 20; batch classifier loss: 0.040839; batch adversarial loss: 0.024836\n",
      "epoch 471; iter: 30; batch classifier loss: 0.039376; batch adversarial loss: 0.022677\n",
      "epoch 471; iter: 40; batch classifier loss: 0.036864; batch adversarial loss: 0.019377\n",
      "epoch 471; iter: 50; batch classifier loss: 0.037610; batch adversarial loss: 0.019916\n",
      "[472/500] Running epoch\n",
      "epoch 472; iter: 0; batch classifier loss: 0.035705; batch adversarial loss: 0.020338\n",
      "epoch 472; iter: 10; batch classifier loss: 0.036495; batch adversarial loss: 0.023572\n",
      "epoch 472; iter: 20; batch classifier loss: 0.039557; batch adversarial loss: 0.022808\n",
      "epoch 472; iter: 30; batch classifier loss: 0.038277; batch adversarial loss: 0.025764\n",
      "epoch 472; iter: 40; batch classifier loss: 0.037118; batch adversarial loss: 0.024180\n",
      "epoch 472; iter: 50; batch classifier loss: 0.038482; batch adversarial loss: 0.027234\n",
      "[473/500] Running epoch\n",
      "epoch 473; iter: 0; batch classifier loss: 0.035399; batch adversarial loss: 0.021736\n",
      "epoch 473; iter: 10; batch classifier loss: 0.040098; batch adversarial loss: 0.022290\n",
      "epoch 473; iter: 20; batch classifier loss: 0.036637; batch adversarial loss: 0.024973\n",
      "epoch 473; iter: 30; batch classifier loss: 0.038523; batch adversarial loss: 0.026608\n",
      "epoch 473; iter: 40; batch classifier loss: 0.037136; batch adversarial loss: 0.022106\n",
      "epoch 473; iter: 50; batch classifier loss: 0.036064; batch adversarial loss: 0.020388\n",
      "[474/500] Running epoch\n",
      "epoch 474; iter: 0; batch classifier loss: 0.036716; batch adversarial loss: 0.019493\n",
      "epoch 474; iter: 10; batch classifier loss: 0.035817; batch adversarial loss: 0.023375\n",
      "epoch 474; iter: 20; batch classifier loss: 0.040205; batch adversarial loss: 0.020924\n",
      "epoch 474; iter: 30; batch classifier loss: 0.036777; batch adversarial loss: 0.023906\n",
      "epoch 474; iter: 40; batch classifier loss: 0.039393; batch adversarial loss: 0.023493\n",
      "epoch 474; iter: 50; batch classifier loss: 0.037671; batch adversarial loss: 0.022748\n",
      "[475/500] Running epoch\n",
      "epoch 475; iter: 0; batch classifier loss: 0.036858; batch adversarial loss: 0.020137\n",
      "epoch 475; iter: 10; batch classifier loss: 0.036443; batch adversarial loss: 0.021113\n",
      "epoch 475; iter: 20; batch classifier loss: 0.036429; batch adversarial loss: 0.023316\n",
      "epoch 475; iter: 30; batch classifier loss: 0.036204; batch adversarial loss: 0.023912\n",
      "epoch 475; iter: 40; batch classifier loss: 0.038868; batch adversarial loss: 0.022194\n",
      "epoch 475; iter: 50; batch classifier loss: 0.036325; batch adversarial loss: 0.023954\n",
      "[476/500] Running epoch\n",
      "epoch 476; iter: 0; batch classifier loss: 0.037433; batch adversarial loss: 0.023222\n",
      "epoch 476; iter: 10; batch classifier loss: 0.035110; batch adversarial loss: 0.023912\n",
      "epoch 476; iter: 20; batch classifier loss: 0.036458; batch adversarial loss: 0.020612\n",
      "epoch 476; iter: 30; batch classifier loss: 0.035801; batch adversarial loss: 0.019764\n",
      "epoch 476; iter: 40; batch classifier loss: 0.037816; batch adversarial loss: 0.025603\n",
      "epoch 476; iter: 50; batch classifier loss: 0.035891; batch adversarial loss: 0.024417\n",
      "[477/500] Running epoch\n",
      "epoch 477; iter: 0; batch classifier loss: 0.040057; batch adversarial loss: 0.028852\n",
      "epoch 477; iter: 10; batch classifier loss: 0.039175; batch adversarial loss: 0.026354\n",
      "epoch 477; iter: 20; batch classifier loss: 0.037590; batch adversarial loss: 0.025529\n",
      "epoch 477; iter: 30; batch classifier loss: 0.038786; batch adversarial loss: 0.024715\n",
      "epoch 477; iter: 40; batch classifier loss: 0.037587; batch adversarial loss: 0.022091\n",
      "epoch 477; iter: 50; batch classifier loss: 0.038030; batch adversarial loss: 0.018729\n",
      "[478/500] Running epoch\n",
      "epoch 478; iter: 0; batch classifier loss: 0.037380; batch adversarial loss: 0.025373\n",
      "epoch 478; iter: 10; batch classifier loss: 0.035179; batch adversarial loss: 0.022063\n",
      "epoch 478; iter: 20; batch classifier loss: 0.040375; batch adversarial loss: 0.024170\n",
      "epoch 478; iter: 30; batch classifier loss: 0.038777; batch adversarial loss: 0.024334\n",
      "epoch 478; iter: 40; batch classifier loss: 0.038852; batch adversarial loss: 0.026378\n",
      "epoch 478; iter: 50; batch classifier loss: 0.038964; batch adversarial loss: 0.024153\n",
      "[479/500] Running epoch\n",
      "epoch 479; iter: 0; batch classifier loss: 0.038428; batch adversarial loss: 0.029150\n",
      "epoch 479; iter: 10; batch classifier loss: 0.040209; batch adversarial loss: 0.020373\n",
      "epoch 479; iter: 20; batch classifier loss: 0.038353; batch adversarial loss: 0.027315\n",
      "epoch 479; iter: 30; batch classifier loss: 0.038839; batch adversarial loss: 0.025209\n",
      "epoch 479; iter: 40; batch classifier loss: 0.038160; batch adversarial loss: 0.019617\n",
      "epoch 479; iter: 50; batch classifier loss: 0.036326; batch adversarial loss: 0.024806\n",
      "[480/500] Running epoch\n",
      "epoch 480; iter: 0; batch classifier loss: 0.038427; batch adversarial loss: 0.021714\n",
      "epoch 480; iter: 10; batch classifier loss: 0.038013; batch adversarial loss: 0.026884\n",
      "epoch 480; iter: 20; batch classifier loss: 0.037613; batch adversarial loss: 0.023776\n",
      "epoch 480; iter: 30; batch classifier loss: 0.037678; batch adversarial loss: 0.019767\n",
      "epoch 480; iter: 40; batch classifier loss: 0.038065; batch adversarial loss: 0.027393\n",
      "epoch 480; iter: 50; batch classifier loss: 0.037606; batch adversarial loss: 0.024608\n",
      "||w||: 1.2978535890579224\n",
      "||w2||: 0.5965328812599182\n",
      "w.T g: [[0.3042224]]\n",
      "[481/500] Running epoch\n",
      "epoch 481; iter: 0; batch classifier loss: 0.039983; batch adversarial loss: 0.028119\n",
      "epoch 481; iter: 10; batch classifier loss: 0.039025; batch adversarial loss: 0.024788\n",
      "epoch 481; iter: 20; batch classifier loss: 0.036572; batch adversarial loss: 0.021888\n",
      "epoch 481; iter: 30; batch classifier loss: 0.037474; batch adversarial loss: 0.022829\n",
      "epoch 481; iter: 40; batch classifier loss: 0.036097; batch adversarial loss: 0.021947\n",
      "epoch 481; iter: 50; batch classifier loss: 0.036316; batch adversarial loss: 0.024785\n",
      "[482/500] Running epoch\n",
      "epoch 482; iter: 0; batch classifier loss: 0.038142; batch adversarial loss: 0.025365\n",
      "epoch 482; iter: 10; batch classifier loss: 0.035829; batch adversarial loss: 0.021993\n",
      "epoch 482; iter: 20; batch classifier loss: 0.036554; batch adversarial loss: 0.022716\n",
      "epoch 482; iter: 30; batch classifier loss: 0.038123; batch adversarial loss: 0.023619\n",
      "epoch 482; iter: 40; batch classifier loss: 0.037541; batch adversarial loss: 0.026244\n",
      "epoch 482; iter: 50; batch classifier loss: 0.038616; batch adversarial loss: 0.022098\n",
      "[483/500] Running epoch\n",
      "epoch 483; iter: 0; batch classifier loss: 0.036332; batch adversarial loss: 0.026234\n",
      "epoch 483; iter: 10; batch classifier loss: 0.035365; batch adversarial loss: 0.022755\n",
      "epoch 483; iter: 20; batch classifier loss: 0.036148; batch adversarial loss: 0.022304\n",
      "epoch 483; iter: 30; batch classifier loss: 0.037999; batch adversarial loss: 0.024373\n",
      "epoch 483; iter: 40; batch classifier loss: 0.037713; batch adversarial loss: 0.021860\n",
      "epoch 483; iter: 50; batch classifier loss: 0.038973; batch adversarial loss: 0.029712\n",
      "[484/500] Running epoch\n",
      "epoch 484; iter: 0; batch classifier loss: 0.039679; batch adversarial loss: 0.023284\n",
      "epoch 484; iter: 10; batch classifier loss: 0.036565; batch adversarial loss: 0.018454\n",
      "epoch 484; iter: 20; batch classifier loss: 0.037921; batch adversarial loss: 0.023320\n",
      "epoch 484; iter: 30; batch classifier loss: 0.039350; batch adversarial loss: 0.026221\n",
      "epoch 484; iter: 40; batch classifier loss: 0.038381; batch adversarial loss: 0.031465\n",
      "epoch 484; iter: 50; batch classifier loss: 0.035587; batch adversarial loss: 0.020090\n",
      "[485/500] Running epoch\n",
      "epoch 485; iter: 0; batch classifier loss: 0.037901; batch adversarial loss: 0.024353\n",
      "epoch 485; iter: 10; batch classifier loss: 0.039732; batch adversarial loss: 0.026458\n",
      "epoch 485; iter: 20; batch classifier loss: 0.037199; batch adversarial loss: 0.025984\n",
      "epoch 485; iter: 30; batch classifier loss: 0.040292; batch adversarial loss: 0.024404\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 485; iter: 40; batch classifier loss: 0.036388; batch adversarial loss: 0.024779\n",
      "epoch 485; iter: 50; batch classifier loss: 0.037003; batch adversarial loss: 0.019941\n",
      "[486/500] Running epoch\n",
      "epoch 486; iter: 0; batch classifier loss: 0.036281; batch adversarial loss: 0.022235\n",
      "epoch 486; iter: 10; batch classifier loss: 0.036313; batch adversarial loss: 0.019541\n",
      "epoch 486; iter: 20; batch classifier loss: 0.039310; batch adversarial loss: 0.022718\n",
      "epoch 486; iter: 30; batch classifier loss: 0.036877; batch adversarial loss: 0.022312\n",
      "epoch 486; iter: 40; batch classifier loss: 0.039548; batch adversarial loss: 0.028095\n",
      "epoch 486; iter: 50; batch classifier loss: 0.035223; batch adversarial loss: 0.023139\n",
      "[487/500] Running epoch\n",
      "epoch 487; iter: 0; batch classifier loss: 0.038163; batch adversarial loss: 0.023958\n",
      "epoch 487; iter: 10; batch classifier loss: 0.038875; batch adversarial loss: 0.024517\n",
      "epoch 487; iter: 20; batch classifier loss: 0.036340; batch adversarial loss: 0.022678\n",
      "epoch 487; iter: 30; batch classifier loss: 0.038069; batch adversarial loss: 0.024311\n",
      "epoch 487; iter: 40; batch classifier loss: 0.036761; batch adversarial loss: 0.028519\n",
      "epoch 487; iter: 50; batch classifier loss: 0.040094; batch adversarial loss: 0.025407\n",
      "[488/500] Running epoch\n",
      "epoch 488; iter: 0; batch classifier loss: 0.037231; batch adversarial loss: 0.024555\n",
      "epoch 488; iter: 10; batch classifier loss: 0.038268; batch adversarial loss: 0.021714\n",
      "epoch 488; iter: 20; batch classifier loss: 0.035655; batch adversarial loss: 0.021171\n",
      "epoch 488; iter: 30; batch classifier loss: 0.037118; batch adversarial loss: 0.024000\n",
      "epoch 488; iter: 40; batch classifier loss: 0.038685; batch adversarial loss: 0.021887\n",
      "epoch 488; iter: 50; batch classifier loss: 0.035641; batch adversarial loss: 0.023480\n",
      "[489/500] Running epoch\n",
      "epoch 489; iter: 0; batch classifier loss: 0.038757; batch adversarial loss: 0.025519\n",
      "epoch 489; iter: 10; batch classifier loss: 0.038345; batch adversarial loss: 0.021305\n",
      "epoch 489; iter: 20; batch classifier loss: 0.036657; batch adversarial loss: 0.021101\n",
      "epoch 489; iter: 30; batch classifier loss: 0.036676; batch adversarial loss: 0.021873\n",
      "epoch 489; iter: 40; batch classifier loss: 0.038752; batch adversarial loss: 0.021081\n",
      "epoch 489; iter: 50; batch classifier loss: 0.037223; batch adversarial loss: 0.022386\n",
      "[490/500] Running epoch\n",
      "epoch 490; iter: 0; batch classifier loss: 0.039046; batch adversarial loss: 0.027805\n",
      "epoch 490; iter: 10; batch classifier loss: 0.037835; batch adversarial loss: 0.021288\n",
      "epoch 490; iter: 20; batch classifier loss: 0.037079; batch adversarial loss: 0.023252\n",
      "epoch 490; iter: 30; batch classifier loss: 0.038828; batch adversarial loss: 0.027017\n",
      "epoch 490; iter: 40; batch classifier loss: 0.038624; batch adversarial loss: 0.021248\n",
      "epoch 490; iter: 50; batch classifier loss: 0.038173; batch adversarial loss: 0.022282\n",
      "||w||: 1.2978535890579224\n",
      "||w2||: 0.5965328812599182\n",
      "w.T g: [[0.3042224]]\n",
      "[491/500] Running epoch\n",
      "epoch 491; iter: 0; batch classifier loss: 0.039932; batch adversarial loss: 0.026855\n",
      "epoch 491; iter: 10; batch classifier loss: 0.038115; batch adversarial loss: 0.024914\n",
      "epoch 491; iter: 20; batch classifier loss: 0.037449; batch adversarial loss: 0.024366\n",
      "epoch 491; iter: 30; batch classifier loss: 0.036948; batch adversarial loss: 0.021501\n",
      "epoch 491; iter: 40; batch classifier loss: 0.037283; batch adversarial loss: 0.023126\n",
      "epoch 491; iter: 50; batch classifier loss: 0.037924; batch adversarial loss: 0.020202\n",
      "[492/500] Running epoch\n",
      "epoch 492; iter: 0; batch classifier loss: 0.037639; batch adversarial loss: 0.023086\n",
      "epoch 492; iter: 10; batch classifier loss: 0.037422; batch adversarial loss: 0.019885\n",
      "epoch 492; iter: 20; batch classifier loss: 0.038307; batch adversarial loss: 0.022730\n",
      "epoch 492; iter: 30; batch classifier loss: 0.038258; batch adversarial loss: 0.019766\n",
      "epoch 492; iter: 40; batch classifier loss: 0.038090; batch adversarial loss: 0.026472\n",
      "epoch 492; iter: 50; batch classifier loss: 0.037579; batch adversarial loss: 0.025567\n",
      "[493/500] Running epoch\n",
      "epoch 493; iter: 0; batch classifier loss: 0.036204; batch adversarial loss: 0.022731\n",
      "epoch 493; iter: 10; batch classifier loss: 0.036887; batch adversarial loss: 0.028244\n",
      "epoch 493; iter: 20; batch classifier loss: 0.037542; batch adversarial loss: 0.024535\n",
      "epoch 493; iter: 30; batch classifier loss: 0.035771; batch adversarial loss: 0.021543\n",
      "epoch 493; iter: 40; batch classifier loss: 0.038569; batch adversarial loss: 0.023832\n",
      "epoch 493; iter: 50; batch classifier loss: 0.040464; batch adversarial loss: 0.028509\n",
      "[494/500] Running epoch\n",
      "epoch 494; iter: 0; batch classifier loss: 0.037639; batch adversarial loss: 0.022223\n",
      "epoch 494; iter: 10; batch classifier loss: 0.035395; batch adversarial loss: 0.023868\n",
      "epoch 494; iter: 20; batch classifier loss: 0.039344; batch adversarial loss: 0.028761\n",
      "epoch 494; iter: 30; batch classifier loss: 0.038432; batch adversarial loss: 0.021243\n",
      "epoch 494; iter: 40; batch classifier loss: 0.037200; batch adversarial loss: 0.020499\n",
      "epoch 494; iter: 50; batch classifier loss: 0.039454; batch adversarial loss: 0.023406\n",
      "[495/500] Running epoch\n",
      "epoch 495; iter: 0; batch classifier loss: 0.035353; batch adversarial loss: 0.026035\n",
      "epoch 495; iter: 10; batch classifier loss: 0.037615; batch adversarial loss: 0.024597\n",
      "epoch 495; iter: 20; batch classifier loss: 0.037100; batch adversarial loss: 0.025298\n",
      "epoch 495; iter: 30; batch classifier loss: 0.037569; batch adversarial loss: 0.021725\n",
      "epoch 495; iter: 40; batch classifier loss: 0.039287; batch adversarial loss: 0.022558\n",
      "epoch 495; iter: 50; batch classifier loss: 0.035660; batch adversarial loss: 0.020379\n",
      "[496/500] Running epoch\n",
      "epoch 496; iter: 0; batch classifier loss: 0.035465; batch adversarial loss: 0.024198\n",
      "epoch 496; iter: 10; batch classifier loss: 0.038927; batch adversarial loss: 0.026489\n",
      "epoch 496; iter: 20; batch classifier loss: 0.036086; batch adversarial loss: 0.019937\n",
      "epoch 496; iter: 30; batch classifier loss: 0.038254; batch adversarial loss: 0.021992\n",
      "epoch 496; iter: 40; batch classifier loss: 0.039204; batch adversarial loss: 0.026877\n",
      "epoch 496; iter: 50; batch classifier loss: 0.037601; batch adversarial loss: 0.022828\n",
      "[497/500] Running epoch\n",
      "epoch 497; iter: 0; batch classifier loss: 0.037042; batch adversarial loss: 0.026736\n",
      "epoch 497; iter: 10; batch classifier loss: 0.036063; batch adversarial loss: 0.023078\n",
      "epoch 497; iter: 20; batch classifier loss: 0.037878; batch adversarial loss: 0.025110\n",
      "epoch 497; iter: 30; batch classifier loss: 0.038544; batch adversarial loss: 0.024114\n",
      "epoch 497; iter: 40; batch classifier loss: 0.037642; batch adversarial loss: 0.020367\n",
      "epoch 497; iter: 50; batch classifier loss: 0.036480; batch adversarial loss: 0.022611\n",
      "[498/500] Running epoch\n",
      "epoch 498; iter: 0; batch classifier loss: 0.039160; batch adversarial loss: 0.023785\n",
      "epoch 498; iter: 10; batch classifier loss: 0.036288; batch adversarial loss: 0.019982\n",
      "epoch 498; iter: 20; batch classifier loss: 0.037994; batch adversarial loss: 0.025346\n",
      "epoch 498; iter: 30; batch classifier loss: 0.038004; batch adversarial loss: 0.022538\n",
      "epoch 498; iter: 40; batch classifier loss: 0.039075; batch adversarial loss: 0.026233\n",
      "epoch 498; iter: 50; batch classifier loss: 0.038771; batch adversarial loss: 0.023611\n",
      "[499/500] Running epoch\n",
      "epoch 499; iter: 0; batch classifier loss: 0.037598; batch adversarial loss: 0.023244\n",
      "epoch 499; iter: 10; batch classifier loss: 0.037614; batch adversarial loss: 0.025738\n",
      "epoch 499; iter: 20; batch classifier loss: 0.036397; batch adversarial loss: 0.024313\n",
      "epoch 499; iter: 30; batch classifier loss: 0.036357; batch adversarial loss: 0.028223\n",
      "epoch 499; iter: 40; batch classifier loss: 0.038247; batch adversarial loss: 0.022886\n",
      "epoch 499; iter: 50; batch classifier loss: 0.037409; batch adversarial loss: 0.022793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<adversarial_debiasing.AdversarialDebiasing at 0x7fcb52b2b090>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the variant of the model with debiasing\n",
    "# debiased_model = AdversarialDebiasing(\n",
    "#     word_embedding_dim=word_embedding_dim,\n",
    "#     num_epochs=500,\n",
    "#     debias=True,\n",
    "#     gender_subspace=gender_subspace,\n",
    "#     batch_size=256,\n",
    "#     adversary_loss_weight=0.1,\n",
    "#     classifier_learning_rate = 2 ** -8,\n",
    "#     adversary_learning_rate = 2 ** -8\n",
    "# )\n",
    "debiased_model = AdversarialDebiasing(\n",
    "    word_embedding_dim=word_embedding_dim,\n",
    "    num_epochs=500,\n",
    "    debias=True,\n",
    "    gender_subspace=gender_subspace,\n",
    "    batch_size=256,\n",
    "    adversary_loss_weight=0.1,\n",
    "    classifier_learning_rate = 2 ** -6,\n",
    "    adversary_learning_rate = 2 ** -6\n",
    ")\n",
    "\n",
    "debiased_model.fit(dataset=transformed_analogy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28268819]]\n"
     ]
    }
   ],
   "source": [
    "W1 = debiased_model.get_model_weights()\n",
    "print(np.dot(W1.clone().cpu().detach().numpy().T,gender_subspace.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 900)\n"
     ]
    }
   ],
   "source": [
    "# Examples to test the models upon\n",
    "datapoints, test_analogies = [], []\n",
    "with open(os.path.join('data', 'sexism-traps.txt'), 'r') as f:\n",
    "    # Reading each line\n",
    "    for line in f.readlines():\n",
    "        words = line.split()\n",
    "        if words[0] == ':':\n",
    "            continue\n",
    "        test_analogies.append(words)\n",
    "        word_embeddings = word_vectors[words]\n",
    "        word_embeddings = np.reshape(word_embeddings, (1, -1))\n",
    "        datapoints.append(word_embeddings)\n",
    "datapoints = np.vstack(datapoints)\n",
    "print(datapoints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Qualitative evaluation of the non-debiased model\n",
    "\n",
    "# non_debiased_predictions = non_debiased_model.predict(datapoints)\n",
    "features = torch.cat([torch.Tensor(x).unsqueeze_(0) for x in datapoints])\n",
    "x1 = features[:, 0:word_embedding_dim]\n",
    "x2 = features[:, word_embedding_dim:word_embedding_dim * 2]\n",
    "x3 = features[:, word_embedding_dim * 2:word_embedding_dim * 3]\n",
    "\n",
    "non_debiased_predictions = x2 + x3 - x1\n",
    "non_debiased_predictions = non_debiased_predictions.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_debiased_most_similar_list = utility_functions.obtain_most_similar(non_debiased_predictions, word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Displaying the similarity list for the non-debiased model\n",
    "non_debiased_most_similar_list_data_frames = []\n",
    "for i in range(len(non_debiased_most_similar_list)):\n",
    "    # print(\"{} : {} :: {} : \".format(test_analogies[i][0], test_analogies[i][1], test_analogies[i][2]))\n",
    "    temp_data_frame = pd.DataFrame(non_debiased_most_similar_list[i][1:], columns = ['Neighbor', 'Similarity'])\n",
    "    non_debiased_most_similar_list_data_frames.append(temp_data_frame)\n",
    "    # print(tabulate(temp_data_frame, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Qualitative evaluation of the debiased model\n",
    "debiased_predictions = debiased_model.predict(datapoints)\n",
    "debiased_most_similar_list = utility_functions.obtain_most_similar(debiased_predictions, word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Displaying the similarity list for the debiased model\n",
    "debiased_most_similar_list_data_frames = []\n",
    "for i in range(len(debiased_most_similar_list)):\n",
    "    # print(\"{} : {} :: {} : \".format(test_analogies[i][0], test_analogies[i][1], test_analogies[i][2]))\n",
    "    temp_data_frame = pd.DataFrame(debiased_most_similar_list[i][1:], columns = ['Neighbor', 'Similarity'])\n",
    "    debiased_most_similar_list_data_frames.append(temp_data_frame)\n",
    "    # print(tabulate(temp_data_frame, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he : strong :: she : \n",
      "+-------------+--------------+-------------+--------------+\n",
      "| Biased      |       Biased | Debiased    |     Debiased |\n",
      "| Neighbour   |   Similarity | Neighbour   |   Similarity |\n",
      "|-------------+--------------+-------------+--------------|\n",
      "| strong      |        0.794 | strong      |        0.815 |\n",
      "| robust      |        0.531 | stong       |        0.54  |\n",
      "| stong       |        0.516 | robust      |        0.537 |\n",
      "| solid       |        0.51  | solid       |        0.536 |\n",
      "| stronger    |        0.504 | stronger    |        0.528 |\n",
      "| weak        |        0.493 | strongest   |        0.494 |\n",
      "| strongest   |        0.476 | weak        |        0.492 |\n",
      "| Strong      |        0.468 | Strong      |        0.471 |\n",
      "| she         |        0.436 | good        |        0.437 |\n",
      "+-------------+--------------+-------------+--------------+\n",
      "he : boss :: she : \n",
      "+---------------------------+--------------+-----------------+--------------+\n",
      "| Biased                    |       Biased | Debiased        |     Debiased |\n",
      "| Neighbour                 |   Similarity | Neighbour       |   Similarity |\n",
      "|---------------------------+--------------+-----------------+--------------|\n",
      "| boss                      |        0.814 | boss            |        0.83  |\n",
      "| bosses                    |        0.581 | bosses          |        0.588 |\n",
      "| manageress                |        0.513 | Kym_Marsh       |        0.503 |\n",
      "| Kym_Marsh                 |        0.51  | supremo         |        0.499 |\n",
      "| stepmum                   |        0.5   | Bev_Callard     |        0.496 |\n",
      "| Jane_Danson               |        0.497 | manageress      |        0.486 |\n",
      "| Vicky_Entwistle           |        0.496 | Vicky_Entwistle |        0.483 |\n",
      "| Bev_Callard               |        0.491 | Jane_Danson     |        0.482 |\n",
      "| Coronation_Street_actress |        0.489 | Sandeesh        |        0.479 |\n",
      "+---------------------------+--------------+-----------------+--------------+\n",
      "he : company :: she : \n",
      "+-----------------+--------------+---------------+--------------+\n",
      "| Biased          |       Biased | Debiased      |     Debiased |\n",
      "| Neighbour       |   Similarity | Neighbour     |   Similarity |\n",
      "|-----------------+--------------+---------------+--------------|\n",
      "| company         |        0.766 | company       |        0.757 |\n",
      "| she             |        0.512 | companies     |        0.475 |\n",
      "| companies       |        0.479 | compay        |        0.467 |\n",
      "| her             |        0.478 | comapny       |        0.467 |\n",
      "| compay          |        0.468 | Park_Seong_ae |        0.462 |\n",
      "| Park_Seong_ae   |        0.467 | com_pany      |        0.458 |\n",
      "| com_pany        |        0.464 | firm          |        0.45  |\n",
      "| Martha_Lindeman |        0.46  | Dana_Lengkeek |        0.445 |\n",
      "| ClubJenna       |        0.458 | ClubJenna     |        0.44  |\n",
      "+-----------------+--------------+---------------+--------------+\n",
      "he : athletic :: she : \n",
      "+---------------------------+--------------+---------------------------+--------------+\n",
      "| Biased                    |       Biased | Debiased                  |     Debiased |\n",
      "| Neighbour                 |   Similarity | Neighbour                 |   Similarity |\n",
      "|---------------------------+--------------+---------------------------+--------------|\n",
      "| athletic                  |        0.877 | athletic                  |        0.89  |\n",
      "| athletics                 |        0.729 | athletics                 |        0.726 |\n",
      "| atheltic                  |        0.615 | atheltic                  |        0.622 |\n",
      "| athletic_director         |        0.599 | athletic_director         |        0.593 |\n",
      "| basketball                |        0.566 | basketball                |        0.564 |\n",
      "| intercollegiate_athletic  |        0.563 | Athletic_Director         |        0.552 |\n",
      "| Athletic_Director         |        0.556 | intercollegiate_athletic  |        0.552 |\n",
      "| intercollegiate_athletics |        0.528 | intercollegiate_athletics |        0.532 |\n",
      "| softball                  |        0.524 | collegiate_athletics      |        0.523 |\n",
      "+---------------------------+--------------+---------------------------+--------------+\n",
      "he : doctor :: she : \n",
      "+--------------------+--------------+--------------------+--------------+\n",
      "| Biased             |       Biased | Debiased           |     Debiased |\n",
      "| Neighbour          |   Similarity | Neighbour          |   Similarity |\n",
      "|--------------------+--------------+--------------------+--------------|\n",
      "| doctor             |        0.865 | doctor             |        0.865 |\n",
      "| nurse              |        0.692 | gynecologist       |        0.669 |\n",
      "| gynecologist       |        0.691 | doctors            |        0.655 |\n",
      "| nurse_practitioner |        0.646 | nurse              |        0.64  |\n",
      "| doctors            |        0.643 | physician          |        0.636 |\n",
      "| pediatrician       |        0.642 | pediatrician       |        0.618 |\n",
      "| physician          |        0.63  | nurse_practitioner |        0.616 |\n",
      "| midwife            |        0.617 | dermatologist      |        0.587 |\n",
      "| pharmacist         |        0.609 | pharmacist         |        0.586 |\n",
      "+--------------------+--------------+--------------------+--------------+\n",
      "he : leader :: she : \n",
      "+------------------------+--------------+------------------------+--------------+\n",
      "| Biased                 |       Biased | Debiased               |     Debiased |\n",
      "| Neighbour              |   Similarity | Neighbour              |   Similarity |\n",
      "|------------------------+--------------+------------------------+--------------|\n",
      "| leader                 |        0.793 | leader                 |        0.814 |\n",
      "| chairwoman             |        0.471 | leadership             |        0.473 |\n",
      "| Leader                 |        0.463 | Leader                 |        0.463 |\n",
      "| leadership             |        0.458 | chairwoman             |        0.457 |\n",
      "| leaders                |        0.438 | leaders                |        0.443 |\n",
      "| businesswoman          |        0.436 | leader_Rosa_Otunbayeva |        0.421 |\n",
      "| leader_Rosa_Otunbayeva |        0.43  | stateswoman            |        0.417 |\n",
      "| stateswoman            |        0.422 | premier                |        0.407 |\n",
      "| she                    |        0.422 | chairperson            |        0.398 |\n",
      "+------------------------+--------------+------------------------+--------------+\n",
      "he : director :: she : \n",
      "+--------------------+--------------+--------------------+--------------+\n",
      "| Biased             |       Biased | Debiased           |     Debiased |\n",
      "| Neighbour          |   Similarity | Neighbour          |   Similarity |\n",
      "|--------------------+--------------+--------------------+--------------|\n",
      "| director           |        0.864 | director           |        0.879 |\n",
      "| coordinator        |        0.692 | coordinator        |        0.705 |\n",
      "| chairwoman         |        0.681 | chairwoman         |        0.67  |\n",
      "| Executive_Director |        0.625 | vice_president     |        0.643 |\n",
      "| vice_president     |        0.624 | Executive_Director |        0.642 |\n",
      "| Director           |        0.613 | Director           |        0.626 |\n",
      "| executive          |        0.597 | co_ordinator       |        0.609 |\n",
      "| co_ordinator       |        0.596 | executive          |        0.608 |\n",
      "| direc_tor          |        0.594 | vp                 |        0.607 |\n",
      "+--------------------+--------------+--------------------+--------------+\n",
      "he : rich :: she : \n",
      "+-----------------+--------------+-----------------+--------------+\n",
      "| Biased          |       Biased | Debiased        |     Debiased |\n",
      "| Neighbour       |   Similarity | Neighbour       |   Similarity |\n",
      "|-----------------+--------------+-----------------+--------------|\n",
      "| rich            |        0.827 | rich            |        0.843 |\n",
      "| richer          |        0.504 | richer          |        0.537 |\n",
      "| wealthy         |        0.502 | wealthy         |        0.507 |\n",
      "| richness        |        0.448 | richness        |        0.46  |\n",
      "| sexy_beauties   |        0.444 | sexy_beauties   |        0.433 |\n",
      "| fabulously_rich |        0.423 | fabulously_rich |        0.433 |\n",
      "| millionairess   |        0.418 | filthy_rich     |        0.429 |\n",
      "| heiresses       |        0.418 | Lovey_Howell    |        0.429 |\n",
      "| Lovey_Howell    |        0.412 | wealthier       |        0.427 |\n",
      "+-----------------+--------------+-----------------+--------------+\n",
      "he : pilot :: she : \n",
      "+---------------------+--------------+---------------------+--------------+\n",
      "| Biased              |       Biased | Debiased            |     Debiased |\n",
      "| Neighbour           |   Similarity | Neighbour           |   Similarity |\n",
      "|---------------------+--------------+---------------------+--------------|\n",
      "| pilot               |        0.853 | pilot               |        0.849 |\n",
      "| Pilot               |        0.543 | pilots              |        0.541 |\n",
      "| pilots              |        0.535 | Pilot               |        0.524 |\n",
      "| flight_attendant    |        0.518 | piloting            |        0.509 |\n",
      "| piloting            |        0.5   | flight_attendant    |        0.495 |\n",
      "| Maj._Robert_Grzywna |        0.492 | Aileen_McGlynn      |        0.468 |\n",
      "| Buddy_Summerfield   |        0.475 | Maj._Robert_Grzywna |        0.463 |\n",
      "| Cessna_###R         |        0.473 | aborts_landing      |        0.458 |\n",
      "| Marvin_Renslow      |        0.469 | Marvin_Renslow      |        0.456 |\n",
      "+---------------------+--------------+---------------------+--------------+\n",
      "he : captain :: she : \n",
      "+--------------------------+--------------+--------------------------+--------------+\n",
      "| Biased                   |       Biased | Debiased                 |     Debiased |\n",
      "| Neighbour                |   Similarity | Neighbour                |   Similarity |\n",
      "|--------------------------+--------------+--------------------------+--------------|\n",
      "| captain                  |        0.847 | captain                  |        0.861 |\n",
      "| captian                  |        0.622 | captian                  |        0.64  |\n",
      "| skipper                  |        0.612 | captains                 |        0.635 |\n",
      "| captains                 |        0.608 | skipper                  |        0.621 |\n",
      "| captaining               |        0.528 | captaining               |        0.553 |\n",
      "| captained                |        0.519 | captained                |        0.546 |\n",
      "| captain_Sharelle_McMahon |        0.502 | Captain                  |        0.504 |\n",
      "| Hockeyroo                |        0.495 | captain_Sharelle_McMahon |        0.496 |\n",
      "| captain_Karen_Rolton     |        0.49  | Hockeyroo                |        0.489 |\n",
      "+--------------------------+--------------+--------------------------+--------------+\n",
      "he : president :: she : \n",
      "+--------------------+--------------+--------------------+--------------+\n",
      "| Biased             |       Biased | Debiased           |     Debiased |\n",
      "| Neighbour          |   Similarity | Neighbour          |   Similarity |\n",
      "|--------------------+--------------+--------------------+--------------|\n",
      "| president          |        0.82  | president          |        0.838 |\n",
      "| President          |        0.65  | President          |        0.664 |\n",
      "| chairwoman         |        0.613 | chairwoman         |        0.601 |\n",
      "| chairperson        |        0.571 | vice_president     |        0.574 |\n",
      "| vice_president     |        0.55  | chairperson        |        0.573 |\n",
      "| executive          |        0.526 | Executive_Director |        0.545 |\n",
      "| Vice_President     |        0.526 | executive          |        0.541 |\n",
      "| Executive_Director |        0.524 | Vice_President     |        0.539 |\n",
      "| chief_executive    |        0.502 | chief_executive    |        0.523 |\n",
      "+--------------------+--------------+--------------------+--------------+\n",
      "he : power :: she : \n",
      "+--------------------+--------------+--------------------+--------------+\n",
      "| Biased             |       Biased | Debiased           |     Debiased |\n",
      "| Neighbour          |   Similarity | Neighbour          |   Similarity |\n",
      "|--------------------+--------------+--------------------+--------------|\n",
      "| power              |        0.796 | power              |        0.817 |\n",
      "| electricity        |        0.496 | electricity        |        0.488 |\n",
      "| Power              |        0.485 | Power              |        0.488 |\n",
      "| she                |        0.42  | electricty         |        0.408 |\n",
      "| Concentrated_solar |        0.414 | Concentrated_solar |        0.408 |\n",
      "| Elisha_Moreno      |        0.414 | electricy          |        0.407 |\n",
      "| hydro              |        0.413 | hydro              |        0.401 |\n",
      "| Dorothy_Bracken    |        0.409 | electicity         |        0.4   |\n",
      "| electicity         |        0.408 | energy             |        0.399 |\n",
      "+--------------------+--------------+--------------------+--------------+\n",
      "he : rational :: she : \n",
      "+-----------------+--------------+-----------------+--------------+\n",
      "| Biased          |       Biased | Debiased        |     Debiased |\n",
      "| Neighbour       |   Similarity | Neighbour       |   Similarity |\n",
      "|-----------------+--------------+-----------------+--------------|\n",
      "| rational        |        0.845 | rational        |        0.854 |\n",
      "| rationally      |        0.583 | rationally      |        0.586 |\n",
      "| rationality     |        0.572 | rationality     |        0.576 |\n",
      "| irrational      |        0.569 | irrational      |        0.574 |\n",
      "| sane            |        0.537 | sane            |        0.542 |\n",
      "| sensible        |        0.528 | sensible        |        0.536 |\n",
      "| sane_rational   |        0.523 | sane_rational   |        0.532 |\n",
      "| rational_beings |        0.513 | rational_beings |        0.519 |\n",
      "| dispassionate   |        0.509 | dispassionate   |        0.512 |\n",
      "+-----------------+--------------+-----------------+--------------+\n",
      "he : confident :: she : \n",
      "+-----------------------+--------------+-----------------------+--------------+\n",
      "| Biased                |       Biased | Debiased              |     Debiased |\n",
      "| Neighbour             |   Similarity | Neighbour             |   Similarity |\n",
      "|-----------------------+--------------+-----------------------+--------------|\n",
      "| confident             |        0.822 | confident             |        0.826 |\n",
      "| hopeful               |        0.596 | hopeful               |        0.599 |\n",
      "| optimistic            |        0.59  | optimistic            |        0.593 |\n",
      "| cautiously_optimistic |        0.572 | cautiously_optimistic |        0.575 |\n",
      "| convinced             |        0.531 | convinced             |        0.535 |\n",
      "| happy                 |        0.518 | happy                 |        0.522 |\n",
      "| pleased               |        0.51  | pleased               |        0.514 |\n",
      "| excited               |        0.503 | excited               |        0.506 |\n",
      "| guardedly_optimistic  |        0.502 | guardedly_optimistic  |        0.504 |\n",
      "+-----------------------+--------------+-----------------------+--------------+\n",
      "he : hard :: she : \n",
      "+----------------------+--------------+----------------------+--------------+\n",
      "| Biased               |       Biased | Debiased             |     Debiased |\n",
      "| Neighbour            |   Similarity | Neighbour            |   Similarity |\n",
      "|----------------------+--------------+----------------------+--------------|\n",
      "| hard                 |        0.799 | hard                 |        0.819 |\n",
      "| harder               |        0.551 | harder               |        0.579 |\n",
      "| she                  |        0.52  | tough                |        0.512 |\n",
      "| tough                |        0.484 | difficult            |        0.508 |\n",
      "| difficult            |        0.483 | Hard                 |        0.493 |\n",
      "| Hard                 |        0.482 | she                  |        0.483 |\n",
      "| her                  |        0.454 | hardest              |        0.454 |\n",
      "| SERENA_WILLIAMS_Yeah |        0.446 | SERENA_WILLIAMS_Yeah |        0.453 |\n",
      "| hardest              |        0.44  | really               |        0.434 |\n",
      "+----------------------+--------------+----------------------+--------------+\n",
      "he : relaxed :: she : \n",
      "+-------------+--------------+-------------+--------------+\n",
      "| Biased      |       Biased | Debiased    |     Debiased |\n",
      "| Neighbour   |   Similarity | Neighbour   |   Similarity |\n",
      "|-------------+--------------+-------------+--------------|\n",
      "| relaxed     |        0.86  | relaxed     |        0.875 |\n",
      "| relaxing    |        0.606 | relaxing    |        0.595 |\n",
      "| relax       |        0.584 | relax       |        0.591 |\n",
      "| Relaxed     |        0.535 | comfortable |        0.546 |\n",
      "| comfortable |        0.518 | Relaxed     |        0.538 |\n",
      "| looser      |        0.514 | looser      |        0.533 |\n",
      "| Relaxing    |        0.49  | calmer      |        0.515 |\n",
      "| calmer      |        0.486 | laxed       |        0.497 |\n",
      "| relaxes     |        0.486 | relaxes     |        0.497 |\n",
      "+-------------+--------------+-------------+--------------+\n",
      "he : cry :: she : \n",
      "+------------------+--------------+------------------+--------------+\n",
      "| Biased           |       Biased | Debiased         |     Debiased |\n",
      "| Neighbour        |   Similarity | Neighbour        |   Similarity |\n",
      "|------------------+--------------+------------------+--------------|\n",
      "| cry              |        0.871 | cry              |        0.886 |\n",
      "| crying           |        0.619 | crying           |        0.628 |\n",
      "| cries            |        0.584 | cries            |        0.592 |\n",
      "| bawling          |        0.533 | scream           |        0.538 |\n",
      "| sob              |        0.525 | bawling          |        0.535 |\n",
      "| weep             |        0.523 | weep             |        0.533 |\n",
      "| cry_hysterically |        0.52  | cried            |        0.523 |\n",
      "| cried            |        0.52  | sob              |        0.522 |\n",
      "| scream           |        0.518 | cry_hysterically |        0.508 |\n",
      "+------------------+--------------+------------------+--------------+\n",
      "he : brave :: she : \n",
      "+--------------+--------------+--------------+--------------+\n",
      "| Biased       |       Biased | Debiased     |     Debiased |\n",
      "| Neighbour    |   Similarity | Neighbour    |   Similarity |\n",
      "|--------------+--------------+--------------+--------------|\n",
      "| brave        |        0.847 | brave        |        0.862 |\n",
      "| courageous   |        0.636 | courageous   |        0.645 |\n",
      "| bravely      |        0.562 | bravely      |        0.565 |\n",
      "| bravest      |        0.542 | bravest      |        0.554 |\n",
      "| brave_souls  |        0.495 | courage      |        0.498 |\n",
      "| courage      |        0.489 | valiant      |        0.494 |\n",
      "| valiant      |        0.487 | brave_souls  |        0.488 |\n",
      "| courageously |        0.469 | courageously |        0.472 |\n",
      "| gallant      |        0.469 | gallant      |        0.471 |\n",
      "+--------------+--------------+--------------+--------------+\n",
      "he : intelligent :: she : \n",
      "+------------------------+--------------+------------------------+--------------+\n",
      "| Biased                 |       Biased | Debiased               |     Debiased |\n",
      "| Neighbour              |   Similarity | Neighbour              |   Similarity |\n",
      "|------------------------+--------------+------------------------+--------------|\n",
      "| intelligent            |        0.85  | intelligent            |        0.863 |\n",
      "| smart                  |        0.533 | smart                  |        0.547 |\n",
      "| WHAT_MAKES_HER_SPECIAL |        0.482 | intellegent            |        0.493 |\n",
      "| she'sa                 |        0.479 | intuitive              |        0.48  |\n",
      "| intellegent            |        0.478 | she'sa                 |        0.478 |\n",
      "| intuitive              |        0.478 | socially_adept         |        0.477 |\n",
      "| socially_adept         |        0.476 | thoughtful_considerate |        0.475 |\n",
      "| thoughtful_considerate |        0.473 | WHAT_MAKES_HER_SPECIAL |        0.471 |\n",
      "| vivacious              |        0.467 | thoughtful             |        0.47  |\n",
      "+------------------------+--------------+------------------------+--------------+\n",
      "he : ambitious :: she : \n",
      "+-------------------------------------+--------------+--------------------+--------------+\n",
      "| Biased                              |       Biased | Debiased           |     Debiased |\n",
      "| Neighbour                           |   Similarity | Neighbour          |   Similarity |\n",
      "|-------------------------------------+--------------+--------------------+--------------|\n",
      "| ambitious                           |        0.834 | ambitious          |        0.851 |\n",
      "| Ambitious                           |        0.594 | Ambitious          |        0.607 |\n",
      "| overly_ambitious                    |        0.535 | overly_ambitious   |        0.551 |\n",
      "| Dianna_Agron_Quinn                  |        0.509 | Dianna_Agron_Quinn |        0.497 |\n",
      "| overambitious                       |        0.475 | overambitious      |        0.48  |\n",
      "| ambitiously                         |        0.452 | ambitous           |        0.462 |\n",
      "| ambitous                            |        0.44  | ambitiously        |        0.461 |\n",
      "| idealistic                          |        0.438 | idealistic         |        0.448 |\n",
      "| flagship_Yenipazar_polymetallic_VMS |        0.437 | audacious          |        0.446 |\n",
      "+-------------------------------------+--------------+--------------------+--------------+\n",
      "man : woman :: boss : \n",
      "+---------------------+--------------+--------------------+--------------+\n",
      "| Biased              |       Biased | Debiased           |     Debiased |\n",
      "| Neighbour           |   Similarity | Neighbour          |   Similarity |\n",
      "|---------------------+--------------+--------------------+--------------|\n",
      "| boss                |        0.814 | boss               |        0.83  |\n",
      "| bosses              |        0.559 | bosses             |        0.565 |\n",
      "| manageress          |        0.5   | supremo            |        0.488 |\n",
      "| coworker            |        0.471 | exec               |        0.485 |\n",
      "| receptionist        |        0.47  | head_honcho        |        0.475 |\n",
      "| exec                |        0.47  | manageress         |        0.473 |\n",
      "| husband             |        0.469 | honcho             |        0.447 |\n",
      "| Fiz_Jennie_McAlpine |        0.465 | owner_Pearse_Flynn |        0.445 |\n",
      "| supremo             |        0.459 | manager            |        0.436 |\n",
      "+---------------------+--------------+--------------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# Combining the dataframes pertaining to both the variants of the model\n",
    "iterables = [['Biased', 'Debiased'], ['Neighbour', 'Similarity']]\n",
    "index = pd.MultiIndex.from_product(iterables)\n",
    "overall_data_frames_list = []\n",
    "for i in range(len(non_debiased_most_similar_list)):\n",
    "    overall_list = []\n",
    "    print(\"{} : {} :: {} : \".format(test_analogies[i][0], test_analogies[i][1], test_analogies[i][2]))\n",
    "    for j in range(len(non_debiased_most_similar_list[i][1:])):\n",
    "        temp_list = []\n",
    "        temp_list.append(non_debiased_most_similar_list[i][j][0])\n",
    "        temp_list.append(round(non_debiased_most_similar_list[i][j][1], 3))\n",
    "        temp_list.append(debiased_most_similar_list[i][j][0])\n",
    "        temp_list.append(round(debiased_most_similar_list[i][j][1], 3))\n",
    "        overall_list.append(temp_list)\n",
    "    temp_df = pd.DataFrame(overall_list, columns = index)\n",
    "    # print(temp_df.to_string(index = False))\n",
    "    print(tabulate(temp_df, headers = ['Biased\\nNeighbour', 'Biased\\nSimilarity', 'Debiased\\nNeighbour', 'Debiased\\nSimilarity'], tablefmt = 'psql', showindex = False))\n",
    "    overall_data_frames_list.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Fake dataset for testing purposes\n",
    "\n",
    "# embedding_dim = 100\n",
    "# analogy_dataset = [\n",
    "#     Datapoint(\n",
    "#     analogy_embeddings=np.random.normal(0, 1, size=(3 * embedding_dim, 1)), \n",
    "#     gt_embedding=np.random.normal(0, 1, size=(embedding_dim, 1)),\n",
    "#     protected_embedding=np.random.uniform(0, 1, size=(1))) for n in range(0, 1000)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake dataset for testing purposes\n",
    "\n",
    "# embedding_dim = 100\n",
    "# analogy_dataset = [\n",
    "#     Datapoint(\n",
    "#     analogy_embeddings=np.random.normal(0, 1, size=(3 * embedding_dim, 1)), \n",
    "#     gt_embedding=np.random.normal(0, 1, size=(embedding_dim, 1)),\n",
    "#     protected_embedding=np.random.uniform(0, 1, size=(1))) for n in range(0, 1000)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the word vectors dictionary\n",
    "word_vectors = load_pretrained_vectors(config.wiki_embedding_data_path, config.save_dir, config.wiki_save_file, config.use_glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the google analogies training dataset:\n",
    "analogy_dataset = load_data()\n",
    "analogy_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data such that it includes the embeddings of the words in consideration\n",
    "transformed_analogy_dataset, gender_subspace = transform_data(word_vectors, analogy_dataset, use_boluk = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the transformed analogy dataset\n",
    "print(transformed_analogy_dataset[0].analogy_embeddings.shape)\n",
    "print(transformed_analogy_dataset[0].gt_embedding.shape)\n",
    "print(transformed_analogy_dataset[0].protected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the variant of the model without debiasing\n",
    "non_debiased_model = AdversarialDebiasing(debias=False, num_epochs=50)\n",
    "non_debiased_model.fit(dataset=transformed_analogy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = non_debiased_model.get_model_weights()\n",
    "print(np.dot(W1.detach().numpy().T,gender_subspace.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the variant of the model with debiasing\n",
    "debiased_model = AdversarialDebiasing(num_epochs=500)\n",
    "debiased_model.fit(dataset=transformed_analogy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = debiased_model.get_model_weights()\n",
    "print(np.dot(W1.detach().numpy().T,gender_subspace.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples to test the models upon\n",
    "datapoints, test_analogies = [], []\n",
    "with open(os.path.join('data', 'sexism-traps.txt'), 'r') as f:\n",
    "    # Reading each line\n",
    "    for line in f.readlines():\n",
    "        words = line.split()\n",
    "        if words[0] == ':':\n",
    "            continue\n",
    "        test_analogies.append(words)\n",
    "        word_embeddings = word_vectors[words]\n",
    "        word_embeddings = np.reshape(word_embeddings, (1, -1))\n",
    "        datapoints.append(word_embeddings)\n",
    "datapoints = np.vstack(datapoints)\n",
    "print(datapoints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative evaluation of the non-debiased model\n",
    "non_debiased_predictions = non_debiased_model.predict(datapoints)\n",
    "non_debiased_most_similar_list = utility_functions.obtain_most_similar(non_debiased_predictions, word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the similarity list for the non-debiased model\n",
    "non_debiased_most_similar_list_data_frames = []\n",
    "for i in range(len(non_debiased_most_similar_list)):\n",
    "    # print(\"{} : {} :: {} : \".format(test_analogies[i][0], test_analogies[i][1], test_analogies[i][2]))\n",
    "    temp_data_frame = pd.DataFrame(non_debiased_most_similar_list[i][1:], columns = ['Neighbor', 'Similarity'])\n",
    "    non_debiased_most_similar_list_data_frames.append(temp_data_frame)\n",
    "    # print(tabulate(temp_data_frame, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative evaluation of the debiased model\n",
    "debiased_predictions = debiased_model.predict(datapoints)\n",
    "debiased_most_similar_list = utility_functions.obtain_most_similar(debiased_predictions, word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the similarity list for the debiased model\n",
    "debiased_most_similar_list_data_frames = []\n",
    "for i in range(len(debiased_most_similar_list)):\n",
    "    # print(\"{} : {} :: {} : \".format(test_analogies[i][0], test_analogies[i][1], test_analogies[i][2]))\n",
    "    temp_data_frame = pd.DataFrame(debiased_most_similar_list[i][1:], columns = ['Neighbor', 'Similarity'])\n",
    "    debiased_most_similar_list_data_frames.append(temp_data_frame)\n",
    "    # print(tabulate(temp_data_frame, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the dataframes pertaining to both the variants of the model\n",
    "iterables = [['Biased', 'Debiased'], ['Neighbour', 'Similarity']]\n",
    "index = pd.MultiIndex.from_product(iterables)\n",
    "overall_data_frames_list = []\n",
    "for i in range(len(non_debiased_most_similar_list)):\n",
    "    overall_list = []\n",
    "    print(\"{} : {} :: {} : \".format(test_analogies[i][0], test_analogies[i][1], test_analogies[i][2]))\n",
    "    for j in range(len(non_debiased_most_similar_list[i][1:])):\n",
    "        temp_list = []\n",
    "        temp_list.append(non_debiased_most_similar_list[i][j][0])\n",
    "        temp_list.append(round(non_debiased_most_similar_list[i][j][1], 3))\n",
    "        temp_list.append(debiased_most_similar_list[i][j][0])\n",
    "        temp_list.append(round(debiased_most_similar_list[i][j][1], 3))\n",
    "        overall_list.append(temp_list)\n",
    "    temp_df = pd.DataFrame(overall_list, columns = index)\n",
    "    # print(temp_df.to_string(index = False))\n",
    "    print(tabulate(temp_df, headers = ['Biased\\nNeighbour', 'Biased\\nSimilarity', 'Debiased\\nNeighbour', 'Debiased\\nSimilarity'], tablefmt = 'psql', showindex = False))\n",
    "    overall_data_frames_list.append(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fake dataset for testing purposes\n",
    "\n",
    "# embedding_dim = 100\n",
    "# analogy_dataset = [\n",
    "#     Datapoint(\n",
    "#     analogy_embeddings=np.random.normal(0, 1, size=(3 * embedding_dim, 1)), \n",
    "#     gt_embedding=np.random.normal(0, 1, size=(embedding_dim, 1)),\n",
    "#     protected_embedding=np.random.uniform(0, 1, size=(1))) for n in range(0, 1000)\n",
    "# ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (FACT-AI)",
   "language": "python",
   "name": "pycharm-634e202"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
