{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from tabulate import tabulate\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from adversarial_debiasing import AdversarialDebiasing\n",
    "from load_data import load_data, transform_data, Datapoint\n",
    "\n",
    "from load_vectors import load_pretrained_vectors, load_vectors\n",
    "import config\n",
    "import utility_functions\n",
    "import qualitative_evaluation\n",
    "\n",
    "import gensim\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Autoreloading changes made in other python scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the desired word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading from saved file.\n"
     ]
    }
   ],
   "source": [
    "# For Wikipedia2Vec - pass \"Wikipedia2Vec\"\n",
    "# For Glove - pass \"Glove\"\n",
    "# For GoogleNews (Word2Vec) - pass \"GoogleNews\"\n",
    "\n",
    "word_vectors = load_pretrained_vectors(\"Glove\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the Google Analogies Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Analogies : 19544\n",
      "The first 5 analogies:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Raw_Datapoint(x1='Athens', x2='Greece', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Cairo', y='Egypt', task='capital-common-countries')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analogy_dataset = load_data()\n",
    "print(\"Total Number of Analogies : {}\".format(len(analogy_dataset)))\n",
    "print(\"The first 5 analogies:\")\n",
    "analogy_dataset[0:6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming the above dataset to include the respective word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed datapoint for the first analogy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Datapoint(analogy_embeddings=array([ 1.27120003e-01,  2.20400006e-01,  3.34540009e-01, -5.78999996e-01,\n",
       "       -6.81469977e-01,  2.51949996e-01, -7.63480008e-01, -5.78790009e-01,\n",
       "       -2.91530013e-01,  3.86209995e-01, -3.96910012e-01,  3.20870012e-01,\n",
       "       -9.76779982e-02,  3.21809985e-02,  1.18600003e-01,  3.22279990e-01,\n",
       "       -3.06719989e-01, -4.63580012e-01, -1.31380007e-01, -5.71169972e-01,\n",
       "       -2.21819997e-01,  3.22770000e-01, -6.74659982e-02, -4.50760007e-01,\n",
       "       -2.54599988e-01, -8.35819989e-02,  2.44670004e-01,  4.41489995e-01,\n",
       "       -2.03150004e-01, -1.37189999e-01, -5.03970027e-01, -9.37030017e-02,\n",
       "        9.36819986e-02,  3.27230006e-01,  5.13209999e-01, -5.35640001e-01,\n",
       "        2.68350005e-01, -2.15599999e-01,  1.25379995e-01, -1.73810005e-01,\n",
       "        5.55570006e-01, -1.00089997e-01,  7.84850001e-01, -1.97459996e-01,\n",
       "       -1.11900002e-01, -8.64040013e-03,  6.45210028e-01,  2.02199996e-01,\n",
       "        2.98460007e-01, -3.47479992e-02,  2.13060006e-01,  4.60249990e-01,\n",
       "        1.79600000e-01,  5.10179996e-02, -2.11700007e-01,  3.98039997e-01,\n",
       "        1.71969995e-01,  1.64989993e-01, -8.37239981e-01, -1.34029999e-01,\n",
       "        2.96680003e-01, -1.14450000e-01, -3.71440016e-02, -5.73700011e-01,\n",
       "        4.02330011e-01,  4.16269988e-01, -2.02240005e-01, -6.20150030e-01,\n",
       "        6.84200004e-02,  1.38669997e-01, -8.41700017e-01, -1.33940000e-02,\n",
       "       -6.60530031e-02, -1.10030003e-01, -6.46430016e-01,  3.00440013e-01,\n",
       "       -9.79750007e-02,  1.18890002e-01,  7.96049982e-02, -2.63540000e-01,\n",
       "        1.88449994e-01, -4.04890001e-01, -1.62059993e-01, -5.72350025e-01,\n",
       "        7.29279965e-02,  6.70930028e-01,  5.10409996e-02,  1.86409995e-01,\n",
       "       -4.28689986e-01, -7.08090007e-01, -2.25730002e-01,  7.70619988e-01,\n",
       "       -4.62260008e-01,  9.32589993e-02,  1.28250003e-01, -4.35579985e-01,\n",
       "       -9.27919984e-01,  8.27300012e-01,  2.68409997e-01,  5.67330010e-02,\n",
       "       -5.20060003e-01,  2.40229994e-01, -3.76459986e-01, -6.09729998e-02,\n",
       "        4.78379995e-01, -1.92690000e-01,  5.51800013e-01, -2.66369998e-01,\n",
       "        5.29699996e-02, -6.71809971e-01, -2.13670000e-01, -5.91950007e-02,\n",
       "        1.83950007e-01, -1.69499993e-01, -1.67239994e-01, -6.85760006e-02,\n",
       "        3.64540011e-01,  2.43560001e-01,  4.07889992e-01,  1.39070004e-02,\n",
       "       -2.16000006e-01, -8.30829963e-02, -3.05409998e-01, -3.62980008e-01,\n",
       "       -7.72930011e-02, -1.18519999e-01, -1.45070001e-01, -3.18100005e-02,\n",
       "        6.39400035e-02, -2.13819996e-01,  1.37459993e-01,  1.18979998e-01,\n",
       "       -2.11590007e-01,  3.23940009e-01,  1.13399997e-01,  3.47530007e-01,\n",
       "       -2.04099998e-01,  9.65389982e-02,  7.49849975e-01,  1.45569995e-01,\n",
       "        5.47830015e-02,  1.23920001e-01, -1.88409999e-01,  1.31730005e-01,\n",
       "        3.88839990e-01,  3.55230004e-01,  4.55119997e-01,  6.52019978e-02,\n",
       "       -4.34329987e-01,  5.49650006e-02,  1.18349999e-04, -3.22859995e-02,\n",
       "        7.26310015e-01,  3.41179997e-01, -4.69140001e-02, -5.15829980e-01,\n",
       "       -2.50580013e-01, -3.65740001e-01, -9.67319980e-02, -2.01120004e-01,\n",
       "        3.28489989e-01,  2.70390004e-01, -1.90219998e-01, -8.01580027e-02,\n",
       "       -3.70029986e-01,  4.77510005e-01, -1.66749999e-01,  3.24779987e-01,\n",
       "       -7.60840019e-03,  2.66070008e-01,  1.19900003e-01,  4.19079989e-01,\n",
       "       -1.51940003e-01,  3.53159994e-01,  5.57140000e-02,  2.49219999e-01,\n",
       "       -1.83819994e-01,  3.20819989e-02, -4.95110005e-01, -3.70150000e-01,\n",
       "       -8.24310035e-02,  5.61739981e-01, -6.45699978e-01, -6.87780008e-02,\n",
       "       -1.63780004e-01,  4.38250005e-01,  1.84259996e-01, -4.13510017e-02,\n",
       "       -2.38489993e-02, -2.34180003e-01,  1.99279994e-01, -1.30999997e-01,\n",
       "        5.63019991e-01, -2.42770001e-01,  4.82699990e-01,  2.48559996e-01,\n",
       "       -6.64290011e-01,  2.90219992e-01, -1.83390006e-01, -2.53500007e-02,\n",
       "       -3.84220004e-01,  8.36780012e-01,  3.49009991e-01, -3.47510010e-01,\n",
       "        4.45099995e-02,  2.36509994e-01,  1.66810006e-01,  2.93350011e-01,\n",
       "        6.19960010e-01, -2.29489997e-01, -2.62629986e-01, -9.76100005e-03,\n",
       "        5.26689999e-02,  1.78320006e-01, -5.39740026e-01, -2.49559999e-01,\n",
       "       -1.21750003e-02, -4.07799985e-03,  1.03890002e-01,  1.12029999e-01,\n",
       "        3.67489994e-01, -2.87570000e-01, -4.98329997e-01, -3.52530003e-01,\n",
       "       -2.59450006e+00,  1.12360001e-01,  6.24310002e-02, -4.96219993e-01,\n",
       "        8.86740014e-02,  1.34660006e-01,  2.24720001e-01,  7.20879972e-01,\n",
       "       -4.63300012e-02,  3.41859995e-03, -1.71320006e-01, -5.84370017e-01,\n",
       "       -2.50349998e-01,  3.64470005e-01,  8.46960023e-02,  4.62559998e-01,\n",
       "       -6.51969984e-02,  2.51260012e-01,  2.24830002e-01,  2.44440004e-01,\n",
       "       -2.82539994e-01,  1.70800000e-01, -1.52239993e-01, -9.71449986e-02,\n",
       "        9.04430002e-02, -4.05380011e-01, -4.58340012e-02, -3.11309993e-01,\n",
       "        3.68570000e-01, -3.84319991e-01,  1.42440006e-01,  1.79550007e-01,\n",
       "       -5.02349995e-02, -2.28349999e-01,  1.86829995e-02,  1.21880002e-01,\n",
       "        2.33649999e-01,  6.23870008e-02, -1.12549998e-02,  6.51059985e-01,\n",
       "        2.09820002e-01,  4.51510012e-01, -1.44700006e-01, -3.04390013e-01,\n",
       "       -4.50049996e-01, -1.67809993e-01, -2.16910005e-01,  9.33829993e-02,\n",
       "        2.57469993e-02, -1.37930006e-01, -1.80430003e-02, -1.30710006e-01,\n",
       "       -9.08920020e-02, -9.34109986e-01, -6.36210024e-01,  3.94200012e-02,\n",
       "       -5.03199995e-02, -4.58959997e-01,  2.89429992e-01, -3.74870002e-03,\n",
       "       -5.37660003e-01,  3.00700009e-01,  1.79059997e-01,  6.49950027e-01,\n",
       "        7.63610005e-02, -2.44939998e-01,  7.48849988e-01, -4.01760012e-01,\n",
       "        1.22520000e-01, -2.32669994e-01, -7.53880024e-01,  4.32770014e-01,\n",
       "       -3.71519998e-02, -1.59459993e-01, -2.56449997e-01, -4.85600010e-02,\n",
       "        5.03120005e-01,  7.05229998e-01,  4.51689988e-01, -3.40290010e-01,\n",
       "       -6.98210001e-01,  5.43460011e-01, -1.79929996e+00, -2.38869995e-01,\n",
       "       -1.62709996e-01,  1.57739997e-01, -1.09730005e+00,  6.89509988e-01,\n",
       "       -2.30399996e-01,  1.28539994e-01, -5.87470010e-02,  2.29509994e-02,\n",
       "       -1.32309999e-02, -4.68120009e-01, -4.25449997e-01, -3.72709990e-01,\n",
       "        2.38720000e-01,  7.32110023e-01, -9.01990011e-02,  2.89570000e-02,\n",
       "       -2.97049999e-01, -1.45590007e-01,  3.60920012e-01,  3.17750007e-01,\n",
       "       -5.95149994e-01,  4.31579985e-02, -3.08899999e-01,  8.18350017e-02,\n",
       "       -1.07320003e-01,  1.10440004e+00,  8.99469972e-01, -1.50979996e-01,\n",
       "        3.03990006e-01, -2.68209994e-01,  2.98409998e-01, -9.36959982e-02,\n",
       "        8.33410025e-01, -4.64439988e-01,  5.82050025e-01, -4.46530012e-03,\n",
       "       -2.97270000e-01, -1.99980006e-01,  3.80210012e-01,  4.55210000e-01,\n",
       "       -1.64690003e-01, -2.24450007e-01, -6.66489974e-02,  1.31259993e-01,\n",
       "        5.31359985e-02,  6.56130016e-01, -2.60720015e-01,  4.37090009e-01,\n",
       "       -1.66209996e-01, -2.88060009e-01, -1.65120006e-01, -4.28570002e-01,\n",
       "        2.79850006e-01, -4.78029996e-01,  5.29190004e-02, -3.29840004e-01,\n",
       "        1.84220001e-01,  5.75760007e-01, -2.60520011e-01, -7.89830029e-01,\n",
       "       -1.15659997e-01,  6.47340000e-01, -9.07190025e-01, -3.30289990e-01,\n",
       "        5.83180003e-02,  4.76480007e-01, -3.99089992e-01,  1.34819999e-01,\n",
       "       -1.83600001e-02, -1.19620003e-01,  6.01369977e-01,  5.99009991e-02,\n",
       "       -1.32569999e-01, -7.52799988e-01,  1.40019998e-01, -3.87589991e-01,\n",
       "       -4.37319994e-01,  8.71230006e-01,  3.53610009e-01, -2.13679999e-01,\n",
       "       -3.85969996e-01,  3.68840009e-01,  4.80599999e-02,  7.83360004e-01,\n",
       "       -8.67420018e-01, -2.01020002e-01,  5.70200026e-01, -3.54530007e-01,\n",
       "       -1.16719997e+00,  7.06399977e-01,  2.00500004e-02, -1.25420004e-01,\n",
       "       -6.90289974e-01,  5.84810019e-01, -3.37740004e-01, -2.54799992e-01,\n",
       "        3.12599987e-01,  6.55340031e-02,  3.83340001e-01, -2.75759995e-01,\n",
       "       -1.41589999e-01, -3.74709994e-01, -5.75919986e-01, -3.26020002e-01,\n",
       "        2.55039990e-01, -1.26900002e-01,  6.61360007e-03, -1.13059998e-01,\n",
       "        6.64460003e-01,  3.24259996e-01, -3.37870006e-04,  3.01149994e-01,\n",
       "        1.34540005e-02, -6.42319992e-02, -6.91709965e-02, -5.88729978e-01,\n",
       "       -1.69499993e-01,  4.62810010e-01, -1.17150001e-01, -1.10650003e-01,\n",
       "        2.19090000e-01, -7.74729997e-02, -3.93990010e-01,  5.47190011e-01,\n",
       "       -1.41599998e-01,  3.04060012e-01, -1.06459998e-01,  5.50960004e-01,\n",
       "       -4.97970015e-01,  2.44529992e-02,  8.46660018e-01, -1.40039995e-01,\n",
       "       -1.02320001e-01,  2.36249998e-01, -3.34259987e-01,  3.37060004e-01,\n",
       "        3.47770005e-01, -1.23590000e-01,  5.51769972e-01,  6.51889980e-01,\n",
       "       -4.63719994e-01,  1.78790003e-01, -3.07689995e-01,  6.05409980e-01,\n",
       "        2.92519987e-01, -4.78600003e-02, -4.33750004e-02, -5.05609989e-01,\n",
       "       -1.87490001e-01, -1.24380000e-01,  4.93890010e-02, -2.87750006e-01,\n",
       "        9.45189968e-02,  7.07849979e-01, -3.84310007e-01,  1.35140002e-01,\n",
       "       -7.37690032e-02,  3.90350014e-01, -2.53790002e-02,  5.64120002e-02,\n",
       "        6.59110010e-01,  5.36719978e-01,  2.74940014e-01,  5.94820023e-01,\n",
       "       -3.03499997e-01,  8.07129979e-01,  2.28389993e-01,  1.53569996e-01,\n",
       "       -2.39040002e-01, -1.55699998e-01, -1.44840002e-01, -2.35009998e-01,\n",
       "        9.76430029e-02,  2.81789988e-01, -5.26180029e-01, -3.15499991e-01,\n",
       "        2.29320005e-01, -2.98999995e-02, -1.53239995e-01, -1.04670003e-01,\n",
       "       -3.03130001e-01, -5.68549991e-01,  3.16659987e-01, -2.22609997e-01,\n",
       "       -1.69499993e-01, -6.16240025e-01,  5.20569980e-01,  3.08250010e-01,\n",
       "        6.90620020e-02,  4.49490011e-01, -1.68500006e-01, -2.38309994e-01,\n",
       "       -4.33450013e-01,  5.96149981e-01, -1.15769997e-01, -5.37400007e-01,\n",
       "       -1.41650001e-02,  2.02120006e-01, -2.06530005e-01,  2.88239986e-01,\n",
       "        4.90159988e-01, -1.87490001e-01,  1.14170000e-01,  3.28370005e-01,\n",
       "       -1.68439999e-01,  5.88230006e-02, -9.71159995e-01, -3.93599987e-01,\n",
       "       -2.22220004e-01, -1.52009996e-02,  1.79629996e-01, -5.98829985e-01,\n",
       "        5.72629988e-01, -5.46869993e-01, -5.29969990e-01,  2.04720005e-01,\n",
       "       -2.04550004e+00, -2.07249999e-01,  3.90059985e-02, -5.73849976e-01,\n",
       "        1.17289998e-01, -1.84719995e-01,  2.58280009e-01,  1.12129998e+00,\n",
       "       -1.51129998e-02,  1.32569999e-01,  2.95850009e-01, -8.33540022e-01,\n",
       "       -8.72239992e-02,  1.19980000e-01, -4.23850000e-01,  6.77839994e-01,\n",
       "       -1.65940002e-01, -1.07950002e-01, -1.52390003e-01, -3.53170000e-02,\n",
       "       -5.01820028e-01, -3.30819994e-01,  1.61390007e-01, -7.51050003e-03,\n",
       "        5.08769989e-01, -1.45899996e-01,  7.36669973e-02, -3.74370009e-01,\n",
       "        7.03580022e-01, -4.58900005e-01, -5.08329988e-01, -3.66479993e-01,\n",
       "        1.86920002e-01, -2.87380010e-01,  1.62770003e-01,  8.15919995e-01,\n",
       "        2.76749998e-01, -1.71850007e-02, -1.58099998e-02,  3.07580009e-02,\n",
       "       -1.65549994e-01, -1.25880003e-01,  1.22929998e-01, -5.12780011e-01,\n",
       "       -8.77550021e-02,  2.01539993e-01, -1.42590001e-01,  1.64089993e-01,\n",
       "        5.06980002e-01, -9.55290020e-01, -2.01480001e-01,  4.00389999e-01,\n",
       "        8.30390006e-02, -1.42589998e+00, -8.61580014e-01, -6.97430015e-01,\n",
       "       -3.38979997e-02, -4.07879986e-02,  4.33849990e-01, -1.37280002e-01,\n",
       "        1.72130004e-01, -2.78230011e-03,  1.13899998e-01,  2.38849998e-01,\n",
       "       -4.56419997e-02, -6.38289988e-01,  6.66840017e-01,  1.65629998e-01,\n",
       "        1.85680002e-01, -4.14000005e-01, -4.09700006e-01,  1.36800006e-01,\n",
       "        3.96590009e-02, -3.42390001e-01,  6.04799986e-02,  4.49939996e-01,\n",
       "        1.43429995e-01, -9.16260034e-02,  8.61390010e-02, -6.22770011e-01,\n",
       "       -6.07020020e-01,  2.89830007e-02, -1.17120004e+00,  2.91810006e-01,\n",
       "       -3.46859992e-01,  4.65840012e-01,  3.18549991e-01,  4.48419988e-01,\n",
       "       -4.41100001e-01, -3.64950001e-01,  4.08960015e-01,  9.11059976e-01,\n",
       "        2.03600004e-01, -4.50509995e-01, -1.27999997e-02,  4.42750007e-01,\n",
       "       -8.12069997e-02, -1.78240001e-01, -4.83209997e-01, -2.13780001e-01,\n",
       "       -2.62820005e-01,  2.17259992e-02, -3.72200012e-01, -4.02740002e-01,\n",
       "        4.60920006e-01,  2.09940001e-01, -3.45459998e-01, -5.92929982e-02,\n",
       "        3.38369995e-01,  7.83649981e-01, -3.77319992e-01, -1.87329993e-01,\n",
       "       -2.11180001e-01,  2.82810003e-01, -3.56050014e-01, -4.86559987e-01,\n",
       "        9.39719975e-02,  2.46979997e-01,  4.90350008e-01,  3.88099998e-01,\n",
       "       -2.51210004e-01, -4.98959988e-01,  3.00359994e-01, -3.90630007e-01,\n",
       "       -6.20769978e-01,  7.52179995e-02,  4.33270007e-01, -1.98579997e-01,\n",
       "        5.69939971e-01, -5.61980009e-01, -1.00600004e+00, -6.62180007e-01,\n",
       "        3.63090008e-01,  4.17019986e-02,  1.99870005e-01, -1.15149997e-01,\n",
       "        3.60229999e-01,  2.17899993e-01, -9.43600014e-02, -1.78010002e-01,\n",
       "        2.41620004e-01,  1.19790003e-01, -1.31600007e-01,  2.48609995e-03,\n",
       "        3.87120008e-01, -2.18250006e-01, -2.26950005e-01,  4.01300013e-01,\n",
       "        7.75509998e-02,  1.47579998e-01, -7.04699978e-02,  6.43100023e-01,\n",
       "       -7.78110027e-02, -6.77619994e-01,  3.23210001e-01, -3.44220012e-01,\n",
       "        4.89019990e-01, -5.08520007e-01, -1.98339999e-01, -9.57009971e-01,\n",
       "       -1.98180005e-01,  2.47480005e-01,  2.52640009e-01,  3.53729993e-01,\n",
       "        6.00560009e-01,  5.80909997e-02, -4.78550009e-02,  4.79840010e-01,\n",
       "       -5.37000000e-01, -4.21410007e-03,  2.59909987e-01, -5.16309977e-01,\n",
       "       -5.23549974e-01,  3.37630004e-01,  3.55450004e-01, -8.99540007e-01,\n",
       "       -1.72950000e-01,  1.30290002e-01, -1.37339998e-02,  5.19829988e-01,\n",
       "       -4.32099998e-02,  2.05200002e-01,  2.78369993e-01, -1.62200004e-01,\n",
       "       -1.79340005e-01, -2.89019998e-02,  6.48859963e-02,  7.65540004e-02,\n",
       "       -2.41950005e-01, -3.19000006e-01, -1.62249997e-01, -4.23860013e-01,\n",
       "       -2.09900007e-01, -4.41729985e-02,  2.73820013e-01, -2.75660004e-03,\n",
       "        3.72410007e-02, -9.91519988e-01,  1.69000000e-01, -6.39789999e-02,\n",
       "       -2.05530003e-01,  8.31459999e-01, -2.49990001e-01,  4.31499988e-01,\n",
       "        5.31289995e-01, -2.74170011e-01,  5.98900020e-01, -1.12680003e-01,\n",
       "       -1.62599996e-01, -5.93600012e-02,  8.83979976e-01,  5.43730021e-01,\n",
       "        4.20390010e-01,  5.29699981e-01,  3.14260006e-01,  1.73930004e-01,\n",
       "       -3.34650010e-01,  1.99539997e-02,  4.12079990e-01, -2.78059989e-01,\n",
       "       -1.87279999e-01,  5.46909988e-01,  8.33569989e-02,  2.55329996e-01,\n",
       "        7.08739996e-01,  2.69190013e-01, -4.57459986e-01, -5.24930000e-01,\n",
       "        3.11930001e-01, -3.05790007e-02, -2.52099991e-01, -2.39570007e-01,\n",
       "       -1.17880002e-01,  2.81129986e-01,  2.34420002e-01, -4.58950013e-01,\n",
       "       -5.63870013e-01,  3.57879996e-01,  2.19390005e-01,  1.61320001e-01,\n",
       "       -1.10579997e-01,  2.89039999e-01,  2.57230014e-01,  2.14969993e-01,\n",
       "        6.38530016e-01, -7.93330014e-01,  5.71720004e-01,  5.29659986e-01,\n",
       "        5.92949986e-01,  3.29270005e-01, -1.82119995e-01, -1.52160004e-01,\n",
       "       -1.07900001e-01,  2.44749993e-01, -2.22010002e-01, -6.45990014e-01,\n",
       "       -1.27450004e-03,  7.26710021e-01,  3.73299986e-01, -7.05830008e-02,\n",
       "       -1.96470007e-01,  3.06349993e-01,  1.11839998e+00, -6.83470011e-01,\n",
       "        3.51009995e-01,  7.20809996e-02, -3.33950013e-01,  3.15299988e-01,\n",
       "        7.41320014e-01, -6.54139966e-02,  1.69909999e-01, -5.79060018e-01,\n",
       "        8.51449966e-02,  6.76259995e-01, -1.27839997e-01, -1.96820006e-01,\n",
       "        1.98009998e-01, -3.39729991e-03,  2.01470003e-01, -5.76979995e-01,\n",
       "       -5.18410001e-04, -2.90419996e-01, -3.50760013e-01,  5.48049986e-01,\n",
       "        3.11430007e-01,  1.07680000e-01, -6.19199984e-02,  2.66609997e-01,\n",
       "        1.33760005e-01,  1.92139998e-01, -5.09590030e-01,  5.72919985e-03,\n",
       "       -1.08729994e+00,  5.15789986e-01, -2.75279999e-01, -4.66149986e-01,\n",
       "       -3.95889997e-01,  7.24460006e-01,  2.57169992e-01, -4.26409990e-01,\n",
       "       -1.48860002e+00,  3.51680011e-01, -5.77769987e-02, -2.28660002e-01,\n",
       "       -1.28749996e-01, -4.14669991e-01, -8.50370005e-02,  5.82120001e-01,\n",
       "       -2.97560006e-01,  5.43139994e-01, -1.45310000e-01, -6.84859991e-01,\n",
       "        4.59910005e-01,  2.27610007e-01,  1.02130003e-01, -7.01080024e-01,\n",
       "       -1.80309996e-01,  1.29999995e+00, -6.29350021e-02,  2.28349999e-01,\n",
       "       -3.01580012e-01,  5.32549977e-01, -3.20270002e-01, -3.59429985e-01,\n",
       "       -4.94560003e-01, -4.03109998e-01, -1.19190000e-01, -1.09109998e-01,\n",
       "        5.92419982e-01, -2.91539997e-01, -3.17799985e-01,  1.18749999e-01,\n",
       "       -1.02939999e+00, -1.60980001e-01, -6.10949993e-01,  2.20689997e-01,\n",
       "        1.28079996e-01, -5.45040011e-01,  3.54229994e-02,  5.25099993e-01,\n",
       "        5.99569976e-01,  6.00419998e-01,  1.36480004e-01,  6.44370019e-01,\n",
       "       -4.60539997e-01, -6.51960015e-01,  5.60280025e-01, -5.29870018e-02,\n",
       "       -4.74730015e-01, -6.77850008e-01,  4.01659995e-01, -4.94219989e-01,\n",
       "        4.34839994e-01, -3.28420013e-01, -2.63190001e-01, -6.54039979e-02,\n",
       "        2.07190007e-01,  2.19899997e-01,  1.87490001e-01, -5.41859984e-01,\n",
       "        3.89679998e-01, -5.04239976e-01, -7.21829981e-02, -3.50609988e-01,\n",
       "        1.18260004e-01,  2.02740002e-02, -4.60799992e-01, -1.52089998e-01,\n",
       "        2.75200000e-03, -1.41540006e-01, -3.21880013e-01, -1.76070005e-01,\n",
       "        6.64049983e-01, -1.08439997e-01, -4.17620003e-01, -2.78380007e-01]), gt_embedding=array([-5.18050015e-01, -1.20759998e-02, -1.74119994e-01, -2.81320006e-01,\n",
       "       -8.69149983e-01,  7.25430027e-02, -2.59520006e+00,  9.53190029e-01,\n",
       "        1.82129994e-01,  4.44790006e-01, -6.55490011e-02,  3.84330004e-01,\n",
       "       -4.86900002e-01, -5.14180005e-01,  9.16920006e-02,  6.71130002e-01,\n",
       "        3.95289987e-01, -7.21160024e-02,  6.14489973e-01,  7.21310019e-01,\n",
       "       -1.17459998e-01,  2.47539997e-01, -1.73730001e-01,  4.60680015e-02,\n",
       "       -3.39489996e-01,  4.43800002e-01, -3.30830008e-01, -3.68000001e-01,\n",
       "        3.79000008e-02,  5.68629980e-01, -4.43159997e-01, -4.39460009e-01,\n",
       "        2.48099998e-01,  8.70419979e-01, -2.82260001e-01,  8.61679986e-02,\n",
       "       -3.92010003e-01,  6.54049993e-01, -6.51929975e-02,  9.71869975e-02,\n",
       "        1.97249994e-01,  3.73129994e-01,  3.07599992e-01,  2.45930001e-01,\n",
       "       -2.55820006e-01, -9.82370004e-02, -8.92030001e-02, -9.97309983e-02,\n",
       "       -6.24750018e-01,  1.84560001e-01,  5.48959970e-01, -6.12749994e-01,\n",
       "       -7.58410022e-02, -2.39690006e-01, -8.20720017e-01, -3.34459990e-01,\n",
       "        4.90630008e-02,  2.43959993e-01,  2.46050000e-01, -7.91099966e-02,\n",
       "        1.61070004e-01,  4.07750010e-01, -2.86859989e-01,  1.49320006e-01,\n",
       "        3.19180012e-01,  1.71709999e-01, -1.06780000e-01, -1.91870004e-01,\n",
       "       -7.96210021e-02, -3.48439999e-02, -4.05339986e-01,  2.31810004e-01,\n",
       "        2.88480014e-01,  4.78029996e-01,  3.60399991e-01,  8.49259973e-01,\n",
       "        3.73329991e-03, -4.78399992e-01, -2.17899993e-01,  4.06749994e-01,\n",
       "        1.46610007e-01, -1.29579997e+00, -1.71049997e-01, -1.27719998e+00,\n",
       "       -5.47869980e-01,  2.45399997e-01,  3.96860003e-01,  3.40270013e-01,\n",
       "        1.15599997e-01,  3.37289989e-01, -2.35609993e-01,  1.50529996e-01,\n",
       "       -1.73549995e-01,  2.00000003e-01,  4.96430010e-01, -5.78750014e-01,\n",
       "       -1.40690005e+00, -1.23470001e-01,  5.53740025e-01, -1.00220001e+00,\n",
       "       -7.07319975e-01,  5.53680003e-01, -2.33180001e-02,  7.82729983e-01,\n",
       "        1.99239999e-01,  2.85840005e-01,  2.29389995e-01, -1.70770004e-01,\n",
       "        4.92780000e-01, -9.87830013e-02, -3.44639987e-01,  1.63509995e-01,\n",
       "        1.32750003e-02, -6.03839993e-01, -3.97190005e-01, -7.58690014e-02,\n",
       "       -4.09520008e-02, -1.90919995e-01, -1.61009997e-01,  2.65679993e-02,\n",
       "       -2.70980000e-02, -1.12619996e+00,  1.89879999e-01, -4.95599985e-01,\n",
       "       -1.22970000e-01,  2.80860007e-01,  1.08970001e-01,  4.07090008e-01,\n",
       "        7.68090010e-01, -4.58609998e-01,  8.60399976e-02, -5.24940006e-02,\n",
       "        1.15489997e-01, -2.09919997e-02,  7.87790000e-01,  1.17760003e-01,\n",
       "       -1.37940004e-01,  3.72319996e-01,  1.01489998e-01,  2.39319995e-01,\n",
       "        2.43630007e-01, -4.84100014e-01, -9.65280011e-02, -7.05550015e-02,\n",
       "       -7.05929995e-02,  3.10770005e-01, -2.69050002e-01,  2.93309987e-01,\n",
       "        6.87290013e-01,  1.17660001e-01, -2.21729994e-01, -3.69700007e-02,\n",
       "        1.18780002e-01, -2.94189990e-01, -2.84319997e-01,  1.19779997e-01,\n",
       "       -5.02390005e-02, -7.32019991e-02,  7.19270036e-02, -5.60949981e-01,\n",
       "       -6.49330020e-01,  1.06820002e-01,  2.14550003e-01,  4.10160005e-01,\n",
       "        1.07969999e-01,  1.54860005e-01, -1.06889997e-02, -7.93019962e-03,\n",
       "        6.39750004e-01, -7.11199999e-01,  5.78599989e-01,  7.48860002e-01,\n",
       "        2.57470012e-01,  1.43629998e-01, -3.26359987e-01,  3.78019996e-02,\n",
       "        1.06689997e-01, -6.43979982e-02,  1.32119998e-01, -6.91070020e-01,\n",
       "       -2.72229999e-01,  5.31639993e-01,  3.35209996e-01, -9.43809981e-04,\n",
       "       -1.71900004e-01,  2.21379995e-01,  8.59390020e-01, -5.93750000e-01,\n",
       "       -2.98770010e-01, -6.26349971e-02,  1.20300002e-01,  1.03340000e-01,\n",
       "       -7.54280016e-02, -9.95320007e-02,  2.69930005e-01, -3.14909995e-01,\n",
       "        1.81349993e-01,  4.36470002e-01,  1.68929994e-01, -3.11019987e-01,\n",
       "        3.37159991e-01, -3.08090001e-01, -1.46149993e-01, -7.03170002e-01,\n",
       "        7.79170021e-02,  2.33530000e-01,  8.98310021e-02,  3.57549995e-01,\n",
       "        1.89880002e-02,  2.54779994e-01, -2.75049992e-02,  2.17779994e-01,\n",
       "       -3.76359999e-01,  1.31310001e-01, -8.08369994e-01, -2.38089994e-01,\n",
       "       -8.74189973e-01,  5.63629985e-01, -4.82139997e-02, -8.81810009e-01,\n",
       "       -5.97289979e-01,  4.50470001e-01, -6.73329979e-02, -1.61400005e-01,\n",
       "       -1.50950003e+00, -2.44629994e-01, -3.75030011e-01,  5.93949974e-01,\n",
       "        2.56089985e-01, -3.84829998e-01,  8.86119977e-02,  4.22639996e-01,\n",
       "       -4.45100009e-01,  7.73999989e-01, -5.75730026e-01, -8.61240029e-01,\n",
       "       -9.45639983e-02,  5.13409972e-01, -2.86090001e-02, -1.59590006e-01,\n",
       "       -3.24409992e-01,  7.87829995e-01, -4.04650003e-01,  1.18199997e-01,\n",
       "       -6.90530017e-02,  4.40719992e-01,  4.39239992e-03, -1.13750003e-01,\n",
       "        4.87219989e-02, -3.28170002e-01,  5.16040027e-01, -2.41889998e-01,\n",
       "        3.03559989e-01, -1.74659997e-01, -2.21410006e-01, -1.49269998e-01,\n",
       "       -7.11350024e-01,  1.35040000e-01, -4.20569986e-01,  8.09949994e-01,\n",
       "       -1.40420005e-01, -6.25419974e-01, -4.74909991e-01,  4.11390007e-01,\n",
       "       -9.65300016e-03, -2.51049995e-01,  2.85430014e-01,  6.37220025e-01,\n",
       "       -2.47580007e-01, -6.59550011e-01,  5.68170011e-01,  2.01049998e-01,\n",
       "        7.76169971e-02, -8.28310013e-01, -2.38140002e-02, -3.77499998e-01,\n",
       "        8.01859975e-01, -8.64009976e-01, -1.58739999e-01, -3.17530006e-01,\n",
       "        1.40090004e-01,  3.39599997e-01,  1.76990002e-01, -2.38110006e-01,\n",
       "        4.38730001e-01, -6.77680016e-01, -1.35499999e-01, -2.18309999e-01,\n",
       "        9.68779996e-02, -6.06210008e-02, -2.68420011e-01,  2.33899996e-01,\n",
       "       -1.56379998e-01, -1.00290000e-01,  5.34630008e-02, -6.80719987e-02,\n",
       "        3.97489995e-01,  5.01380004e-02,  1.41389996e-01,  3.97570014e-01]), protected=array([0.901986]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_analogy_dataset, gender_subspace = transform_data(word_vectors, analogy_dataset, use_boluk = False)\n",
    "print(\"Transformed datapoint for the first analogy\")\n",
    "transformed_analogy_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Obtaining the dimensionality of the word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the word embedding : 300\n"
     ]
    }
   ],
   "source": [
    "word_embedding_dim = transformed_analogy_dataset[0].gt_embedding.shape[0]\n",
    "print(\"Dimensions of the word embedding : {}\".format(word_embedding_dim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the dimensions of the transformed analogy dataset components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions of the network input : (900,)\n",
      "Dimensions of the ground-truth embedding : (300,)\n",
      "Dimensions of the ground-truth protected variable : (1,)\n"
     ]
    }
   ],
   "source": [
    "# Testing the transformed analogy dataset\n",
    "assert transformed_analogy_dataset[0].analogy_embeddings.shape[0] == word_embedding_dim * 3\n",
    "assert transformed_analogy_dataset[0].gt_embedding.shape[0] == word_embedding_dim\n",
    "assert transformed_analogy_dataset[0].protected.shape[0] == 1\n",
    "\n",
    "print(\"Dimensions of the network input : {}\".format(transformed_analogy_dataset[0].analogy_embeddings.shape))\n",
    "print(\"Dimensions of the ground-truth embedding : {}\".format(transformed_analogy_dataset[0].gt_embedding.shape))\n",
    "print(\"Dimensions of the ground-truth protected variable : {}\".format(transformed_analogy_dataset[0].protected.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flag to indicate whether you want to use a pre-trained model or you want to train a model from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_pretrained = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case you want to use a pre-trained model, then specify the type of word embeddings upon which the model was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"GNews\" for Google News (Word2Vec)\n",
    "# \"WikipediaVec\" for Wikipedia2Vec\n",
    "# \"Glove\" for Glove vectors\n",
    "\n",
    "word_embedding_type = \"Glove\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case of using a pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_pretrained:\n",
    "    \n",
    "    # Obtaining the saved parameters dictionary\n",
    "    pretrained_parameters = utility_functions.obtain_trained_parameters('models')\n",
    "    \n",
    "    # Obtaining the best weights for the non-debiased model\n",
    "    non_debiased_W1 = pretrained_parameters['non_debiased'][word_embedding_type][\"W1\"]\n",
    "    \n",
    "    # Creating an instance of the non-debiased model\n",
    "    non_debiased_model = AdversarialDebiasing(word_embedding_dim = word_embedding_dim, debias = False)\n",
    "    non_debiased_model.W1 = non_debiased_W1\n",
    "    \n",
    "    # Obtaining the best weights for the debiased model\n",
    "    debiased_W1 = pretrained_parameters['debiased'][word_embedding_type][\"W1\"]\n",
    "    \n",
    "    # Creating an instance of the debiased model\n",
    "    debiased_model = AdversarialDebiasing(word_embedding_dim = word_embedding_dim, debias = True)\n",
    "    debiased_model.W1 = debiased_W1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In case of using a model trained from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not use_pretrained:\n",
    "    \n",
    "    # Best parameters from grid search\n",
    "    best_adversary_loss_weight = 1.0\n",
    "    best_learning_rate = 2 ** -6\n",
    "    \n",
    "    # Creating an instance of the non-debiased model\n",
    "    non_debiased_model = AdversarialDebiasing(word_embedding_dim = word_embedding_dim, num_epochs = 500, debias = False, \\\n",
    "                                             gender_subspace = gender_subspace, batch_size = 256, \\\n",
    "                                              adversary_loss_weight = best_adversary_loss_weight, \\\n",
    "                                             classifier_learning_rate = best_learning_rate, \\\n",
    "                                             adversary_learning_rate = best_learning_rate)\n",
    "    \n",
    "    # Fitting the non-debiased model to the training dataset\n",
    "    print(\"****************** Training the non-debiased model ********************\")\n",
    "    non_debiased_model.fit(dataset = transformed_analogy_dataset)\n",
    "    \n",
    "    # Creating an instance of the debiased model\n",
    "    debiased_model = AdversarialDebiasing(word_embedding_dim = word_embedding_dim, num_epochs = 500, debias = True, \\\n",
    "                                             gender_subspace = gender_subspace, batch_size = 256, \\\n",
    "                                              adversary_loss_weight = best_adversary_loss_weight, \\\n",
    "                                             classifier_learning_rate = best_learning_rate, \\\n",
    "                                             adversary_learning_rate = best_learning_rate)\n",
    "    \n",
    "    Fitting the non-debiased model to the training dataset\n",
    "    print(\"****************** Training the debiased model ********************\")\n",
    "    debiased_model.fit(dataset = transformed_analogy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling memory issues\n",
    "word_vectors.init_sims(replace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Qualitative Evaluation (on some evaluation analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he : doctor :: she : \n",
      "+-------------+--------------+---------------+--------------+\n",
      "| Biased      |       Biased | Debiased      |     Debiased |\n",
      "| Neighbour   |   Similarity | Neighbour     |   Similarity |\n",
      "|-------------+--------------+---------------+--------------|\n",
      "| nurse       |        0.653 | mordrid       |        0.544 |\n",
      "| doctors     |        0.652 | gynecologist  |        0.485 |\n",
      "| physician   |        0.627 | midwife       |        0.48  |\n",
      "| pregnant    |        0.618 | kerish        |        0.467 |\n",
      "| pregnancy   |        0.589 | obstetrician  |        0.464 |\n",
      "| she         |        0.584 | nurse         |        0.462 |\n",
      "| midwife     |        0.568 | pediatrician  |        0.454 |\n",
      "| her         |        0.566 | naturopath    |        0.451 |\n",
      "| patient     |        0.565 | dermatologist |        0.45  |\n",
      "+-------------+--------------+---------------+--------------+\n",
      "he : director :: she : \n",
      "+-------------+--------------+--------------------+--------------+\n",
      "| Biased      |       Biased | Debiased           |     Debiased |\n",
      "| Neighbour   |   Similarity | Neighbour          |   Similarity |\n",
      "|-------------+--------------+--------------------+--------------|\n",
      "| assistant   |        0.642 | co-director        |        0.571 |\n",
      "| julie       |        0.635 | co-artistic        |        0.483 |\n",
      "| executive   |        0.629 | president/creative |        0.474 |\n",
      "| coordinator |        0.625 | co-ordinator       |        0.468 |\n",
      "| associate   |        0.623 | chairwoman         |        0.463 |\n",
      "| susan       |        0.616 | debra              |        0.458 |\n",
      "| directors   |        0.608 | coordinator        |        0.453 |\n",
      "| jennifer    |        0.605 | choreographer      |        0.452 |\n",
      "| directed    |        0.599 | kathryn            |        0.45  |\n",
      "+-------------+--------------+--------------------+--------------+\n",
      "he : intelligent :: she : \n",
      "+---------------+--------------+--------------+--------------+\n",
      "| Biased        |       Biased | Debiased     |     Debiased |\n",
      "| Neighbour     |   Similarity | Neighbour    |   Similarity |\n",
      "|---------------+--------------+--------------+--------------|\n",
      "| smart         |        0.664 | intellegent  |        0.508 |\n",
      "| sophisticated |        0.576 | inteligent   |        0.473 |\n",
      "| thoughtful    |        0.556 | perceptive   |        0.47  |\n",
      "| clever        |        0.553 | well-spoken  |        0.448 |\n",
      "| sensible      |        0.533 | quick-witted |        0.428 |\n",
      "| intuitive     |        0.526 | smart        |        0.428 |\n",
      "| caring        |        0.516 | resourceful  |        0.412 |\n",
      "| energetic     |        0.514 | self-aware   |        0.408 |\n",
      "| witty         |        0.513 | empathetic   |        0.405 |\n",
      "+---------------+--------------+--------------+--------------+\n",
      "he : pilot :: she : \n",
      "+-------------+--------------+--------------+--------------+\n",
      "| Biased      |       Biased | Debiased     |     Debiased |\n",
      "| Neighbour   |   Similarity | Neighbour    |   Similarity |\n",
      "|-------------+--------------+--------------+--------------|\n",
      "| pilots      |        0.592 | u/t          |        0.482 |\n",
      "| aircraft    |        0.521 | pilots       |        0.42  |\n",
      "| airplane    |        0.515 | short-finned |        0.409 |\n",
      "| flight      |        0.513 | iroshizuku   |        0.403 |\n",
      "| program     |        0.496 | hi-tec-c     |        0.401 |\n",
      "| she         |        0.485 | prera        |        0.397 |\n",
      "| helicopter  |        0.478 | piloted      |        0.392 |\n",
      "| flying      |        0.477 | fl400        |        0.389 |\n",
      "| crew        |        0.476 | stewardess   |        0.385 |\n",
      "+-------------+--------------+--------------+--------------+\n",
      "man : woman :: boss : \n",
      "+-------------+--------------+---------------+--------------+\n",
      "| Biased      |       Biased | Debiased      |     Debiased |\n",
      "| Neighbour   |   Similarity | Neighbour     |   Similarity |\n",
      "|-------------+--------------+---------------+--------------|\n",
      "| bosses      |        0.62  | ge-7          |        0.442 |\n",
      "| woman       |        0.56  | bosses        |        0.439 |\n",
      "| wife        |        0.511 | 302r          |        0.438 |\n",
      "| mother      |        0.508 | bossdvd.com   |        0.432 |\n",
      "| husband     |        0.497 | pointy-haired |        0.421 |\n",
      "| girl        |        0.495 | fs-5u         |        0.419 |\n",
      "| wants       |        0.484 | me-25         |        0.415 |\n",
      "| co-worker   |        0.483 | odb-3         |        0.412 |\n",
      "| mom         |        0.482 | metalzone     |        0.41  |\n",
      "+-------------+--------------+---------------+--------------+\n",
      "he : rich :: she : \n",
      "+-------------+--------------+---------------+--------------+\n",
      "| Biased      |       Biased | Debiased      |     Debiased |\n",
      "| Neighbour   |   Similarity | Neighbour     |   Similarity |\n",
      "|-------------+--------------+---------------+--------------|\n",
      "| beautiful   |        0.584 | luscious      |        0.48  |\n",
      "| gorgeous    |        0.582 | couponsliving |        0.469 |\n",
      "| richer      |        0.564 | juzwiak       |        0.421 |\n",
      "| fabulous    |        0.564 | richer        |        0.415 |\n",
      "| wonderful   |        0.564 | velvety       |        0.401 |\n",
      "| incredibly  |        0.553 | nourishing    |        0.393 |\n",
      "| lovely      |        0.552 | puchalsky     |        0.392 |\n",
      "| wealthy     |        0.552 | opulent       |        0.381 |\n",
      "| luscious    |        0.55  | creamy        |        0.38  |\n",
      "+-------------+--------------+---------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# Get sexism traps as word embeddings and words\n",
    "datapoints, test_analogies = qualitative_evaluation.get_datapoints(word_vectors)\n",
    "\n",
    "# Predictions of the non debiased model\n",
    "non_debiased_predictions = qualitative_evaluation.get_non_debiased_predictions(datapoints, word_embedding_dim)\n",
    "non_debiased_most_similar_list = utility_functions.obtain_most_similar(non_debiased_predictions, word_vectors)\n",
    "\n",
    "# Predictions of the debiased model\n",
    "debiased_predictions = debiased_model.predict(datapoints)\n",
    "debiased_most_similar_list = utility_functions.obtain_most_similar(debiased_predictions, word_vectors)\n",
    "\n",
    "# Print similarity results for both models\n",
    "qualitative_evaluation.print_combined_table(non_debiased_most_similar_list, debiased_most_similar_list, test_analogies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
