{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from collections import defaultdict\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from tabulate import tabulate\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from adversarial_debiasing import AdversarialDebiasing\n",
    "from load_data import load_data, transform_data, Datapoint\n",
    "\n",
    "from load_vectors import load_pretrained_vectors, load_vectors\n",
    "import config\n",
    "import utility_functions\n",
    "\n",
    "import gensim\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For autoreloading changes made in other python scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "vector_size300\nLoading2000000 embeddings\nduplicate words detected, shrinking matrix size from %i to %i30000002000000\nloaded %s matrix(2000000, 300)\n"
    }
   ],
   "source": [
    "# Loading the word vectors dictionary\n",
    "# For Wikipedia2Vec - use config.wiki_embedding_data_path and config.wiki_embedding_type\n",
    "# For Glove - use config.glove_embedding_data_path and config.glove_embedding_type\n",
    "# For GoogleNews (Word2Vec) - use config.google_embedding_data_path and config.google_embedding_type\n",
    "\n",
    "word_vectors = load_pretrained_vectors(config.google_embedding_data_path, config.save_dir, config.google_embedding_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Banjul', y='Gambia', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Beijing', y='China', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Beirut', y='Lebanon', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Belgrade', y='Serbia', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Belmopan', y='Belize', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Berlin', y='Germany', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Bern', y='Switzerland', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Bratislava', y='Slovakia', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Brussels', y='Belgium', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Bucharest', y='Romania', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Budapest', y='Hungary', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Bujumbura', y='Burundi', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Cairo', y='Egypt', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Canberra', y='Australia', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Caracas', y='Venezuela', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Chisinau', y='Moldova', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Conakry', y='Guinea', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Copenhagen', y='Denmark', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Dakar', y='Senegal', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Damascus', y='Syria', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Dhaka', y='Bangladesh', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Doha', y='Qatar', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Dublin', y='Ireland', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Funafuti', y='Tuvalu', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Gaborone', y='Botswana', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Georgetown', y='Guyana', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Hanoi', y='Vietnam', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Harare', y='Zimbabwe', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Havana', y='Cuba', task='capital-world'),\n Raw_Datapoint(x1='Ashgabat', x2='Turkmenistan', x3='Helsinki', y='Finland', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Astana', y='Kazakhstan', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Athens', y='Greece', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Baghdad', y='Iraq', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Baku', y='Azerbaijan', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Bamako', y='Mali', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Bangkok', y='Thailand', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Banjul', y='Gambia', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Beijing', y='China', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Beirut', y='Lebanon', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Belgrade', y='Serbia', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Belmopan', y='Belize', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Berlin', y='Germany', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Bern', y='Switzerland', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Bratislava', y='Slovakia', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Brussels', y='Belgium', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Bucharest', y='Romania', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Budapest', y='Hungary', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Bujumbura', y='Burundi', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Cairo', y='Egypt', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Canberra', y='Australia', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Caracas', y='Venezuela', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Chisinau', y='Moldova', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Conakry', y='Guinea', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Copenhagen', y='Denmark', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Dakar', y='Senegal', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Damascus', y='Syria', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Dhaka', y='Bangladesh', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Doha', y='Qatar', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Dublin', y='Ireland', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Funafuti', y='Tuvalu', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Gaborone', y='Botswana', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Georgetown', y='Guyana', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Hanoi', y='Vietnam', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Harare', y='Zimbabwe', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Havana', y='Cuba', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Helsinki', y='Finland', task='capital-world'),\n Raw_Datapoint(x1='Asmara', x2='Eritrea', x3='Islamabad', y='Pakistan', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Athens', y='Greece', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Baghdad', y='Iraq', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Baku', y='Azerbaijan', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Bamako', y='Mali', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Bangkok', y='Thailand', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Banjul', y='Gambia', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Beijing', y='China', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Beirut', y='Lebanon', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Belgrade', y='Serbia', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Belmopan', y='Belize', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Berlin', y='Germany', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Bern', y='Switzerland', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Bratislava', y='Slovakia', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Brussels', y='Belgium', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Bucharest', y='Romania', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Budapest', y='Hungary', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Bujumbura', y='Burundi', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Cairo', y='Egypt', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Canberra', y='Australia', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Caracas', y='Venezuela', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Chisinau', y='Moldova', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Conakry', y='Guinea', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Copenhagen', y='Denmark', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Dakar', y='Senegal', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Damascus', y='Syria', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Dhaka', y='Bangladesh', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Doha', y='Qatar', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Dublin', y='Ireland', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Funafuti', y='Tuvalu', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Gaborone', y='Botswana', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Georgetown', y='Guyana', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Hanoi', y='Vietnam', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Harare', y='Zimbabwe', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Havana', y='Cuba', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Helsinki', y='Finland', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Islamabad', y='Pakistan', task='capital-world'),\n Raw_Datapoint(x1='Astana', x2='Kazakhstan', x3='Jakarta', y='Indonesia', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Baghdad', y='Iraq', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Baku', y='Azerbaijan', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Bamako', y='Mali', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Bangkok', y='Thailand', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Banjul', y='Gambia', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Beijing', y='China', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Beirut', y='Lebanon', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Belgrade', y='Serbia', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Belmopan', y='Belize', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Berlin', y='Germany', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Bern', y='Switzerland', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Bratislava', y='Slovakia', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Brussels', y='Belgium', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Bucharest', y='Romania', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Budapest', y='Hungary', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Bujumbura', y='Burundi', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Cairo', y='Egypt', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Canberra', y='Australia', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Caracas', y='Venezuela', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Chisinau', y='Moldova', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Conakry', y='Guinea', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Copenhagen', y='Denmark', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Dakar', y='Senegal', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Damascus', y='Syria', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Dhaka', y='Bangladesh', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Doha', y='Qatar', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Dublin', y='Ireland', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Funafuti', y='Tuvalu', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Gaborone', y='Botswana', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Georgetown', y='Guyana', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Hanoi', y='Vietnam', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Harare', y='Zimbabwe', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Havana', y='Cuba', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Helsinki', y='Finland', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Islamabad', y='Pakistan', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Jakarta', y='Indonesia', task='capital-world'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Kabul', y='Afghanistan', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Baku', y='Azerbaijan', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bamako', y='Mali', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bangkok', y='Thailand', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Banjul', y='Gambia', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Beijing', y='China', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Beirut', y='Lebanon', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Belgrade', y='Serbia', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Belmopan', y='Belize', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Berlin', y='Germany', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bern', y='Switzerland', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bratislava', y='Slovakia', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Brussels', y='Belgium', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bucharest', y='Romania', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Budapest', y='Hungary', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Bujumbura', y='Burundi', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Cairo', y='Egypt', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Canberra', y='Australia', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Caracas', y='Venezuela', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Chisinau', y='Moldova', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Conakry', y='Guinea', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Copenhagen', y='Denmark', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Dakar', y='Senegal', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Damascus', y='Syria', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Dhaka', y='Bangladesh', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Doha', y='Qatar', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Dublin', y='Ireland', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Dushanbe', y='Tajikistan', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Funafuti', y='Tuvalu', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Gaborone', y='Botswana', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Georgetown', y='Guyana', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Hanoi', y='Vietnam', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Harare', y='Zimbabwe', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Havana', y='Cuba', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Helsinki', y='Finland', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Islamabad', y='Pakistan', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Jakarta', y='Indonesia', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Kabul', y='Afghanistan', task='capital-world'),\n Raw_Datapoint(x1='Baghdad', x2='Iraq', x3='Kampala', y='Uganda', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Bamako', y='Mali', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Bangkok', y='Thailand', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Banjul', y='Gambia', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Beijing', y='China', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Beirut', y='Lebanon', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Belgrade', y='Serbia', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Belmopan', y='Belize', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Berlin', y='Germany', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Bern', y='Switzerland', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Bishkek', y='Kyrgyzstan', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Bratislava', y='Slovakia', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Brussels', y='Belgium', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Bucharest', y='Romania', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Budapest', y='Hungary', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Bujumbura', y='Burundi', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Cairo', y='Egypt', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Canberra', y='Australia', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Caracas', y='Venezuela', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Chisinau', y='Moldova', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Conakry', y='Guinea', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Copenhagen', y='Denmark', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Dakar', y='Senegal', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Damascus', y='Syria', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Dhaka', y='Bangladesh', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Doha', y='Qatar', task='capital-world'),\n Raw_Datapoint(x1='Baku', x2='Azerbaijan', x3='Dublin', y='Ireland', task='capital-world'),\n ...]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the google analogies training dataset:\n",
    "analogy_dataset = load_data()\n",
    "analogy_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the data such that it includes the embeddings of the words in consideration\n",
    "transformed_analogy_dataset, gender_subspace = transform_data(word_vectors, analogy_dataset, use_boluk = False)\n",
    "\n",
    "\n",
    "# Obtaining the dimensionality of the word embeddings\n",
    "word_embedding_dim = transformed_analogy_dataset[0].gt_embedding.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(900,)\n(300,)\n(1,)\n"
    }
   ],
   "source": [
    "# Testing the transformed analogy dataset\n",
    "assert transformed_analogy_dataset[0].analogy_embeddings.shape[0] == word_embedding_dim * 3\n",
    "assert transformed_analogy_dataset[0].gt_embedding.shape[0] == word_embedding_dim\n",
    "assert transformed_analogy_dataset[0].protected.shape[0] == 1\n",
    "\n",
    "print(transformed_analogy_dataset[0].analogy_embeddings.shape)\n",
    "print(transformed_analogy_dataset[0].gt_embedding.shape)\n",
    "print(transformed_analogy_dataset[0].protected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n[0/5] Running epoch\n[1/5] Running epoch\n[2/5] Running epoch\n[3/5] Running epoch\n[4/5] Running epoch\n"
    }
   ],
   "source": [
    "# To run the grid-search and obtain the np.dot(w.T, g) values\n",
    "learning_rate_list = [2 ** -12, 2 ** -6, 2 ** -3]\n",
    "adversary_loss_weight_list = [1.0, 0.5, 0.1]\n",
    "\n",
    "# For the saved model checkpoints pertaining to the word embedding type\n",
    "word_embedding_type = 'GNews'\n",
    "\n",
    "# Performing the grid search\n",
    "utility_functions.grid_search(learning_rate_list, adversary_loss_weight_list, word_embedding_dim, gender_subspace, transformed_analogy_dataset, 'models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Best : [[-0.79155959]]\nLast : [[-0.79155959]]\n"
    }
   ],
   "source": [
    "with open(os.path.join('models', 'debiased', word_embedding_type + \"_\" + str(2 ** -6) + \"_\" + str(1.0) + '.pckl'), 'rb') as f:\n",
    "    best_state_dict = pickle.load(f)\n",
    "\n",
    "with open(os.path.join('models', 'debiased', word_embedding_type + \"_\" + str(2 ** -6) + \"_\" + str(1.0) + '_last.pckl'), 'rb') as f:\n",
    "    last_state_dict = pickle.load(f)\n",
    "\n",
    "debiased_model_best = AdversarialDebiasing(\n",
    "                seed = 42,\n",
    "                word_embedding_dim = word_embedding_dim,\n",
    "                num_epochs = 500,\n",
    "                debias = False,\n",
    "                gender_subspace = gender_subspace,\n",
    "                batch_size = 256,\n",
    "                adversary_loss_weight = 0.1,\n",
    "                classifier_learning_rate = 2 ** -6,\n",
    "                adversary_learning_rate = 2 ** -6\n",
    "            )\n",
    "\n",
    "debiased_model_last = AdversarialDebiasing(\n",
    "                seed = 42,\n",
    "                word_embedding_dim = word_embedding_dim,\n",
    "                num_epochs = 500,\n",
    "                debias = False,\n",
    "                gender_subspace = gender_subspace,\n",
    "                batch_size = 256,\n",
    "                adversary_loss_weight = 0.1,\n",
    "                classifier_learning_rate = 2 ** -6,\n",
    "                adversary_learning_rate = 2 ** -6\n",
    "            )\n",
    "\n",
    "debiased_model_best.W1 = best_state_dict[\"W1\"]\n",
    "debiased_model_best.W2 = best_state_dict[\"W2\"]\n",
    "\n",
    "debiased_model_last.W1 = last_state_dict[\"W1\"]\n",
    "debiased_model_last.W2 = last_state_dict[\"W2\"]\n",
    "\n",
    "print(\"Best : {}\".format(np.dot(debiased_model_best.W1.clone().detach().cpu().numpy().T, gender_subspace.T)))\n",
    "\n",
    "print(\"Last : {}\".format(np.dot(debiased_model_last.W1.clone().detach().cpu().numpy().T, gender_subspace.T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_embedding_dim = transformed_analogy_dataset[0].gt_embedding.shape[0]\n",
    "# Training the variant of the model without debiasing\n",
    "non_debiased_model = AdversarialDebiasing(\n",
    "    word_embedding_dim=word_embedding_dim,\n",
    "    num_epochs=500,\n",
    "    debias=False,\n",
    "    gender_subspace=gender_subspace,\n",
    "    batch_size=256,\n",
    "    adversary_loss_weight=0.1,\n",
    "    classifier_learning_rate = 2 ** -6,\n",
    "    adversary_learning_rate = 2 ** -6\n",
    ")\n",
    "non_debiased_model.fit(dataset=transformed_analogy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = non_debiased_model.get_model_weights()\n",
    "print(np.dot(W1.detach().numpy().T,gender_subspace.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_subspace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the variant of the model with debiasing\n",
    "# debiased_model = AdversarialDebiasing(\n",
    "#     word_embedding_dim=word_embedding_dim,\n",
    "#     num_epochs=500,\n",
    "#     debias=True,\n",
    "#     gender_subspace=gender_subspace,\n",
    "#     batch_size=256,\n",
    "#     adversary_loss_weight=0.1,\n",
    "#     classifier_learning_rate = 2 ** -8,\n",
    "#     adversary_learning_rate = 2 ** -8\n",
    "# )\n",
    "debiased_model = AdversarialDebiasing(\n",
    "    word_embedding_dim=word_embedding_dim,\n",
    "    num_epochs=500,\n",
    "    debias=True,\n",
    "    gender_subspace=gender_subspace,\n",
    "    batch_size=256,\n",
    "    adversary_loss_weight=0.1,\n",
    "    classifier_learning_rate = 2 ** -6,\n",
    "    adversary_learning_rate = 2 ** -6\n",
    ")\n",
    "\n",
    "debiased_model.fit(dataset=transformed_analogy_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = debiased_model.get_model_weights()\n",
    "print(np.dot(W1.clone().cpu().detach().numpy().T,gender_subspace.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples to test the models upon\n",
    "datapoints, test_analogies = [], []\n",
    "with open(os.path.join('data', 'sexism-traps.txt'), 'r') as f:\n",
    "    # Reading each line\n",
    "    for line in f.readlines():\n",
    "        words = line.split()\n",
    "        if words[0] == ':':\n",
    "            continue\n",
    "        test_analogies.append(words)\n",
    "        word_embeddings = word_vectors[words]\n",
    "        word_embeddings = np.reshape(word_embeddings, (1, -1))\n",
    "        datapoints.append(word_embeddings)\n",
    "datapoints = np.vstack(datapoints)\n",
    "print(datapoints.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative evaluation of the non-debiased model\n",
    "\n",
    "# non_debiased_predictions = non_debiased_model.predict(datapoints)\n",
    "features = torch.cat([torch.Tensor(x).unsqueeze_(0) for x in datapoints])\n",
    "x1 = features[:, 0:word_embedding_dim]\n",
    "x2 = features[:, word_embedding_dim:word_embedding_dim * 2]\n",
    "x3 = features[:, word_embedding_dim * 2:word_embedding_dim * 3]\n",
    "\n",
    "non_debiased_predictions = x2 + x3 - x1\n",
    "non_debiased_predictions = non_debiased_predictions.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_debiased_most_similar_list = utility_functions.obtain_most_similar(non_debiased_predictions, word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the similarity list for the non-debiased model\n",
    "non_debiased_most_similar_list_data_frames = []\n",
    "for i in range(len(non_debiased_most_similar_list)):\n",
    "    # print(\"{} : {} :: {} : \".format(test_analogies[i][0], test_analogies[i][1], test_analogies[i][2]))\n",
    "    temp_data_frame = pd.DataFrame(non_debiased_most_similar_list[i][1:], columns = ['Neighbor', 'Similarity'])\n",
    "    non_debiased_most_similar_list_data_frames.append(temp_data_frame)\n",
    "    # print(tabulate(temp_data_frame, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative evaluation of the debiased model\n",
    "debiased_predictions = debiased_model.predict(datapoints)\n",
    "debiased_most_similar_list = utility_functions.obtain_most_similar(debiased_predictions, word_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying the similarity list for the debiased model\n",
    "debiased_most_similar_list_data_frames = []\n",
    "for i in range(len(debiased_most_similar_list)):\n",
    "    # print(\"{} : {} :: {} : \".format(test_analogies[i][0], test_analogies[i][1], test_analogies[i][2]))\n",
    "    temp_data_frame = pd.DataFrame(debiased_most_similar_list[i][1:], columns = ['Neighbor', 'Similarity'])\n",
    "    debiased_most_similar_list_data_frames.append(temp_data_frame)\n",
    "    # print(tabulate(temp_data_frame, headers='keys', tablefmt='psql', showindex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining the dataframes pertaining to both the variants of the model\n",
    "iterables = [['Biased', 'Debiased'], ['Neighbour', 'Similarity']]\n",
    "index = pd.MultiIndex.from_product(iterables)\n",
    "overall_data_frames_list = []\n",
    "for i in range(len(non_debiased_most_similar_list)):\n",
    "    overall_list = []\n",
    "    print(\"{} : {} :: {} : \".format(test_analogies[i][0], test_analogies[i][1], test_analogies[i][2]))\n",
    "    for j in range(1, len(non_debiased_most_similar_list[i])):\n",
    "        temp_list = []\n",
    "        temp_list.append(non_debiased_most_similar_list[i][j][0])\n",
    "        temp_list.append(round(non_debiased_most_similar_list[i][j][1], 3))\n",
    "        temp_list.append(debiased_most_similar_list[i][j][0])\n",
    "        temp_list.append(round(debiased_most_similar_list[i][j][1], 3))\n",
    "        overall_list.append(temp_list)\n",
    "    temp_df = pd.DataFrame(overall_list, columns = index)\n",
    "    # print(temp_df.to_string(index = False))\n",
    "    print(tabulate(temp_df, headers = ['Biased\\nNeighbour', 'Biased\\nSimilarity', 'Debiased\\nNeighbour', 'Debiased\\nSimilarity'], tablefmt = 'psql', showindex = False))\n",
    "    overall_data_frames_list.append(temp_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbasecondab37d419580d64adfa435fa6a50f93de5"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}