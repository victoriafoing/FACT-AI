{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from tabulate import tabulate\n",
    "import re \n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from adversarial_debiasing import AdversarialDebiasing\n",
    "from load_data import load_data, transform_data, Datapoint\n",
    "\n",
    "from load_vectors import load_pretrained_vectors, load_vectors\n",
    "import config\n",
    "import utility_functions\n",
    "import qualitative_evaluation\n",
    "\n",
    "import gensim\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# For autoreloading changes made in other python scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# Loading the word vectors dictionary\n",
    "# For Wikipedia2Vec - use config.wiki_embedding_data_path and config.wiki_embedding_type\n",
    "# For Glove - use config.glove_embedding_data_path and config.glove_embedding_type\n",
    "# For GoogleNews (Word2Vec) - use config.google_embedding_data_path and config.google_embedding_type\n",
    "word_vectors = load_pretrained_vectors(\"Wikipedia2Vec\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Raw_Datapoint(x1='Athens', x2='Greece', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Beijing', y='China', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Berlin', y='Germany', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Bern', y='Switzerland', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Cairo', y='Egypt', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Canberra', y='Australia', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Havana', y='Cuba', task='capital-common-countries'),\n",
       " Raw_Datapoint(x1='Athens', x2='Greece', x3='Helsinki', y='Finland', task='capital-common-countries')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the google analogies training dataset:\n",
    "analogy_dataset = load_data()\n",
    "analogy_dataset[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900,)\n",
      "(300,)\n",
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "# Transform the data such that it includes the embeddings of the words in consideration\n",
    "transformed_analogy_dataset, gender_subspace = transform_data(word_vectors, analogy_dataset, use_boluk = False)\n",
    "\n",
    "\n",
    "# Obtaining the dimensionality of the word embeddings\n",
    "word_embedding_dim = transformed_analogy_dataset[0].gt_embedding.shape[0]\n",
    "\n",
    "# Testing the transformed analogy dataset\n",
    "assert transformed_analogy_dataset[0].analogy_embeddings.shape[0] == word_embedding_dim * 3\n",
    "assert transformed_analogy_dataset[0].gt_embedding.shape[0] == word_embedding_dim\n",
    "assert transformed_analogy_dataset[0].protected.shape[0] == 1\n",
    "\n",
    "print(transformed_analogy_dataset[0].analogy_embeddings.shape)\n",
    "print(transformed_analogy_dataset[0].gt_embedding.shape)\n",
    "print(transformed_analogy_dataset[0].protected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the grid-search and obtain the np.dot(w.T, g) values\n",
    "learning_rate_list = [2 ** -12, 2 ** -6, 2 ** -3]\n",
    "adversary_loss_weight_list = [1.0, 0.5, 0.1]\n",
    "\n",
    "# For the saved model checkpoints pertaining to the word embedding type\n",
    "word_embedding_type = 'GNews'\n",
    "\n",
    "# Performing the grid search\n",
    "utility_functions.grid_search(learning_rate_list, adversary_loss_weight_list, word_embedding_dim, gender_subspace, transformed_analogy_dataset, word_embedding_type, 'models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model_path: Path, word_embedding_dim, gender_subspace):\n",
    "    # with open(str(model_path), \"rb\") as f:\n",
    "    #     state_dict = pickle.load(f)\n",
    "    # device = torch.device('cpu')\n",
    "    # print(model_path)\n",
    "    state_dict = torch.load(str(model_path), map_location=torch.device('cpu'))\n",
    "    model = AdversarialDebiasing(\n",
    "                    seed = 42,\n",
    "                    word_embedding_dim = word_embedding_dim,\n",
    "                    num_epochs = 500,\n",
    "                    debias = False,\n",
    "                    gender_subspace = gender_subspace,\n",
    "                    batch_size = 256,\n",
    "                    adversary_loss_weight = 0.1,\n",
    "                    classifier_learning_rate = 2 ** -6,\n",
    "                    adversary_learning_rate = 2 ** -6\n",
    "                )\n",
    "    \n",
    "    model.W1 = state_dict[\"W1\"]\n",
    "    model.W2 = state_dict[\"W2\"]\n",
    "    \n",
    "    return model\n",
    "\n",
    "debiased_models = defaultdict(list)\n",
    "biased_models = defaultdict(list)\n",
    "\n",
    "\n",
    "ModelResult = namedtuple('ModelResult', ['best_model', 'last_model', 'embedding_type', 'learning_rate', 'adversary_weight', 'debiased'])\n",
    "\n",
    "for model_base_path in [Path('models/debiased'), Path('models/non_debiased')]:\n",
    "    l, debiased = (biased_models, False) if 'non_debiased' in str(model_base_path) else (debiased_models, True)\n",
    "\n",
    "    for model_path in model_base_path.iterdir():\n",
    "        if '_last' in str(model_path):\n",
    "            continue\n",
    "            \n",
    "        m = re.search('^([A-Za-z]+)_([\\d.]+)_([\\d.]+)(_last){0,1}.pckl$', str(model_path.name))\n",
    "        embeddings = m.group(1)\n",
    "        learning_rate = m.group(2)\n",
    "        adversary_weight = m.group(3)\n",
    "        \n",
    "        best_model = load_model(model_path, word_embedding_dim, gender_subspace)\n",
    "        \n",
    "        last_model_path = model_path.parent / f\"{model_path.stem}_last{model_path.suffix}\"\n",
    "        last_model = load_model(last_model_path, word_embedding_dim, gender_subspace)\n",
    "        \n",
    "        \n",
    "        l[embeddings].append(ModelResult(best_model, last_model, embeddings, learning_rate, adversary_weight, debiased))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'Glove': [ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FA8448>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FA8788>, embedding_type='Glove', learning_rate='0.000244140625', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1C31E4988>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1C31E4688>, embedding_type='Glove', learning_rate='0.000244140625', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1C31E4C08>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1C31E4AC8>, embedding_type='Glove', learning_rate='0.000244140625', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6485548>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6485948>, embedding_type='Glove', learning_rate='0.015625', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1C31E4C88>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1C31E49C8>, embedding_type='Glove', learning_rate='0.015625', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6485788>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6485448>, embedding_type='Glove', learning_rate='0.015625', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD61E4C8>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD61ED48>, embedding_type='Glove', learning_rate='0.125', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD61E588>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD61E1C8>, embedding_type='Glove', learning_rate='0.125', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD61ECC8>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD61E608>, embedding_type='Glove', learning_rate='0.125', adversary_weight='1.0', debiased=True)], 'GNews': [ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD61E9C8>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1C31CB108>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD604F08>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD61E8C8>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD61EC08>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD604AC8>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD604F88>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04308B0C8>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04308B048>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04308BA08>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04308B3C8>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04308B188>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04308BD48>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04307DC48>, embedding_type='GNews', learning_rate='0.125', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04307D548>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04307DB48>, embedding_type='GNews', learning_rate='0.125', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04307D348>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04307D708>, embedding_type='GNews', learning_rate='0.125', adversary_weight='1.0', debiased=True)], 'WikipediaVec': [ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04307D848>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04307D0C8>, embedding_type='WikipediaVec', learning_rate='0.000244140625', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04307D608>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A043087388>, embedding_type='WikipediaVec', learning_rate='0.000244140625', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A043087408>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A043087948>, embedding_type='WikipediaVec', learning_rate='0.000244140625', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1C31D4CC8>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1C31D4748>, embedding_type='WikipediaVec', learning_rate='0.015625', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A043087D48>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A043087F08>, embedding_type='WikipediaVec', learning_rate='0.015625', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A043087A08>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A043087C48>, embedding_type='WikipediaVec', learning_rate='0.015625', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A043083C08>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A043083888>, embedding_type='WikipediaVec', learning_rate='0.125', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A0430830C8>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A043083848>, embedding_type='WikipediaVec', learning_rate='0.125', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A043083648>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A043083588>, embedding_type='WikipediaVec', learning_rate='0.125', adversary_weight='1.0', debiased=True)]}) 3\n",
      "defaultdict(<class 'list'>, {'GNews': [ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A0430838C8>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A043083C88>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='0.1', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAA608>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CAD2DB88>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='0.5', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD601048>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CAD1D288>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='1.0', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CAD1D088>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD601208>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='0.1', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD601648>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD6016C8>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='0.5', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1C30A18C8>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1C30A1C48>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='1.0', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAAF08>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAAF48>, embedding_type='GNews', learning_rate='0.125', adversary_weight='0.1', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAAEC8>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAAAC8>, embedding_type='GNews', learning_rate='0.125', adversary_weight='0.5', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAF988>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAFB88>, embedding_type='GNews', learning_rate='0.125', adversary_weight='1.0', debiased=False)], 'WikipediaVec': [ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAFC88>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAFE88>, embedding_type='WikipediaVec', learning_rate='0.000244140625', adversary_weight='0.1', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAFE48>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAFD08>, embedding_type='WikipediaVec', learning_rate='0.000244140625', adversary_weight='0.5', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAF808>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAFF88>, embedding_type='WikipediaVec', learning_rate='0.000244140625', adversary_weight='1.0', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAF648>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FAF508>, embedding_type='WikipediaVec', learning_rate='0.015625', adversary_weight='0.1', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FB49C8>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FB4C08>, embedding_type='WikipediaVec', learning_rate='0.015625', adversary_weight='0.5', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FB4588>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FB4F88>, embedding_type='WikipediaVec', learning_rate='0.015625', adversary_weight='1.0', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FB4388>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FB4C88>, embedding_type='WikipediaVec', learning_rate='0.125', adversary_weight='0.1', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FB48C8>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FB46C8>, embedding_type='WikipediaVec', learning_rate='0.125', adversary_weight='0.5', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FBE648>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FBE988>, embedding_type='WikipediaVec', learning_rate='0.125', adversary_weight='1.0', debiased=False)]}) 2\n",
      "[ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD61E9C8>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1C31CB108>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD604F08>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD61E8C8>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD61EC08>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD604AC8>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1CD604F88>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04308B0C8>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04308B048>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04308BA08>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04308B3C8>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04308B188>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04308BD48>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04307DC48>, embedding_type='GNews', learning_rate='0.125', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04307D548>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04307DB48>, embedding_type='GNews', learning_rate='0.125', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04307D348>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04307D708>, embedding_type='GNews', learning_rate='0.125', adversary_weight='1.0', debiased=True)]\n"
     ]
    }
   ],
   "source": [
    "print(debiased_models, len(debiased_models))\n",
    "print(biased_models, len(biased_models))\n",
    "print(debiased_models['GNews'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.000244140625</th>\n",
       "      <th>0.015625</th>\n",
       "      <th>0.125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.336968</td>\n",
       "      <td>0.723946</td>\n",
       "      <td>17.0963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.339728</td>\n",
       "      <td>-0.25536</td>\n",
       "      <td>-6.16493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.326831</td>\n",
       "      <td>-0.379391</td>\n",
       "      <td>-0.536122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0.000244140625  0.015625     0.125\n",
       "0.1       0.336968  0.723946   17.0963\n",
       "0.5       0.339728  -0.25536  -6.16493\n",
       "1.0       0.326831 -0.379391 -0.536122"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last model\n",
    "learning_rates = list(set(model.learning_rate for models in debiased_models.values() for model in models)) \n",
    "adversary_weights = list(set(model.adversary_weight for models in debiased_models.values() for model in models)) \n",
    "\n",
    "adversary_weights = sorted(adversary_weights)\n",
    "learning_rates = sorted(learning_rates)\n",
    "\n",
    "box_df_debiased = pd.DataFrame([], columns=learning_rates, index=adversary_weights)\n",
    "\n",
    "for model_result in debiased_models['GNews']:\n",
    "    box_df_debiased.loc[model_result.adversary_weight, model_result.learning_rate] = np.dot(model_result.best_model.W1.clone().detach().numpy().T, gender_subspace.T).item()\n",
    "\n",
    "box_df_debiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.000244140625</th>\n",
       "      <th>0.015625</th>\n",
       "      <th>0.125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.00297724</td>\n",
       "      <td>-0.0917036</td>\n",
       "      <td>-0.0926525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.00297724</td>\n",
       "      <td>-0.0917036</td>\n",
       "      <td>-0.0926525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.00297724</td>\n",
       "      <td>-0.0917036</td>\n",
       "      <td>-0.0926525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0.000244140625   0.015625      0.125\n",
       "0.1     0.00297724 -0.0917036 -0.0926525\n",
       "0.5     0.00297724 -0.0917036 -0.0926525\n",
       "1.0     0.00297724 -0.0917036 -0.0926525"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best model\n",
    "box_df_debiased = pd.DataFrame([], columns=learning_rates, index=adversary_weights)\n",
    "\n",
    "for model_result in biased_models['GNews']:\n",
    "    box_df_debiased.loc[model_result.adversary_weight, model_result.learning_rate] = np.dot(model_result.best_model.W1.clone().detach().numpy().T, gender_subspace.T).item()\n",
    "\n",
    "box_df_debiased\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.000244140625</th>\n",
       "      <th>0.015625</th>\n",
       "      <th>0.125</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0.000244140625  0.015625  0.125\n",
       "0.1             0.0       0.0    0.0\n",
       "0.5             0.0       0.0    0.0\n",
       "1.0             0.0       0.0    0.0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "box_df_biased = pd.DataFrame([], columns=learning_rates, index=adversary_weights)\n",
    "\n",
    "for model_result in debiased_models:\n",
    "    box_df_biased.loc[model_result.adversary_weight, model_result.learning_rate] = np.dot(model_result.last_model.W1.clone().detach().numpy().T, gender_subspace).item()\n",
    "\n",
    "box_df_biased\n",
    "\n",
    "\n",
    "\n",
    "# debiased_model_best.W1 = best_state_dict[\"W1\"]\n",
    "# debiased_model_best.W2 = best_state_dict[\"W2\"]\n",
    "# debiased_model_last.W1 = last_state_dict[\"W1\"]\n",
    "# debiased_model_last.W2 = last_state_dict[\"W2\"]\n",
    "# \n",
    "# print(\"Best : {}\".format(np.dot(debiased_model_best.W1.clone().detach().cpu().numpy().T, gender_subspace.T)))\n",
    "# \n",
    "# print(\"Last : {}\".format(np.dot(debiased_model_last.W1.clone().detach().cpu().numpy().T, gender_subspace.T)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FB4308>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D6FB4FC8>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='0.1', debiased=True)\n",
      "ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A04309DBC8>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x000001A1D8192B48>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='0.1', debiased=False)\n"
     ]
    }
   ],
   "source": [
    "lr = '0.000244140625'\n",
    "debiased_model_result = [m for m in debiased_models['GNews'] if m.learning_rate == lr and m.adversary_weight == '0.1'][0]\n",
    "print(debiased_model_result)\n",
    "debiased_model = debiased_model_result.best_model\n",
    "biased_model_result = [m for m in biased_models['GNews'] if m.learning_rate == lr and m.adversary_weight == '0.1'][0]\n",
    "print(biased_model_result)\n",
    "biased_model = biased_model_result.best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Qualitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "he : strong :: she : \n",
      "+-------------+--------------+-------------+--------------+\n",
      "| Biased      |       Biased | Debiased    |     Debiased |\n",
      "| Neighbour   |   Similarity | Neighbour   |   Similarity |\n",
      "|-------------+--------------+-------------+--------------|\n",
      "| robust      |        0.492 | robust      |        0.504 |\n",
      "| stong       |        0.48  | stong       |        0.498 |\n",
      "| solid       |        0.46  | solid       |        0.488 |\n",
      "| stronger    |        0.453 | stronger    |        0.476 |\n",
      "| weak        |        0.445 | strongest   |        0.457 |\n",
      "| strongest   |        0.438 | weak        |        0.449 |\n",
      "| Strong      |        0.432 | Strong      |        0.447 |\n",
      "| perky       |        0.384 | STRONG      |        0.388 |\n",
      "| buoyant     |        0.381 | resilient   |        0.385 |\n",
      "+-------------+--------------+-------------+--------------+\n",
      "he : boss :: she : \n",
      "+---------------------------+--------------+---------------------------+--------------+\n",
      "| Biased                    |       Biased | Debiased                  |     Debiased |\n",
      "| Neighbour                 |   Similarity | Neighbour                 |   Similarity |\n",
      "|---------------------------+--------------+---------------------------+--------------|\n",
      "| bosses                    |        0.529 | bosses                    |        0.539 |\n",
      "| Kym_Marsh                 |        0.514 | Kym_Marsh                 |        0.506 |\n",
      "| manageress                |        0.507 | Corrie_babe               |        0.505 |\n",
      "| Corrie_babe               |        0.499 | Bev_Callard               |        0.485 |\n",
      "| Coronation_Street_actress |        0.494 | Jane_Danson               |        0.478 |\n",
      "| Jane_Danson               |        0.489 | manageress                |        0.473 |\n",
      "| Manageress                |        0.483 | Coronation_Street_actress |        0.47  |\n",
      "| stepmum                   |        0.48  | Vicky_Entwistle           |        0.469 |\n",
      "| Vicky_Entwistle           |        0.479 | Danielle_Lineker          |        0.466 |\n",
      "+---------------------------+--------------+---------------------------+--------------+\n",
      "he : company :: she : \n",
      "+------------------------+--------------+-----------------+--------------+\n",
      "| Biased                 |       Biased | Debiased        |     Debiased |\n",
      "| Neighbour              |   Similarity | Neighbour       |   Similarity |\n",
      "|------------------------+--------------+-----------------+--------------|\n",
      "| companies              |        0.476 | companies       |        0.479 |\n",
      "| Carol_Hively_Walgreens |        0.463 | compay          |        0.466 |\n",
      "| compay                 |        0.461 | companys        |        0.457 |\n",
      "| Linda_McGillen         |        0.455 | Linda_McGillen  |        0.454 |\n",
      "| Jani_Strand            |        0.452 | Jafra_Cosmetics |        0.453 |\n",
      "| com_pany               |        0.452 | Dana_Lengkeek   |        0.45  |\n",
      "| ClubJenna              |        0.449 | comapny         |        0.449 |\n",
      "| Jafra_Cosmetics        |        0.446 | com_pany        |        0.445 |\n",
      "| Park_Seong_ae          |        0.445 | Heidi_Magyar    |        0.438 |\n",
      "+------------------------+--------------+-----------------+--------------+\n",
      "he : athletic :: she : \n",
      "+--------------------------+--------------+--------------------------+--------------+\n",
      "| Biased                   |       Biased | Debiased                 |     Debiased |\n",
      "| Neighbour                |   Similarity | Neighbour                |   Similarity |\n",
      "|--------------------------+--------------+--------------------------+--------------|\n",
      "| athletics                |        0.63  | athletics                |        0.624 |\n",
      "| athletic_director        |        0.508 | atheltic                 |        0.516 |\n",
      "| atheltic                 |        0.507 | athletic_director        |        0.502 |\n",
      "| softball                 |        0.506 | basketball               |        0.491 |\n",
      "| volleyball               |        0.497 | intercollegiate_athletic |        0.479 |\n",
      "| intercollegiate_athletic |        0.495 | softball                 |        0.477 |\n",
      "| basketball               |        0.492 | Athletic_Director        |        0.476 |\n",
      "| gymnastics               |        0.491 | volleyball               |        0.469 |\n",
      "| Athletic_Director        |        0.478 | gymnastics               |        0.463 |\n",
      "+--------------------------+--------------+--------------------------+--------------+\n",
      "he : doctor :: she : \n",
      "+--------------------+--------------+--------------------+--------------+\n",
      "| Biased             |       Biased | Debiased           |     Debiased |\n",
      "| Neighbour          |   Similarity | Neighbour          |   Similarity |\n",
      "|--------------------+--------------+--------------------+--------------|\n",
      "| nurse              |        0.656 | gynecologist       |        0.626 |\n",
      "| gynecologist       |        0.649 | nurse_practitioner |        0.592 |\n",
      "| nurse_practitioner |        0.626 | nurse              |        0.592 |\n",
      "| midwife            |        0.602 | pediatrician       |        0.567 |\n",
      "| pediatrician       |        0.597 | doctors            |        0.563 |\n",
      "| dermatologist      |        0.56  | midwife            |        0.563 |\n",
      "| ob_gyn             |        0.557 | ob_gyn             |        0.557 |\n",
      "| pharmacist         |        0.553 | physician          |        0.556 |\n",
      "| obstetrician       |        0.553 | dermatologist      |        0.543 |\n",
      "+--------------------+--------------+--------------------+--------------+\n",
      "he : leader :: she : \n",
      "+------------------------+--------------+------------------------+--------------+\n",
      "| Biased                 |       Biased | Debiased               |     Debiased |\n",
      "| Neighbour              |   Similarity | Neighbour              |   Similarity |\n",
      "|------------------------+--------------+------------------------+--------------|\n",
      "| chairwoman             |        0.483 | chairwoman             |        0.469 |\n",
      "| businesswoman          |        0.43  | Leader                 |        0.422 |\n",
      "| Leader                 |        0.409 | leadership             |        0.417 |\n",
      "| Chairwoman             |        0.398 | chairperson            |        0.396 |\n",
      "| Eldest_daughter        |        0.397 | Chairwoman             |        0.392 |\n",
      "| chairperson            |        0.395 | leaders                |        0.385 |\n",
      "| leadership             |        0.394 | businesswoman          |        0.384 |\n",
      "| leader_Rosa_Otunbayeva |        0.392 | leader_Rosa_Otunbayeva |        0.383 |\n",
      "| Cushman_Titus          |        0.391 | stateswoman            |        0.377 |\n",
      "+------------------------+--------------+------------------------+--------------+\n",
      "he : director :: she : \n",
      "+--------------------+--------------+--------------------+--------------+\n",
      "| Biased             |       Biased | Debiased           |     Debiased |\n",
      "| Neighbour          |   Similarity | Neighbour          |   Similarity |\n",
      "|--------------------+--------------+--------------------+--------------|\n",
      "| chairwoman         |        0.661 | chairwoman         |        0.65  |\n",
      "| coordinator        |        0.627 | coordinator        |        0.637 |\n",
      "| Executive_Director |        0.568 | Executive_Director |        0.59  |\n",
      "| co_ordinator       |        0.546 | vice_president     |        0.566 |\n",
      "| chairperson        |        0.543 | co_ordinator       |        0.556 |\n",
      "| vice_president     |        0.541 | Director           |        0.553 |\n",
      "| Associate_Director |        0.537 | vp                 |        0.551 |\n",
      "| Director           |        0.535 | Associate_Director |        0.549 |\n",
      "| direc_tor          |        0.53  | chairperson        |        0.546 |\n",
      "+--------------------+--------------+--------------------+--------------+\n",
      "he : rich :: she : \n",
      "+---------------------------+--------------+---------------------------+--------------+\n",
      "| Biased                    |       Biased | Debiased                  |     Debiased |\n",
      "| Neighbour                 |   Similarity | Neighbour                 |   Similarity |\n",
      "|---------------------------+--------------+---------------------------+--------------|\n",
      "| friend_Francie_Vos        |        0.51  | friend_Francie_Vos        |        0.499 |\n",
      "| Melamine_nitrogen         |        0.469 | richer                    |        0.488 |\n",
      "| Grace_Gina_Mantegna       |        0.456 | Melamine_nitrogen         |        0.463 |\n",
      "| richer                    |        0.45  | wealthy                   |        0.447 |\n",
      "| wealthy                   |        0.446 | Autonomy_Virage_visionary |        0.428 |\n",
      "| Scicasts_Resource_Library |        0.438 | richness                  |        0.425 |\n",
      "| Autonomy_Virage_visionary |        0.425 | Scicasts_Resource_Library |        0.425 |\n",
      "| kissable_lips             |        0.414 | kissable_lips             |        0.419 |\n",
      "| heiresses                 |        0.414 | Grace_Gina_Mantegna       |        0.418 |\n",
      "+---------------------------+--------------+---------------------------+--------------+\n",
      "he : pilot :: she : \n",
      "+--------------------+--------------+-------------------+--------------+\n",
      "| Biased             |       Biased | Debiased          |     Debiased |\n",
      "| Neighbour          |   Similarity | Neighbour         |   Similarity |\n",
      "|--------------------+--------------+-------------------+--------------|\n",
      "| flight_attendant   |        0.479 | pilots            |        0.469 |\n",
      "| Pilot              |        0.473 | Pilot             |        0.454 |\n",
      "| pilots             |        0.461 | Wash_Alan_Tudyk   |        0.451 |\n",
      "| relaxed_el_Amruni  |        0.458 | flight_attendant  |        0.447 |\n",
      "| Wash_Alan_Tudyk    |        0.457 | Cathy_Bossi       |        0.447 |\n",
      "| Curt_Piercy        |        0.449 | relaxed_el_Amruni |        0.447 |\n",
      "| Aileen_McGlynn     |        0.448 | Aileen_McGlynn    |        0.446 |\n",
      "| airline_stewardess |        0.446 | aborts_landing    |        0.418 |\n",
      "| Cathy_Bossi        |        0.444 | piloting          |        0.417 |\n",
      "+--------------------+--------------+-------------------+--------------+\n",
      "he : captain :: she : \n",
      "+-----------------+--------------+--------------+--------------+\n",
      "| Biased          |       Biased | Debiased     |     Debiased |\n",
      "| Neighbour       |   Similarity | Neighbour    |   Similarity |\n",
      "|-----------------+--------------+--------------+--------------|\n",
      "| captian         |        0.525 | captian      |        0.555 |\n",
      "| captains        |        0.521 | captains     |        0.553 |\n",
      "| netballer       |        0.488 | skipper      |        0.493 |\n",
      "| skipper         |        0.486 | Di_Alagich   |        0.467 |\n",
      "| de_Zwager       |        0.476 | Hockeyroo    |        0.464 |\n",
      "| Hockeyroo       |        0.472 | Lizzy_Igasan |        0.461 |\n",
      "| Eldest_daughter |        0.463 | captained    |        0.46  |\n",
      "| yachtswoman     |        0.463 | Karen_Rolton |        0.453 |\n",
      "| Netballer       |        0.462 | netballer    |        0.452 |\n",
      "+-----------------+--------------+--------------+--------------+\n",
      "he : president :: she : \n",
      "+--------------------+--------------+--------------------+--------------+\n",
      "| Biased             |       Biased | Debiased           |     Debiased |\n",
      "| Neighbour          |   Similarity | Neighbour          |   Similarity |\n",
      "|--------------------+--------------+--------------------+--------------|\n",
      "| chairwoman         |        0.606 | President          |        0.602 |\n",
      "| President          |        0.581 | chairwoman         |        0.595 |\n",
      "| chairperson        |        0.546 | chairperson        |        0.551 |\n",
      "| vice_president     |        0.504 | vice_president     |        0.53  |\n",
      "| Executive_Director |        0.499 | Executive_Director |        0.523 |\n",
      "| Chairwoman         |        0.498 | executive          |        0.505 |\n",
      "| Vice_President     |        0.488 | Vice_President     |        0.504 |\n",
      "| Chairperson        |        0.485 | Chairwoman         |        0.494 |\n",
      "| executive          |        0.481 | copresident        |        0.488 |\n",
      "+--------------------+--------------+--------------------+--------------+\n",
      "he : power :: she : \n",
      "+-----------------------+--------------+-----------------------+--------------+\n",
      "| Biased                |       Biased | Debiased              |     Debiased |\n",
      "| Neighbour             |   Similarity | Neighbour             |   Similarity |\n",
      "|-----------------------+--------------+-----------------------+--------------|\n",
      "| electricity           |        0.451 | Power                 |        0.453 |\n",
      "| Power                 |        0.447 | electricity           |        0.443 |\n",
      "| Lorie_Kessler         |        0.393 | POWER                 |        0.392 |\n",
      "| utility_Zesa_Holdings |        0.389 | Conscientiously_wield |        0.391 |\n",
      "| NTSB_Airliner_engines |        0.386 | electricy             |        0.385 |\n",
      "| Concentrated_solar    |        0.386 | Lorie_Kessler         |        0.383 |\n",
      "| Dorothy_Bracken       |        0.386 | Concentrated_solar    |        0.383 |\n",
      "| Guynn_Savage          |        0.386 | Guynn_Savage          |        0.378 |\n",
      "| cable_splices         |        0.384 | Sostanj_coal_fired    |        0.378 |\n",
      "+-----------------------+--------------+-----------------------+--------------+\n",
      "he : rational :: she : \n",
      "+-----------------+--------------+-----------------+--------------+\n",
      "| Biased          |       Biased | Debiased        |     Debiased |\n",
      "| Neighbour       |   Similarity | Neighbour       |   Similarity |\n",
      "|-----------------+--------------+-----------------+--------------|\n",
      "| irrational      |        0.505 | rationality     |        0.512 |\n",
      "| rationality     |        0.504 | irrational      |        0.509 |\n",
      "| rationally      |        0.504 | rationally      |        0.506 |\n",
      "| rational_beings |        0.461 | rational_beings |        0.474 |\n",
      "| Dear_Worried    |        0.458 | sensible        |        0.467 |\n",
      "| sensible        |        0.45  | sane            |        0.461 |\n",
      "| pathologize     |        0.445 | sane_rational   |        0.459 |\n",
      "| sane            |        0.441 | Dear_Worried    |        0.456 |\n",
      "| sane_rational   |        0.44  | pathologize     |        0.451 |\n",
      "+-----------------+--------------+-----------------+--------------+\n",
      "he : confident :: she : \n",
      "+-----------------------+--------------+-----------------------+--------------+\n",
      "| Biased                |       Biased | Debiased              |     Debiased |\n",
      "| Neighbour             |   Similarity | Neighbour             |   Similarity |\n",
      "|-----------------------+--------------+-----------------------+--------------|\n",
      "| hopeful               |        0.511 | hopeful               |        0.522 |\n",
      "| optimistic            |        0.503 | optimistic            |        0.519 |\n",
      "| cautiously_optimistic |        0.5   | cautiously_optimistic |        0.515 |\n",
      "| pleased               |        0.462 | pleased               |        0.474 |\n",
      "| thrilled              |        0.46  | thrilled              |        0.472 |\n",
      "| convinced             |        0.452 | excited               |        0.464 |\n",
      "| excited               |        0.449 | convinced             |        0.464 |\n",
      "| guardedly_optimistic  |        0.443 | guardedly_optimistic  |        0.453 |\n",
      "| delighted             |        0.439 | delighted             |        0.45  |\n",
      "+-----------------------+--------------+-----------------------+--------------+\n",
      "he : hard :: she : \n",
      "+-------------+--------------+----------------------+--------------+\n",
      "| Biased      |       Biased | Debiased             |     Debiased |\n",
      "| Neighbour   |   Similarity | Neighbour            |   Similarity |\n",
      "|-------------+--------------+----------------------+--------------|\n",
      "| harder      |        0.497 | harder               |        0.53  |\n",
      "| she         |        0.444 | Hard                 |        0.464 |\n",
      "| Hard        |        0.441 | difficult            |        0.463 |\n",
      "| difficult   |        0.43  | tough                |        0.459 |\n",
      "| tough       |        0.42  | hardest              |        0.416 |\n",
      "| her         |        0.414 | she                  |        0.394 |\n",
      "| hardest     |        0.398 | SERENA_WILLIAMS_Yeah |        0.389 |\n",
      "| bangin_bod  |        0.392 | skinny_waif          |        0.383 |\n",
      "| Analeigh    |        0.391 | HARD                 |        0.379 |\n",
      "+-------------+--------------+----------------------+--------------+\n",
      "he : relaxed :: she : \n",
      "+-------------------+--------------+-------------------+--------------+\n",
      "| Biased            |       Biased | Debiased          |     Debiased |\n",
      "| Neighbour         |   Similarity | Neighbour         |   Similarity |\n",
      "|-------------------+--------------+-------------------+--------------|\n",
      "| relaxing          |        0.523 | relaxing          |        0.519 |\n",
      "| relax             |        0.487 | relax             |        0.504 |\n",
      "| ladylike          |        0.463 | comfortable       |        0.46  |\n",
      "| effortlessly_chic |        0.462 | looser            |        0.459 |\n",
      "| demure            |        0.459 | ladylike          |        0.458 |\n",
      "| princessy         |        0.452 | demure            |        0.457 |\n",
      "| she               |        0.448 | Relaxed           |        0.451 |\n",
      "| floral_frock      |        0.447 | princessy         |        0.449 |\n",
      "| perky             |        0.446 | effortlessly_chic |        0.447 |\n",
      "+-------------------+--------------+-------------------+--------------+\n",
      "he : cry :: she : \n",
      "+---------------------+--------------+---------------------+--------------+\n",
      "| Biased              |       Biased | Debiased            |     Debiased |\n",
      "| Neighbour           |   Similarity | Neighbour           |   Similarity |\n",
      "|---------------------+--------------+---------------------+--------------|\n",
      "| crying              |        0.544 | crying              |        0.557 |\n",
      "| cries               |        0.524 | cries               |        0.537 |\n",
      "| nurse_Lalitha_Gujar |        0.514 | nurse_Lalitha_Gujar |        0.51  |\n",
      "| sob                 |        0.483 | scream              |        0.492 |\n",
      "| spoons_powdered     |        0.479 | weep                |        0.487 |\n",
      "| bawling             |        0.476 | sob                 |        0.48  |\n",
      "| cry_hysterically    |        0.474 | bawling             |        0.479 |\n",
      "| weep                |        0.471 | spoons_powdered     |        0.478 |\n",
      "| pompom_fiasco       |        0.462 | cried               |        0.466 |\n",
      "+---------------------+--------------+---------------------+--------------+\n",
      "he : brave :: she : \n",
      "+-------------------+--------------+-------------+--------------+\n",
      "| Biased            |       Biased | Debiased    |     Debiased |\n",
      "| Neighbour         |   Similarity | Neighbour   |   Similarity |\n",
      "|-------------------+--------------+-------------+--------------|\n",
      "| courageous        |        0.562 | courageous  |        0.577 |\n",
      "| bravely           |        0.488 | bravest     |        0.491 |\n",
      "| bravest           |        0.476 | bravely     |        0.489 |\n",
      "| sexy_sassy        |        0.451 | sexy_sassy  |        0.453 |\n",
      "| brave_souls       |        0.446 | valiant     |        0.444 |\n",
      "| Sally_Dynevor     |        0.437 | brave_souls |        0.436 |\n",
      "| Chihuahua_Bruiser |        0.436 | courage     |        0.436 |\n",
      "| heroine           |        0.435 | ballsy      |        0.431 |\n",
      "| valiant           |        0.433 | gallant     |        0.426 |\n",
      "+-------------------+--------------+-------------+--------------+\n",
      "he : intelligent :: she : \n",
      "+------------------------+--------------+------------------------+--------------+\n",
      "| Biased                 |       Biased | Debiased               |     Debiased |\n",
      "| Neighbour              |   Similarity | Neighbour              |   Similarity |\n",
      "|------------------------+--------------+------------------------+--------------|\n",
      "| WHAT_MAKES_HER_SPECIAL |        0.467 | smart                  |        0.468 |\n",
      "| vivacious              |        0.457 | socially_adept         |        0.455 |\n",
      "| she'sa                 |        0.456 | WHAT_MAKES_HER_SPECIAL |        0.451 |\n",
      "| bossy                  |        0.45  | bossy                  |        0.451 |\n",
      "| wheelchair_TAO         |        0.444 | she'sa                 |        0.446 |\n",
      "| socially_adept         |        0.444 | sexy_sassy             |        0.445 |\n",
      "| perky_blond            |        0.442 | wheelchair_TAO         |        0.444 |\n",
      "| sexy_sassy             |        0.44  | vivacious              |        0.441 |\n",
      "| everywoman             |        0.435 | Rufus_Johnstone        |        0.441 |\n",
      "+------------------------+--------------+------------------------+--------------+\n",
      "he : ambitious :: she : \n",
      "+----------------------+--------------+-------------------------+--------------+\n",
      "| Biased               |       Biased | Debiased                |     Debiased |\n",
      "| Neighbour            |   Similarity | Neighbour               |   Similarity |\n",
      "|----------------------+--------------+-------------------------+--------------|\n",
      "| Ambitious            |        0.542 | Ambitious               |        0.557 |\n",
      "| black_sequined_bras  |        0.533 | black_sequined_bras     |        0.538 |\n",
      "| floundered_Mercado   |        0.51  | floundered_Mercado      |        0.5   |\n",
      "| swifter_glossier     |        0.499 | swifter_glossier        |        0.498 |\n",
      "| Dianna_Agron_Quinn   |        0.492 | overly_ambitious        |        0.492 |\n",
      "| local_teen_determ    |        0.482 | Dianna_Agron_Quinn      |        0.48  |\n",
      "| overly_ambitious     |        0.472 | local_teen_determ       |        0.466 |\n",
      "| Teen_Sells_Bracelets |        0.454 | Wazzani_Fortress_resort |        0.454 |\n",
      "| commoner_marrying    |        0.452 | Teen_Sells_Bracelets    |        0.447 |\n",
      "+----------------------+--------------+-------------------------+--------------+\n",
      "man : woman :: boss : \n",
      "+---------------------------+--------------+-------------+--------------+\n",
      "| Biased                    |       Biased | Debiased    |     Debiased |\n",
      "| Neighbour                 |   Similarity | Neighbour   |   Similarity |\n",
      "|---------------------------+--------------+-------------+--------------|\n",
      "| bosses                    |        0.551 | bosses      |        0.557 |\n",
      "| manageress                |        0.493 | exec        |        0.474 |\n",
      "| exec                      |        0.458 | supremo     |        0.466 |\n",
      "| Manageress                |        0.457 | head_honcho |        0.463 |\n",
      "| receptionist              |        0.451 | manageress  |        0.463 |\n",
      "| Jane_Danson               |        0.444 | honcho      |        0.437 |\n",
      "| Fiz_Jennie_McAlpine       |        0.441 | Jane_Danson |        0.431 |\n",
      "| Coronation_Street_actress |        0.44  | Manageress  |        0.431 |\n",
      "| coworker                  |        0.439 | Sandeesh    |        0.43  |\n",
      "+---------------------------+--------------+-------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get sexism traps as word embeddings and words\n",
    "datapoints, test_analogies = qualitative_evaluation.get_datapoints(word_vectors)\n",
    "\n",
    "# Predictions of the non debiased model\n",
    "non_debiased_predictions = biased_model.predict(datapoints)\n",
    "non_debiased_most_similar_list = utility_functions.obtain_most_similar(non_debiased_predictions, word_vectors)\n",
    "\n",
    "# Predictions of the debiased model\n",
    "debiased_predictions = debiased_model.predict(datapoints)\n",
    "debiased_most_similar_list = utility_functions.obtain_most_similar(debiased_predictions, word_vectors)\n",
    "\n",
    "# Print similarity results for both models\n",
    "qualitative_evaluation.print_combined_table(non_debiased_most_similar_list, debiased_most_similar_list, test_analogies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
