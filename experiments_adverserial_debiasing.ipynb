{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "[autoreload of load_vectors failed: Traceback (most recent call last):\n",
      "  File \"/home/max/anaconda3/envs/fact/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 245, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/max/anaconda3/envs/fact/lib/python3.7/site-packages/IPython/extensions/autoreload.py\", line 394, in superreload\n",
      "    module = reload(module)\n",
      "  File \"/home/max/anaconda3/envs/fact/lib/python3.7/imp.py\", line 314, in reload\n",
      "    return importlib.reload(module)\n",
      "  File \"/home/max/anaconda3/envs/fact/lib/python3.7/importlib/__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 630, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/home/max/develop/master_develop/FACT-AI/load_vectors.py\", line 8, in <module>\n",
      "    import wget\n",
      "ModuleNotFoundError: No module named 'wget'\n",
      "]\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "from tabulate import tabulate\n",
    "import re \n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from adversarial_debiasing import AdversarialDebiasing\n",
    "from load_data import load_data, transform_data, Datapoint\n",
    "\n",
    "from load_vectors import load_pretrained_vectors, load_vectors\n",
    "import config\n",
    "import utility_functions\n",
    "import qualitative_evaluation\n",
    "\n",
    "import gensim\n",
    "import gzip\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "# For autoreloading changes made in other python scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-08653ffbf64b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# For Glove - use config.glove_embedding_data_path and config.glove_embedding_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# For GoogleNews (Word2Vec) - use config.google_embedding_data_path and config.google_embedding_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_pretrained_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoogle_embedding_data_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgoogle_embedding_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/develop/master_develop/FACT-AI/load_vectors.py\u001b[0m in \u001b[0;36mload_pretrained_vectors\u001b[0;34m(data_path, savedir, embedding_type)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0membedding_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'google'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m                 \u001b[0mword_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutility_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_num_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/GoogleNews-vectors-negative300.bin.gz'"
     ],
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/GoogleNews-vectors-negative300.bin.gz'",
     "output_type": "error"
    }
   ],
   "source": [
    "# Loading the word vectors dictionary\n",
    "# For Wikipedia2Vec - use config.wiki_embedding_data_path and config.wiki_embedding_type\n",
    "# For Glove - use config.glove_embedding_data_path and config.glove_embedding_type\n",
    "# For GoogleNews (Word2Vec) - use config.google_embedding_data_path and config.google_embedding_type\n",
    "word_vectors = load_pretrained_vectors(config.google_embedding_data_path, config.save_dir, config.google_embedding_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[Raw_Datapoint(x1='Athens', x2='Greece', x3='Baghdad', y='Iraq', task='capital-common-countries'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Bangkok', y='Thailand', task='capital-common-countries'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Beijing', y='China', task='capital-common-countries'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Berlin', y='Germany', task='capital-common-countries'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Bern', y='Switzerland', task='capital-common-countries'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Cairo', y='Egypt', task='capital-common-countries'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Canberra', y='Australia', task='capital-common-countries'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Hanoi', y='Vietnam', task='capital-common-countries'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Havana', y='Cuba', task='capital-common-countries'),\n Raw_Datapoint(x1='Athens', x2='Greece', x3='Helsinki', y='Finland', task='capital-common-countries')]"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 46
    }
   ],
   "source": [
    "# Load the google analogies training dataset:\n",
    "analogy_dataset = load_data()\n",
    "analogy_dataset[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-88888c737abb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Transform the data such that it includes the embeddings of the words in consideration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtransformed_analogy_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgender_subspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manalogy_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_boluk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Obtaining the dimensionality of the word embeddings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word_vectors' is not defined"
     ],
     "ename": "NameError",
     "evalue": "name 'word_vectors' is not defined",
     "output_type": "error"
    }
   ],
   "source": [
    "# Transform the data such that it includes the embeddings of the words in consideration\n",
    "transformed_analogy_dataset, gender_subspace = transform_data(word_vectors, analogy_dataset, use_boluk = False)\n",
    "\n",
    "\n",
    "# Obtaining the dimensionality of the word embeddings\n",
    "word_embedding_dim = transformed_analogy_dataset[0].gt_embedding.shape[0]\n",
    "\n",
    "# Testing the transformed analogy dataset\n",
    "assert transformed_analogy_dataset[0].analogy_embeddings.shape[0] == word_embedding_dim * 3\n",
    "assert transformed_analogy_dataset[0].gt_embedding.shape[0] == word_embedding_dim\n",
    "assert transformed_analogy_dataset[0].protected.shape[0] == 1\n",
    "\n",
    "print(transformed_analogy_dataset[0].analogy_embeddings.shape)\n",
    "print(transformed_analogy_dataset[0].gt_embedding.shape)\n",
    "print(transformed_analogy_dataset[0].protected.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run the grid-search and obtain the np.dot(w.T, g) values\n",
    "learning_rate_list = [2 ** -12, 2 ** -6, 2 ** -3]\n",
    "adversary_loss_weight_list = [1.0, 0.5, 0.1]\n",
    "\n",
    "# For the saved model checkpoints pertaining to the word embedding type\n",
    "word_embedding_type = 'GNews'\n",
    "\n",
    "# Performing the grid search\n",
    "utility_functions.grid_search(learning_rate_list, adversary_loss_weight_list, word_embedding_dim, gender_subspace, transformed_analogy_dataset, word_embedding_type, 'models')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def load_model(model_path: Path, word_embedding_dim, gender_subspace):\n",
    "    # with open(str(model_path), \"rb\") as f:\n",
    "    #     state_dict = pickle.load(f)\n",
    "    # device = torch.device('cpu')\n",
    "    # print(model_path)\n",
    "    state_dict = torch.load(str(model_path), map_location=torch.device('cpu'))\n",
    "    model = AdversarialDebiasing(\n",
    "                    seed = 42,\n",
    "                    word_embedding_dim = word_embedding_dim,\n",
    "                    num_epochs = 500,\n",
    "                    debias = False,\n",
    "                    gender_subspace = gender_subspace,\n",
    "                    batch_size = 256,\n",
    "                    adversary_loss_weight = 0.1,\n",
    "                    classifier_learning_rate = 2 ** -6,\n",
    "                    adversary_learning_rate = 2 ** -6\n",
    "                )\n",
    "    \n",
    "    model.W1 = state_dict[\"W1\"]\n",
    "    model.W2 = state_dict[\"W2\"]\n",
    "    \n",
    "    return model\n",
    "\n",
    "debiased_models = defaultdict(list)\n",
    "non_debiased_models = defaultdict(list)\n",
    "\n",
    "\n",
    "ModelResult = namedtuple('ModelResult', ['best_model', 'last_model', 'embedding_type', 'learning_rate', 'adversary_weight', 'debiased'])\n",
    "\n",
    "for model_base_path in [Path('models/debiased'), Path('models/non_debiased')]:\n",
    "    l, debiased = (non_debiased_models, False) if 'non_debiased' in str(model_base_path) else (debiased_models, True)\n",
    "\n",
    "    for model_path in model_base_path.iterdir():\n",
    "        if '_last' in str(model_path):\n",
    "            continue\n",
    "            \n",
    "        m = re.search('^([A-Za-z]+)_([\\d.]+)_([\\d.]+)(_last){0,1}.pckl$', str(model_path.name))\n",
    "        embeddings = m.group(1)\n",
    "        learning_rate = m.group(2)\n",
    "        adversary_weight = m.group(3)\n",
    "        \n",
    "        best_model = load_model(model_path, word_embedding_dim, gender_subspace)\n",
    "        \n",
    "        last_model_path = model_path.parent / f\"{model_path.stem}_last{model_path.suffix}\"\n",
    "        last_model = load_model(last_model_path, word_embedding_dim, gender_subspace)\n",
    "        \n",
    "        \n",
    "        l[embeddings].append(ModelResult(best_model, last_model, embeddings, learning_rate, adversary_weight, debiased))\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "defaultdict(<class 'list'>, {'GNews': [ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7a5fab50>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7a68e150>, embedding_type='GNews', learning_rate='0.125', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921b910>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921b550>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e8010a390>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7a2b1410>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7bb70b90>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e795eda50>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79867590>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e798677d0>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79867110>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79867a50>, embedding_type='GNews', learning_rate='0.125', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e798675d0>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79867810>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e798674d0>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79867dd0>, embedding_type='GNews', learning_rate='0.125', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921e650>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921eb10>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='1.0', debiased=True)], 'WikipediaVec': [ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921b710>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921bcd0>, embedding_type='WikipediaVec', learning_rate='0.125', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921b990>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921b890>, embedding_type='WikipediaVec', learning_rate='0.000244140625', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921bc10>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921b8d0>, embedding_type='WikipediaVec', learning_rate='0.125', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e795ed550>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e795ed390>, embedding_type='WikipediaVec', learning_rate='0.015625', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e795ed610>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e795edc10>, embedding_type='WikipediaVec', learning_rate='0.015625', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79867690>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79867390>, embedding_type='WikipediaVec', learning_rate='0.015625', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79867950>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79867890>, embedding_type='WikipediaVec', learning_rate='0.125', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7922c510>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7922cbd0>, embedding_type='WikipediaVec', learning_rate='0.000244140625', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921e350>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921e050>, embedding_type='WikipediaVec', learning_rate='0.000244140625', adversary_weight='0.1', debiased=True)], 'Glove': [ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e795ed810>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e795ed590>, embedding_type='Glove', learning_rate='0.000244140625', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79587f90>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79587490>, embedding_type='Glove', learning_rate='0.000244140625', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79867d50>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79867e50>, embedding_type='Glove', learning_rate='0.125', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79867650>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7a6ba210>, embedding_type='Glove', learning_rate='0.015625', adversary_weight='0.5', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7922c450>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79215d50>, embedding_type='Glove', learning_rate='0.125', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79215850>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79215e90>, embedding_type='Glove', learning_rate='0.015625', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7922ca90>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7922ca10>, embedding_type='Glove', learning_rate='0.015625', adversary_weight='0.1', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7922c090>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7922c850>, embedding_type='Glove', learning_rate='0.000244140625', adversary_weight='1.0', debiased=True), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7922c190>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921ef50>, embedding_type='Glove', learning_rate='0.125', adversary_weight='1.0', debiased=True)]}) 3\n",
      "defaultdict(<class 'list'>, {'GNews': [ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921e950>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921ed90>, embedding_type='GNews', learning_rate='0.125', adversary_weight='1.0', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79816790>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921e3d0>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='1.0', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79835110>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79835dd0>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='0.5', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e798359d0>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e795a3950>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='0.5', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79220550>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79220ed0>, embedding_type='GNews', learning_rate='0.000244140625', adversary_weight='0.1', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79226890>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79226750>, embedding_type='GNews', learning_rate='0.125', adversary_weight='0.5', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e797f0690>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e795855d0>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='0.1', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79585390>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79585290>, embedding_type='GNews', learning_rate='0.125', adversary_weight='0.1', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7920d450>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7920d690>, embedding_type='GNews', learning_rate='0.015625', adversary_weight='1.0', debiased=False)], 'WikipediaVec': [ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921ead0>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921ea90>, embedding_type='WikipediaVec', learning_rate='0.125', adversary_weight='0.5', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921e790>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921e8d0>, embedding_type='WikipediaVec', learning_rate='0.000244140625', adversary_weight='0.5', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921ee50>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7921ee10>, embedding_type='WikipediaVec', learning_rate='0.125', adversary_weight='1.0', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79835710>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79835e90>, embedding_type='WikipediaVec', learning_rate='0.015625', adversary_weight='0.5', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79835450>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e795722d0>, embedding_type='WikipediaVec', learning_rate='0.015625', adversary_weight='1.0', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e8012dc50>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79570150>, embedding_type='WikipediaVec', learning_rate='0.015625', adversary_weight='0.1', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e79596a90>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e7aaf3cd0>, embedding_type='WikipediaVec', learning_rate='0.125', adversary_weight='0.1', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e791f4050>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e791f4190>, embedding_type='WikipediaVec', learning_rate='0.000244140625', adversary_weight='1.0', debiased=False), ModelResult(best_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e791f4d10>, last_model=<adversarial_debiasing.AdversarialDebiasing object at 0x7f5e791f49d0>, embedding_type='WikipediaVec', learning_rate='0.000244140625', adversary_weight='0.1', debiased=False)]}) 2\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "print(debiased_models, len(debiased_models))\n",
    "print(non_debiased_models, len(non_debiased_models))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "               0.000244140625 0.015625 0.125\n0.000244140625            NaN      NaN   NaN\n0.015625                  NaN      NaN   NaN\n0.125                     NaN      NaN   NaN\n1.0                         0        0     0\n0.5                         0        0     0\n0.1                         0        0     0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0.000244140625</th>\n      <th>0.015625</th>\n      <th>0.125</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.000244140625</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0.015625</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>0.125</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0.5</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>0.1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 89
    }
   ],
   "source": [
    "# Last model\n",
    "learning_rates = list(set(model.learning_rate for models in debiased_models.values() for model in models)) \n",
    "adversary_weights = list(set(model.learning_rate for models in debiased_models.values() for model in models)) \n",
    "\n",
    "adversary_weights = sorted(adversary_weights)\n",
    "learning_rates = sorted(learning_rates)\n",
    "\n",
    "box_df_debiased = pd.DataFrame([], columns=learning_rates, index=adversary_weights)\n",
    "\n",
    "for model_result in debiased_models['GNews']:\n",
    "    box_df_debiased.loc[model_result.adversary_weight, model_result.learning_rate] = np.dot(model_result.last_model.W1.clone().detach().numpy().T, gender_subspace.T).item()\n",
    "\n",
    "box_df_debiased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "outputs": [
    {
     "data": {
      "text/plain": "     0.000244140625  0.015625  0.125\n0.1             0.0       0.0    0.0\n0.5             0.0       0.0    0.0\n1.0             0.0       0.0    0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0.000244140625</th>\n      <th>0.015625</th>\n      <th>0.125</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0.5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 83
    }
   ],
   "source": [
    "# Best model\n",
    "box_df_debiased = pd.DataFrame([], columns=learning_rates, index=adversary_weights)\n",
    "\n",
    "for model_result in debiased_models:\n",
    "    box_df_debiased.loc[model_result.adversary_weight, model_result.learning_rate] = np.dot(model_result.best_model.W1.clone().detach().numpy().T, gender_subspace).item()\n",
    "\n",
    "box_df_debiased\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "     0.000244140625  0.015625  0.125\n0.1             0.0       0.0    0.0\n0.5             0.0       0.0    0.0\n1.0             0.0       0.0    0.0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0.000244140625</th>\n      <th>0.015625</th>\n      <th>0.125</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0.1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>0.5</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1.0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 81
    }
   ],
   "source": [
    "# \n",
    "box_df_biased = pd.DataFrame([], columns=learning_rates, index=adversary_weights)\n",
    "\n",
    "for model_result in debiased_models:\n",
    "    box_df_biased.loc[model_result.adversary_weight, model_result.learning_rate] = np.dot(model_result.last_model.W1.clone().detach().numpy().T, gender_subspace).item()\n",
    "\n",
    "box_df_biased\n",
    "\n",
    "\n",
    "\n",
    "# debiased_model_best.W1 = best_state_dict[\"W1\"]\n",
    "# debiased_model_best.W2 = best_state_dict[\"W2\"]\n",
    "# debiased_model_last.W1 = last_state_dict[\"W1\"]\n",
    "# debiased_model_last.W2 = last_state_dict[\"W2\"]\n",
    "# \n",
    "# print(\"Best : {}\".format(np.dot(debiased_model_best.W1.clone().detach().cpu().numpy().T, gender_subspace.T)))\n",
    "# \n",
    "# print(\"Last : {}\".format(np.dot(debiased_model_last.W1.clone().detach().cpu().numpy().T, gender_subspace.T)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debiased_model.fit(dataset=transformed_analogy_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Qualitative Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Get sexism traps as word embeddings and words\n",
    "datapoints, test_analogies = qualitative_evaluation.get_datapoints(word_vectors)\n",
    "\n",
    "# Predictions of the non debiased model\n",
    "non_debiased_predictions = qualitative_evaluation.get_non_debiased_predictions(datapoints, word_embedding_dim)\n",
    "non_debiased_most_similar_list = utility_functions.obtain_most_similar(non_debiased_predictions, word_vectors)\n",
    "\n",
    "# Predictions of the debiased model\n",
    "debiased_predictions = debiased_model.predict(datapoints)\n",
    "debiased_most_similar_list = utility_functions.obtain_most_similar(debiased_predictions, word_vectors)\n",
    "\n",
    "# Print similarity results for both models\n",
    "qualitative_evaluation.print_combined_table(non_debiased_most_similar_list, debiased_most_similar_list, test_analogies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}